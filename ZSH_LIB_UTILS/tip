#!/usr/bin/zsh

#Inline ansi
BOLD="\033[1m"
ITALIC="\033[3m"
RESET="\033[m"
REVERSE="\033[7m"
STRIKE="\033[9m"
UNDER="\033[4m"

BLACK_BG="\033[40m"

BLUE_FG="\033[34m"
CYAN_FG="\033[36m"
GREEN_FG="\033[32m"
MAGENTA_FG="\033[35m"
RED_FG="\033[31m"
WHITE_FG="\033[37m"
YELLOW_FG="\033[33m"

WHITE_ON_GREY="\033[0m\033[0;1;37;100m"

#Echoed ansi
E_BOLD=$(echo -n "\033[1m")
E_ITALIC=$(echo -n "\033[3m")
E_RESET=$(echo -n "\033[m")
E_REVERSE=$(echo -n "\033[7m")
E_STRIKE=$(echo -n "\033[9m")
E_UNDER=$(echo -n "\033[4m")

E_BLUE_FG=$(echo -n "\033[34m")
E_CYAN_FG=$(echo -n "\033[36m")
E_GREEN_FG=$(echo -n "\033[32m")
E_MAGENTA_FG=$(echo -n "\033[35m")
E_RED_FG=$(echo -n "\033[31m")
E_WHITE_FG=$(echo -n "\033[37m")
E_YELLOW_FG=$(echo -n "\033[33m")

E_BLACK_BG=$(echo -n "\033[40m")
E_BLUE_BG=$(echo -n "\033[44m")
E_CYAN_BG=$(echo -n "\033[46m")
E_GREEN_BG=$(echo -n "\033[42m")
E_MAGENTA_BG=$(echo -n "\033[45m")
E_RED_BG=$(echo -n "\033[41m")
E_WHITE_BG=$(echo -n "\033[47m")
E_YELLOW_BG=$(echo -n "\033[43m")

#Declarations
typeset -A _EXTERNAL=(desktop_files  1 sed 1 zsh_comp_official 1 zsh_comp_guide 1)
typeset -A _EXTERNAL_FILES
typeset -a _TIPS

#Constants
_EXT_DIR=/usr/local/etc
_EXTERNAL_FILES=(
desktop_files "${_EXT_DIR}/Desktop Entry Specification.pdf"
sed	"${_EXT_DIR}/StreamEditor-BasicCommands.pdf"
sed "${_EXT_DIR}/sed.pdf"
zsh_comp_official "${_EXT_DIR}/zsh-completions-howto.pdf"
zsh_comp_guide "${_EXT_DIR}/ZshUserGuideCompletion.pdf"
zsh_cheatsheet "${_EXT_DIR}/zsh-cheatsheet.md"
)

_SCRIPT_FQFN=${0}
_TIPS=(
cron 
desktop_files 
dpkg 
ex 
git 
linux 
mail
mime 
nfs 
perl 
printf 
pup 
regex 
rsync 
sed 
tput 
vim 
vimcolors 
vim_keymap 
vlc 
zsh 
zsh_comp_official 
zsh_comp_guide
zshdb 
zsh_params 
zsh_primitives 
zsh_cheatsheet 
)

#Imports
_LIB_DIR=/usr/local/lib
source ${_LIB_DIR}/LIB_INIT.zsh
source ${_LIB_DIR}/SEL_LIST.zsh

for D in ${=_DEPS_};do
	if [[ -e ${_LIB_DIR}/${D} ]];then
		source ${_LIB_DIR}/${D}
	else
		echo "Cannot source:${_LIB_DIR}/${D} - not found"
		exit 1
	fi
done

#Functions
tip_cron () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_cron_EOF

The ${E_WHITE_FG}cron${E_RESET} command

   ${E_WHITE_FG}When             Setting${E_RESET}
   ${E_WHITE_FG}----             -------${E_RESET}
   Every 1 minute   ${E_WHITE_FG}*${E_RESET} ${E_GREEN_FG}*${E_RESET} ${E_MAGENTA_FG}*${E_RESET} ${E_RED_FG}*${E_RESET} ${E_CYAN_FG}*${E_RESET}
   Every 15 minutes ${E_WHITE_FG}*/15${E_RESET} ${E_GREEN_FG}*${E_RESET} ${E_MAGENTA_FG}*${E_RESET} ${E_RED_FG}*${E_RESET} ${E_CYAN_FG}*${E_RESET}
   Every 30 minutes ${E_WHITE_FG}*/30${E_RESET} ${E_GREEN_FG}*${E_RESET} ${E_MAGENTA_FG}*${E_RESET} ${E_RED_FG}*${E_RESET} ${E_CYAN_FG}*${E_RESET}
   Every 1 hour     ${E_WHITE_FG}0${E_RESET} ${E_GREEN_FG}*${E_RESET} ${E_MAGENTA_FG}*${E_RESET} ${E_RED_FG}*${E_RESET} ${E_CYAN_FG}*${E_RESET}
   Every 6 hours    ${E_WHITE_FG}0${E_RESET} ${E_GREEN_FG}*/6${E_RESET} ${E_MAGENTA_FG}*${E_RESET} ${E_RED_FG}*${E_RESET} ${E_CYAN_FG}*${E_RESET}
   Every 12 hours   ${E_WHITE_FG}0${E_RESET} ${E_GREEN_FG}*/12${E_RESET} ${E_MAGENTA_FG}*${E_RESET} ${E_RED_FG}*${E_RESET} ${E_CYAN_FG}*${E_RESET}
   Once a day       ${E_WHITE_FG}0${E_RESET} ${E_GREEN_FG}0${E_RESET} ${E_MAGENTA_FG}*${E_RESET} ${E_RED_FG}*${E_RESET} ${E_CYAN_FG}*${E_RESET}
   Once a week(SAT) ${E_WHITE_FG}0${E_RESET} ${E_GREEN_FG}0${E_RESET} ${E_MAGENTA_FG}*${E_RESET} ${E_RED_FG}*${E_RESET} ${E_CYAN_FG}SAT${E_RESET}
   Once a month     ${E_WHITE_FG}0${E_RESET} ${E_GREEN_FG}0${E_RESET} ${E_MAGENTA_FG}1${E_RESET} ${E_RED_FG}*${E_RESET} ${E_CYAN_FG}*${E_RESET}
   Weekdays 6pm     ${E_WHITE_FG}0${E_RESET} ${E_GREEN_FG}18${E_RESET} ${E_MAGENTA_FG}*${E_RESET} ${E_RED_FG}*${E_RESET} ${E_CYAN_FG}1-5${E_RESET}

   Here is a diagram of the general ${E_WHITE_FG}cron${E_RESET} syntax, for illustration:
   +---------------- ${E_WHITE_FG}minute (0-59)${E_RESET}
   |  +------------- ${E_GREEN_FG}hour (0-23)${E_RESET}
   |  |  +---------- ${E_MAGENTA_FG}day of month (1-31)${E_RESET}
   |  |  |  +------- ${E_RED_FG}month (1-12)${E_RESET}
   |  |  |  |  +---- ${E_CYAN_FG}day of week (0-6) (Sunday=0)${E_RESET}
   |  |  |  |  |
   ${E_WHITE_FG}*${E_RESET}  ${E_GREEN_FG}*${E_RESET}  ${E_MAGENTA_FG}*${E_RESET}  ${E_RED_FG}*${E_RESET}  ${E_CYAN_FG}*${E_RESET}  command to be executed

   In the following example, the ${E_WHITE_FG}cron${E_RESET} command shown below will activate the ${E_WHITE_FG}cron${E_RESET} tasks automatically on the hour:

   ${E_WHITE_FG}0 * * * * ping http://www.example.com${E_RESET}

   In the above sample, the ${E_WHITE_FG}0 * * * *${E_RESET} represents when the task should happen
   The first figure represents minutes i.e. on the "zero" minute, or top of the hour
   The other figures represent, respectively, hour, day, month and day of the week
   A * is a wildcard, meaning "every time" 
   The minimum is every one minute ${E_WHITE_FG}* * * * *${E_RESET}

   Thus, the ${E_WHITE_FG}cron${E_RESET} command example above means "ping http://www.example.com at the zero minute on every hour of every day
   of every month of every day of the week."
   
   Legend
   ------
   ${E_WHITE_FG}*${E_RESET}         Expands to all values for the field
   ${E_WHITE_FG},${E_RESET}         List separator
   ${E_WHITE_FG}-${E_RESET}         Range separator
   ${E_WHITE_FG}/${E_RESET}         Specifies step for ranges
   ${E_WHITE_FG}@hourly${E_RESET}   Run at the start of each hour
   ${E_WHITE_FG}@daily${E_RESET}    Run every day at midnight UTC
   ${E_WHITE_FG}@weekly${E_RESET}   Run at every Sunday at midnight UTC
   ${E_WHITE_FG}@monthly${E_RESET}  Run on the 1st of each month at midnight UTC
   ${E_WHITE_FG}@yearly${E_RESET}   Run on Jan 1st at midnight UTC
   ${E_WHITE_FG}@annually${E_RESET} Same as @yearly
   
   
   Every Minute                ${E_WHITE_FG}* * * * *${E_RESET}
   Every Five Minutes          ${E_WHITE_FG}*/5 * * * *${E_RESET}
   Every 10 Minutes            ${E_WHITE_FG}*/10 * * * *${E_RESET}
   Every 15 Minutes            ${E_WHITE_FG}*/15 * * * *${E_RESET}
   Every 30 Minutes            ${E_WHITE_FG}*/30 * * * *${E_RESET}
   Every Hour                  ${E_WHITE_FG}0 * * * *${E_RESET}
   Every Two Hours             ${E_WHITE_FG}0 */2 * * *${E_RESET}
   Every Six Hours             ${E_WHITE_FG}0 */6 * * *${E_RESET}
   Every 12 Hours              ${E_WHITE_FG}0 */12 * * *${E_RESET}
   During the Work Day         ${E_WHITE_FG}*/5 9-17 * * *${E_RESET}
   Every day at Midnight       ${E_WHITE_FG}0 0 * * *${E_RESET}
   Every Two Weeks             ${E_WHITE_FG}0 0 * * Sun [ \$(expr \$(date +%W) % 2) -eq 1 ] && /path/to/command${E_RESET}
   At the Start of Every Month ${E_WHITE_FG}0 0 1 * *${E_RESET}
   On January 1st at Midnight  ${E_WHITE_FG}0 0 1 1 * ${E_RESET}
   Weekends only               ${E_WHITE_FG}0 0 * * 6,0${E_RESET}
   
tip_cron_EOF
}

tip_desktop_files () {
	(
	okular --page 1 "/usr/local/etc/Desktop Entry Specification.pdf" 
	win_max okular
	) 2>/dev/null &
}

tip_dpkg () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_dpkg_EOF

${E_WHITE_FG}Install a specific version of a package with apt${E_RESET}

For available versions...
apt list --all-versions package_name

To install...
sudo apt install package_name=package_version

${E_WHITE_FG}Guide to dpkg -l ...${E_RESET}

${E_CYAN_FG}Example:${E_RESET}dpkg -l grep
Desired=Unknown/Install/Remove/Purge/Hold
| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend
|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)
||/ Name           Version      Architecture Description
+++-==============-============-============-=================================
ii  grep           3.7-1build1  amd64        GNU grep, egrep and fgrep

${E_CYAN_FG}Key:${E_RESET}
First letter -> desired package state ("selection state"):

u ... unknown
i ... install
r ... remove/deinstall
p ... purge (remove including config files)
h ... hold

Second letter -> current package state:

n ... not-installed
i ... installed
c ... config-files (only the config files are installed)
u ... unpacked
f ... half-configured (configuration failed for some reason)
h ... half-installed (installation failed for some reason)
w ... triggers-awaited (package is waiting for a trigger from another package)
t ... triggers-pending (package has been triggered)

Third letter -> error state (you normally shouldn't see a third letter):

r ... reinst-required (package broken, reinstallation required)

${E_WHITE_FG}If this error occurs${E_RESET}:
${E_ITALIC}dpkg: error processing archive (SOMEFILE).deb (--unpack):
${E_ITALIC}trying to overwrite '(SOMEFILE).deb (--unpack):(SOMEFILE)', which is also in package (SOMEFILE)
${E_ITALIC}dpkg-deb: error: paste subprocess was killed by signal (Broken pipe)
${E_ITALIC}Errors were encountered while processing:
${E_ITALIC}(SOMEFILE).deb
${E_ITALIC}E: Sub-process /usr/bin/dpkg returned an error code (1)${E_RESET}

${E_WHITE_FG}Do${E_RESET}:
sudo dpkg -i --force-overwrite (SOMEFILE).deb
Then: sudo apt --fix-broken install
tip_dpkg_EOF
}

tip_ex () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_ex_EOF

EX Command Line Examples
------------------------
insert new top line in file
${E_WHITE_FG}ex${E_RESET} ${E_WHITE_FG}-sc${E_RESET} '1i${E_WHITE_FG}|${E_RESET}text goes here' ${E_WHITE_FG}-cx${E_RESET} <file>

Simple standard input and output using pipes can be achieved by this shell syntax:
$ ${E_WHITE_FG}ex${E_RESET} -sc'%p${E_WHITE_FG}|${E_RESET}q!' <(echo Example)
$ echo Example ${E_WHITE_FG}|${E_RESET} ${E_WHITE_FG}ex${E_RESET} ${E_WHITE_FG}-sc${E_RESET} '%p${E_WHITE_FG}|${E_RESET}q!' /dev/stdin

Here is simple example how to print the file after substitution:
$ ${E_WHITE_FG}ex${E_RESET} /etc/hosts +%s/127/128/ge ${E_WHITE_FG}-sc${E_RESET} '%p${E_WHITE_FG}|${E_RESET}q!'

More examples for editing files in-place:
$ ${E_WHITE_FG}ex${E_RESET} +'%s/127/128/g' -cswq file
$ ${E_WHITE_FG}ex${E_RESET} ${E_WHITE_FG}-sc${E_RESET} '%s/olddomain\.com/newdomain.com/g${E_WHITE_FG}|${E_RESET}x' file
$ printf '%s\n' 'g/olddomain\.com/s//newdomain.com/g' w q ${E_WHITE_FG}|${E_RESET} ${E_WHITE_FG}ex${E_RESET} ${E_WHITE_FG}-s${E_RESET} file
$ ${E_WHITE_FG}ex${E_RESET} ${E_WHITE_FG}-s${E_RESET} "${file}" <<< $'g/old/s//new/g\nw\nq'
$ ${E_WHITE_FG}ex${E_RESET} ${E_WHITE_FG}-sc${E_RESET} 'argdo %s/old/new/ge${E_WHITE_FG}|${E_RESET}x' ./**
$ find . -type f -exec ${E_WHITE_FG}ex${E_RESET} ${E_WHITE_FG}-sc${E_RESET} '%s/old/new/g${E_WHITE_FG}|${E_RESET}x' {} \;

You can also use ${E_WHITE_FG}-s${E_RESET} {scriptin} so the commands are loaded from the file, in example:
$ printf "%s\n" '%s/foo/test/ge' 'wq' > cmds.vim
$ vim ${E_WHITE_FG}-s${E_RESET} cmds.vim ${E_WHITE_FG}-es${E_RESET} file

or using I/O redirection:
$ vim file < cmds.vim

To edit one file and save the changes to another, check the following examples:
$ ${E_WHITE_FG}ex${E_RESET} +%s/127/128/g ${E_WHITE_FG}-sc${E_RESET} 'wq! new_file' /etc/hosts
$ cat /etc/hosts /etc/fstab ${E_WHITE_FG}|${E_RESET} vim - ${E_WHITE_FG}-es${E_RESET} '+:%s/foo/test/g' '+:wq! file3'

More practical examples.
Real live example from the RPM specification:

vim ${E_WHITE_FG}-E${E_RESET} ${E_WHITE_FG}-s${E_RESET} Makefile <<-EOF
   :%substitute/CFLAGS = -g$/CFLAGS =-fPIC -DPIC -g/
   :%substitute/CFLAGS =$/CFLAGS =-fPIC -DPIC/
   :%substitute/ADAFLAGS =$/ADAFLAGS =-fPIC -DPIC/
   :update
   :quit
EOF

Extracting html tags:
${E_WHITE_FG}ex${E_RESET} ${E_WHITE_FG}-s${E_RESET} +'bufdo!/<div.*id=.the_div_id/norm nvatdggdG"2p' +'bufdo!%p' -cqa! *.html

Removing XML tags:
${E_WHITE_FG}ex${E_RESET} ${E_WHITE_FG}-s${E_RESET} +'%s/<[^>].\{-}>//ge' +%p +q! file.txt

Removing style tag from the header and print the parsed output:
curl ${E_WHITE_FG}-s${E_RESET} http://example.com/ ${E_WHITE_FG}|${E_RESET} ${E_WHITE_FG}ex${E_RESET} ${E_WHITE_FG}-s${E_RESET} +'/<style.*/norm nvatd' +%p -cq! /dev/stdin

Parse html with multiple complex rules:
${E_WHITE_FG}ex${E_RESET} ${E_WHITE_FG}-V1${E_RESET} ${PAGE} <<-EOF
  " Correcting missing protocol, see: https://github.com/wkhtmltopdf/wkhtmltopdf/issues/2359 "
  %s,'//,'http://,ge
  %s,"//,"http://,ge
  " Correcting relative paths, see: https://github.com/wkhtmltopdf/wkhtmltopdf/issues/2359 "
  %s,[^,]\zs'/\ze[^>],'http://www.example.com/,ge
  %s,[^,]\zs"/\ze[^>],"http://www.example.com/,ge
  " Remove the margin on the left of the main block. "
  %s/id="doc_container"/id="doc_container" style="min-width:0px;margin-left : 0px;"/g
  %s/<div class="outer_page/<div style="margin: 0px;" class="outer_page/g
  " Remove useless html elements. "
  /<div.*id="global_header"/norm nvatd
  wq " Update changes and quit.
tip_ex_EOF
}

tip_git () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat<<tip_git_EOF

${E_CYAN_FG}Setup${E_RESET}
${E_CYAN_FG}-----${E_RESET}

${E_WHITE_FG}git${E_RESET} clone <repo>
  clone the repository specified by <repo>; this is similar to "checkout" in
  some other version control systems such as Subversion and CVS

Add colors to your ~/.${E_WHITE_FG}git${E_RESET}config file:

  [color]
    ui = auto
  [color "branch"]
    current = yellow reverse
    local = yellow
    remote = green
  [color "diff"]
    meta = yellow bold
    frag = magenta bold
    old = red bold
    new = green bold
  [color "status"]
    added = yellow
    changed = green
    untracked = cyan

Highlight whitespace in diffs

  [color]
    ui = true
  [color "diff"]
    whitespace = red reverse
  [core]
    whitespace=fix,-indent-with-non-tab,trailing-space,cr-at-eol

Add aliases to your ~/.${E_WHITE_FG}git${E_RESET}config file:

  [alias]
    st = status
    ci = commit
    br = branch
    co = checkout
    df = diff
    dc = diff --cached
    lg = log -p
    lol = log --graph --decorate --pretty=oneline --abbrev-commit
    lola = log --graph --decorate --pretty=oneline --abbrev-commit --all
    ls = ls-files

    # Show files ignored by ${E_WHITE_FG}git${E_RESET}:
    ign = ls-files -o -i --exclude-standard


${E_CYAN_FG}Configuration${E_RESET}
${E_CYAN_FG}-------------${E_RESET}

${E_WHITE_FG}git${E_RESET} config -e [--global]
  edit the .${E_WHITE_FG}git${E_RESET}/config [or ~/.${E_WHITE_FG}git${E_RESET}config] file in your \${EDITOR}

${E_WHITE_FG}git${E_RESET} config --global user.name 'John Doe'
${E_WHITE_FG}git${E_RESET} config --global user.email johndoe@example.com
  sets your name and email for commit messages

${E_WHITE_FG}git${E_RESET} config branch.autosetupmerge true
  tells ${E_WHITE_FG}git${E_RESET}-branch and ${E_WHITE_FG}git${E_RESET}-checkout to setup new branches so that ${E_WHITE_FG}git${E_RESET}-pull(1)
  will appropriately merge from that remote branch.  Recommended.  Without this,
  you will have to add --track to your branch command or manually merge remote
  tracking branches with "fetch" and then "merge".

${E_WHITE_FG}git${E_RESET} config core.autocrlf true
  This setting tells ${E_WHITE_FG}git${E_RESET} to convert the newlines to the system's standard
  when checking out files, and to LF newlines when committing in

${E_WHITE_FG}git${E_RESET} config --list
  To view all options

${E_WHITE_FG}git${E_RESET} config apply.whitespace nowarn
  To ignore whitespace

You can add "--global" after "${E_WHITE_FG}git${E_RESET} config" to any of these commands to make it
apply to all ${E_WHITE_FG}git${E_RESET} repos (writes to ~/.${E_WHITE_FG}git${E_RESET}config).


${E_CYAN_FG}Info
${E_CYAN_FG}----${E_RESET}
${E_WHITE_FG}git${E_RESET} reflog
  Use this to recover from *major* mess ups! It's basically a log of the
  last few actions and you might have luck and find old commits that
  have been lost by doing a complex merge.

${E_WHITE_FG}git${E_RESET} diff
  show a diff of the changes made since your last commit
  to diff one file: "${E_WHITE_FG}git${E_RESET} diff -- <filename>"
  to show a diff between staging area and HEAD: '${E_WHITE_FG}git${E_RESET} diff --cached'

${E_WHITE_FG}git${E_RESET} status
  show files added to the staging area, files with changes, and untracked files

${E_WHITE_FG}git${E_RESET} log
  show recent commits, most recent on top. Useful options:
  --color       with color
  --graph       with an ASCII-art commit graph on the left
  --decorate    with branch and tag names on appropriate commits
  --stat        with stats (files changed, insertions, and deletions)
  -p            with full diffs
  --author=foo  only by a certain author
  --after="MMM DD YYYY" ex. ("Jun 20 2008") only commits after a certain date
  --before="MMM DD YYYY" only commits that occur before a certain date
  --merge       only the commits involved in the current merge conflicts

${E_WHITE_FG}git${E_RESET} log <ref>..<ref>
  show commits between the specified range. Useful for seeing changes from
  remotes:
  ${E_WHITE_FG}git${E_RESET} log HEAD..origin/master # after ${E_WHITE_FG}git${E_RESET} remote update

${E_WHITE_FG}git${E_RESET} show <rev>
  show the changeset (diff) of a commit specified by <rev>, which can be any
  SHA1 commit ID, branch name, or tag (shows the last commit (HEAD) by default)

  also to show the contents of a file at a specific revision, use 
     ${E_WHITE_FG}git${E_RESET} show <rev>:<filename>
  this is similar to cat-file but much simpler syntax.

${E_WHITE_FG}git${E_RESET} show --name-only <rev>
  show only the names of the files that changed, no diff information.

${E_WHITE_FG}git${E_RESET} blame <file>
  show who authored each line in <file>

${E_WHITE_FG}git${E_RESET} blame <file> <rev>
  show who authored each line in <file> as of <rev> (allows blame to go back in
  time)

${E_WHITE_FG}git${E_RESET} gui blame
  really nice GUI interface to ${E_WHITE_FG}git${E_RESET} blame

${E_WHITE_FG}git${E_RESET} whatchanged <file>
  show only the commits which affected <file> listing the most recent first
  E.g. view all changes made to a file on a branch:
    ${E_WHITE_FG}git${E_RESET} whatchanged <branch> <file>  | grep commit | 
         colrm 1 7 | xargs -I % ${E_WHITE_FG}git${E_RESET} show % <file>
  this could be combined with ${E_WHITE_FG}git${E_RESET} remote show <remote> to find all changes on
  all branches to a particular file.

${E_WHITE_FG}git${E_RESET} diff <commit> head path/to/fubar
  show the diff between a file on the current branch and potentially another
  branch

${E_WHITE_FG}git${E_RESET} diff --cached [<file>]
  shows diff for staged (${E_WHITE_FG}git${E_RESET}-add'ed) files (which includes uncommitted ${E_WHITE_FG}git${E_RESET}
  cherry-pick'ed files)

${E_WHITE_FG}git${E_RESET} ls-files
  list all files in the index and under version control.

${E_WHITE_FG}git${E_RESET} ls-remote <remote> [HEAD]
  show the current version on the remote repo. This can be used to check whether
  a local is required by comparing the local head revision.

${E_CYAN_FG}Adding / Deleting${E_RESET}
${E_CYAN_FG}-----------------${E_RESET}

${E_WHITE_FG}git${E_RESET} add <file1> <file2> ...
  add <file1>, <file2>, etc... to the project

${E_WHITE_FG}git${E_RESET} add <dir>
  add all files under directory <dir> to the project, including subdirectories

${E_WHITE_FG}git${E_RESET} add .
  add all files under the current directory to the project
  *WARNING*: including untracked files.

${E_WHITE_FG}git${E_RESET} rm <file1> <file2> ...
  remove <file1>, <file2>, etc... from the project

${E_WHITE_FG}git${E_RESET} rm \$(${E_WHITE_FG}git${E_RESET} ls-files --deleted)
  remove all deleted files from the project

${E_WHITE_FG}git${E_RESET} rm --cached <file1> <file2> ...
  commits absence of <file1>, <file2>, etc... from the project

${E_CYAN_FG}Ignoring${E_RESET}
${E_CYAN_FG}---------${E_RESET}

Option 1:

Edit \${GIT_DIR}/info/exclude. See Environment Variables below for explanation on
\${GIT_DIR}.

Option 2:

Add a file .${E_WHITE_FG}git${E_RESET}ignore to the root of your project. This file will be checked in.

Either way you need to add patterns to exclude to these files.

${E_CYAN_FG}Staging${E_RESET}
${E_CYAN_FG}-------${E_RESET}

${E_WHITE_FG}git${E_RESET} add <file1> <file2> ...
${E_WHITE_FG}git${E_RESET} stage <file1> <file2> ...
  add changes in <file1>, <file2> ... to the staging area (to be included in
  the next commit

${E_WHITE_FG}git${E_RESET} add -p
${E_WHITE_FG}git${E_RESET} stage --patch
  interactively walk through the current changes (hunks) in the working
  tree, and decide which changes to add to the staging area.

${E_WHITE_FG}git${E_RESET} add -i
${E_WHITE_FG}git${E_RESET} stage --interactive
  interactively add files/changes to the staging area. For a simpler
  mode (no menu), try '${E_WHITE_FG}git${E_RESET} add --patch' (above)

${E_CYAN_FG}Unstaging${E_RESET}
${E_CYAN_FG}---------${E_RESET}

${E_WHITE_FG}git${E_RESET} reset HEAD <file1> <file2> ...
  remove the specified files from the next commit


${E_CYAN_FG}Committing${E_RESET}
${E_CYAN_FG}----------${E_RESET}

${E_WHITE_FG}git${E_RESET} commit <file1> <file2> ... [-m <msg>]
  commit <file1>, <file2>, etc..., optionally using commit message <msg>,
  otherwise opening your editor to let you type a commit message

${E_WHITE_FG}git${E_RESET} commit -a
  commit all files changed since your last commit
  (does not include new (untracked) files)

${E_WHITE_FG}git${E_RESET} commit -v
  commit verbosely, i.e. includes the diff of the contents being committed in
  the commit message screen

${E_WHITE_FG}git${E_RESET} commit --amend
  edit the commit message of the most recent commit

${E_WHITE_FG}git${E_RESET} commit --amend <file1> <file2> ...
  redo previous commit, including changes made to <file1>, <file2>, etc...


${E_CYAN_FG}Branching${E_RESET}
${E_CYAN_FG}---------${E_RESET}

${E_WHITE_FG}git${E_RESET} branch
  list all local branches

${E_WHITE_FG}git${E_RESET} branch -r
  list all remote branches

${E_WHITE_FG}git${E_RESET} branch -a
  list all local and remote branches

${E_WHITE_FG}git${E_RESET} branch <branch>
  create a new branch named <branch>, referencing the same point in history as
  the current branch

${E_WHITE_FG}git${E_RESET} branch <branch> <start-point>
  create a new branch named <branch>, referencing <start-point>, which may be
  specified any way you like, including using a branch name or a tag name

${E_WHITE_FG}git${E_RESET} push <repo> <start-point>:refs/heads/<branch>
  create a new remote branch named <branch>, referencing <start-point> on the
  remote. Repo is the name of the remote.
  Example: ${E_WHITE_FG}git${E_RESET} push origin origin:refs/heads/branch-1
  Example: ${E_WHITE_FG}git${E_RESET} push origin origin/branch-1:refs/heads/branch-2
  Example: ${E_WHITE_FG}git${E_RESET} push origin branch-1 ## shortcut

${E_WHITE_FG}git${E_RESET} branch --track <branch> <remote-branch>
  create a tracking branch. Will push/pull changes to/from another repository.
  Example: ${E_WHITE_FG}git${E_RESET} branch --track experimental origin/experimental

${E_WHITE_FG}git${E_RESET} branch --set-upstream <branch> <remote-branch> (As of Git 1.7.0)
  Make an existing branch track a remote branch
  Example: ${E_WHITE_FG}git${E_RESET} branch --set-upstream foo origin/foo

${E_WHITE_FG}git${E_RESET} branch -d <branch>
  delete the branch <branch>; if the branch you are deleting points to a
  commit which is not reachable from the current branch, this command
  will fail with a warning.

${E_WHITE_FG}git${E_RESET} branch -r -d <remote-branch>
  delete a remote-tracking branch.
  Example: ${E_WHITE_FG}git${E_RESET} branch -r -d wycats/master

${E_WHITE_FG}git${E_RESET} branch -D <branch>
  even if the branch points to a commit not reachable from the current branch,
  you may know that that commit is still reachable from some other branch or
  tag. In that case it is safe to use this command to force ${E_WHITE_FG}git${E_RESET} to delete the
  branch.

${E_WHITE_FG}git${E_RESET} checkout <branch>
  make the current branch <branch>, updating the working directory to reflect
  the version referenced by <branch>

${E_WHITE_FG}git${E_RESET} checkout -b <new> <start-point>
  create a new branch <new> referencing <start-point>, and check it out.

${E_WHITE_FG}git${E_RESET} push <repository> :<branch>
  removes a branch from a remote repository.
  Example: ${E_WHITE_FG}git${E_RESET} push origin :old_branch_to_be_deleted

${E_WHITE_FG}git${E_RESET} co <branch> <path to new file>
  Checkout a file from another branch and add it to this branch. File
  will still need to be added to the ${E_WHITE_FG}git${E_RESET} branch, but it's present.
  Eg. ${E_WHITE_FG}git${E_RESET} co remote_at_origin__tick702_antifraud_blocking
  ..../...nt_elements_for_iframe_blocked_page.rb

${E_WHITE_FG}git${E_RESET} show <branch> -- <path to file that does not exist>
  Eg. ${E_WHITE_FG}git${E_RESET} show remote_tick702 -- path/to/fubar.txt
  show the contents of a file that was created on another branch and that
  does not exist on the current branch.

${E_WHITE_FG}git${E_RESET} show <rev>:<repo path to file>
  Show the contents of a file at the specific revision. Note: path has to be
  absolute within the repo.

${E_CYAN_FG}Merging${E_RESET}
${E_CYAN_FG}-------${E_RESET}

${E_WHITE_FG}git${E_RESET} merge <branch>
  merge branch <branch> into the current branch; this command is idempotent
  and can be run as many times as needed to keep the current branch
  up-to-date with changes in <branch>

${E_WHITE_FG}git${E_RESET} merge <branch> --no-commit
  merge branch <branch> into the current branch, but do not autocommit the
  result; allows you to make further tweaks

${E_WHITE_FG}git${E_RESET} merge <branch> -s ours
  merge branch <branch> into the current branch, but drops any changes in
  <branch>, using the current tree as the new tree


${E_CYAN_FG}Cherry-Picking${E_RESET}
${E_CYAN_FG}--------------${E_RESET}

${E_WHITE_FG}git${E_RESET} cherry-pick [--edit] [-n] [-m parent-number] [-s] [-x] <commit>
  selectively merge a single commit from another local branch
  Example: ${E_WHITE_FG}git${E_RESET} cherry-pick 7300a6130d9447e18a931e898b64eefedea19544


${E_CYAN_FG}Squashing${E_RESET}
${E_CYAN_FG}---------${E_RESET}
WARNING: "${E_WHITE_FG}git${E_RESET} rebase" changes history. Be careful. Google it.

${E_WHITE_FG}git${E_RESET} rebase --interactive HEAD~10
  (then change all but the first "pick" to "squash")
  squash the last 10 commits into one big commit


${E_CYAN_FG}Conflicts${E_RESET}
${E_CYAN_FG}---------${E_RESET}

${E_WHITE_FG}git${E_RESET} mergetool
  work through conflicted files by opening them in your mergetool (opendiff,
  kdiff3, etc.) and choosing left/right chunks. The merged result is staged for
  commit.

For binary files or if mergetool won't do, resolve the conflict(s) manually
and then do:

  ${E_WHITE_FG}git${E_RESET} add <file1> [<file2> ...]

Once all conflicts are resolved and staged, commit the pending merge with:

  ${E_WHITE_FG}git${E_RESET} commit


${E_CYAN_FG}Sharing${E_RESET}
${E_CYAN_FG}-------${E_RESET}

${E_WHITE_FG}git${E_RESET} fetch <remote>
  update the remote-tracking branches for <remote> (defaults to "origin").
  Does not initiate a merge into the current branch (see "${E_WHITE_FG}git${E_RESET} pull" below).

${E_WHITE_FG}git${E_RESET} pull
  fetch changes from the server, and merge them into the current branch.
  Note: .${E_WHITE_FG}git${E_RESET}/config must have a [branch "some_name"] section for the current
  branch, to know which remote-tracking branch to merge into the current
  branch.  Git 1.5.3 and above adds this automatically.

${E_WHITE_FG}git${E_RESET} push
  update the server with your commits across all branches that are *COMMON*
  between your local copy and the server.  Local branches that were never
  pushed to the server in the first place are not shared.

${E_WHITE_FG}git${E_RESET} push origin <branch>
  update the server with your commits made to <branch> since your last push.
  This is always *required* for new branches that you wish to share. After
  the first explicit push, "${E_WHITE_FG}git${E_RESET} push" by itself is sufficient.

${E_WHITE_FG}git${E_RESET} push origin <branch>:refs/heads/<branch>
  E.g. ${E_WHITE_FG}git${E_RESET} push origin twitter-experiment:refs/heads/twitter-experiment
  Which, in fact, is the same as ${E_WHITE_FG}git${E_RESET} push origin <branch> but a little
  more obvious what is happening.

${E_CYAN_FG}Reverting${E_RESET}
${E_CYAN_FG}---------${E_RESET}

${E_WHITE_FG}git${E_RESET} revert <rev>
  reverse commit specified by <rev> and commit the result.  This does *not* do
  the same thing as similarly named commands in other VCS's such as "svn
  revert" or "bzr revert", see below

${E_WHITE_FG}git${E_RESET} checkout <file>
  re-checkout <file>, overwriting any local changes

${E_WHITE_FG}git${E_RESET} checkout .
  re-checkout all files, overwriting any local changes.  This is most similar
  to "svn revert" if you're used to Subversion commands


${E_CYAN_FG}Fix mistakes / Undo${E_RESET}
${E_CYAN_FG}-------------------${E_RESET}

${E_WHITE_FG}git${E_RESET} reset --hard
  abandon everything since your last commit; this command can be DANGEROUS.
  If merging has resulted in conflicts and you'd like to just forget about
  the merge, this command will do that.

${E_WHITE_FG}git${E_RESET} reset --hard ORIG_HEAD or ${E_WHITE_FG}git${E_RESET} reset --hard origin/master 
  undo your most recent *successful* merge *and* any changes that occurred
  after.  Useful for forgetting about the merge you just did.  If there are
  conflicts (the merge was not successful), use "${E_WHITE_FG}git${E_RESET} reset --hard" (above)
  instead.

${E_WHITE_FG}git${E_RESET} reset --soft HEAD^
  forgot something in your last commit? That's easy to fix. Undo your last
  commit, but keep the changes in the staging area for editing.

${E_WHITE_FG}git${E_RESET} commit --amend
  redo previous commit, including changes you've staged in the meantime.
  Also used to edit commit message of previous commit.


${E_CYAN_FG}Plumbing${E_RESET}
${E_CYAN_FG}--------${E_RESET}

test <sha1-A> = \$(${E_WHITE_FG}git${E_RESET} merge-base <sha1-A> <sha1-B>)
  determine if merging sha1-B into sha1-A is achievable as a fast forward;
  non-zero exit status is false.


${E_CYAN_FG}Stashing${E_RESET}
${E_CYAN_FG}--------${E_RESET}

${E_WHITE_FG}git${E_RESET} stash
${E_WHITE_FG}git${E_RESET} stash save <optional-name>
  save your local modifications to a new stash (so you can for example
  "${E_WHITE_FG}git${E_RESET} svn rebase" or "${E_WHITE_FG}git${E_RESET} pull")

${E_WHITE_FG}git${E_RESET} stash apply
  restore the changes recorded in the stash on top of the current working tree
  state

${E_WHITE_FG}git${E_RESET} stash pop
  restore the changes from the most recent stash, and remove it from the stack
  of stashed changes

${E_WHITE_FG}git${E_RESET} stash list
  list all current stashes

${E_WHITE_FG}git${E_RESET} stash show <stash-name> -p
  show the contents of a stash - accepts all diff args

${E_WHITE_FG}git${E_RESET} stash drop [<stash-name>]
  delete the stash

${E_WHITE_FG}git${E_RESET} stash clear
  delete all current stashes


${E_CYAN_FG}Remotes${E_RESET}
${E_CYAN_FG}-------${E_RESET}

${E_WHITE_FG}git${E_RESET} remote add <remote> <remote_URL>
  adds a remote repository to your ${E_WHITE_FG}git${E_RESET} config.  Can be then fetched locally.
  Example:
    ${E_WHITE_FG}git${E_RESET} remote add coreteam ${E_WHITE_FG}git${E_RESET}://${E_WHITE_FG}git${E_RESET}hub.com/wycats/merb-plugins.${E_WHITE_FG}git${E_RESET}
    ${E_WHITE_FG}git${E_RESET} fetch coreteam

${E_WHITE_FG}git${E_RESET} push <remote> :refs/heads/<branch>
  delete a branch in a remote repository

${E_WHITE_FG}git${E_RESET} push <remote> <remote>:refs/heads/<remote_branch>
  create a branch on a remote repository
  Example: ${E_WHITE_FG}git${E_RESET} push origin origin:refs/heads/new_feature_name

${E_WHITE_FG}git${E_RESET} push <repository> +<remote>:<new_remote>
  replace a <remote> branch with <new_remote>
  think twice before do this
  Example: ${E_WHITE_FG}git${E_RESET} push origin +master:my_branch

${E_WHITE_FG}git${E_RESET} remote prune <remote>
  prune deleted remote-tracking branches from "${E_WHITE_FG}git${E_RESET} branch -r" listing

${E_WHITE_FG}git${E_RESET} remote add -t master -m master origin ${E_WHITE_FG}git${E_RESET}://example.com/${E_WHITE_FG}git${E_RESET}.${E_WHITE_FG}git${E_RESET}/
  add a remote and track its master

${E_WHITE_FG}git${E_RESET} remote show <remote>
  show information about the remote server.

${E_WHITE_FG}git${E_RESET} checkout -b <local branch> <remote>/<remote branch>
  Eg ${E_WHITE_FG}git${E_RESET} checkout -b myfeature origin/myfeature
  Track a remote branch as a local branch.

${E_WHITE_FG}git${E_RESET} pull <remote> <branch>
${E_WHITE_FG}git${E_RESET} push
  For branches that are remotely tracked (via ${E_WHITE_FG}git${E_RESET} push) but
  that complain about non-fast forward commits when doing a
  ${E_WHITE_FG}git${E_RESET} push. The pull synchronizes local and remote, and if
  all goes well, the result is pushable.

${E_WHITE_FG}git${E_RESET} fetch <remote>
  Retrieves all branches from the remote repository. After
  this '${E_WHITE_FG}git${E_RESET} branch --track ...' can be used to track a branch
  from the new remote.

${E_CYAN_FG}Submodules${E_RESET}
${E_CYAN_FG}----------${E_RESET}

${E_WHITE_FG}git${E_RESET} submodule add <remote_repository> <path/to/submodule>
  add the given repository at the given path. The addition will be part of the
  next commit.

${E_WHITE_FG}git${E_RESET} submodule update [--init]
  Update the registered submodules (clone missing submodules, and checkout
  the commit specified by the super-repo). --init is needed the first time.

${E_WHITE_FG}git${E_RESET} submodule foreach <command>
  Executes the given command within each checked out submodule.

Removing submodules

   1. Delete the relevant line from the .${E_WHITE_FG}git${E_RESET}modules file.
   2. Delete the relevant section from .${E_WHITE_FG}git${E_RESET}/config.
   3. Run ${E_WHITE_FG}git${E_RESET} rm --cached path_to_submodule (no trailing slash).
   4. Commit and delete the now untracked submodule files.

Updating submodules
  To update a submodule to a new commit:
    1. update submodule:
        cd <path to submodule>
        ${E_WHITE_FG}git${E_RESET} pull
    2. commit the new version of submodule:
        cd <path to toplevel>
        ${E_WHITE_FG}git${E_RESET} commit -m "update submodule version"
    3. check that the submodule has the correct version
        ${E_WHITE_FG}git${E_RESET} submodule status
  If the update in the submodule is not committed in the
  main repository, it is lost and doing ${E_WHITE_FG}git${E_RESET} submodule
  update will revert to the previous version.

${E_CYAN_FG}Patches${E_RESET}
${E_CYAN_FG}-------${E_RESET}

${E_WHITE_FG}git${E_RESET} format-patch HEAD^
  Generate the last commit as a patch that can be applied on another
  clone (or branch) using '${E_WHITE_FG}git${E_RESET} am'. Format patch can also generate a
  patch for all commits using '${E_WHITE_FG}git${E_RESET} format-patch HEAD^ HEAD'
  All page files will be enumerated with a prefix, e.g. 0001 is the
  first patch.

${E_WHITE_FG}git${E_RESET} format-patch <Revision>^..<Revision>
  Generate a patch for a single commit. E.g.
    ${E_WHITE_FG}git${E_RESET} format-patch d8efce43099^..d8efce43099
  Revision does not need to be fully specified.

${E_WHITE_FG}git${E_RESET} am <patch file>
  Applies the patch file generated by format-patch.

${E_WHITE_FG}git${E_RESET} diff --no-prefix > patchfile
  Generates a patch file that can be applied using patch:
    patch -p0 < patchfile
  Useful for sharing changes without generating a ${E_WHITE_FG}git${E_RESET} commit.

${E_CYAN_FG}Tags
${E_CYAN_FG}----${E_RESET}

${E_WHITE_FG}git${E_RESET} tag -l
  Will list all tags defined in the repository.

${E_WHITE_FG}git${E_RESET} co <tag_name>
  Will checkout the code for a particular tag. After this you'll
  probably want to do: '${E_WHITE_FG}git${E_RESET} co -b <some branch name>' to define
  a branch. Any changes you now make can be committed to that
  branch and later merged.

${E_CYAN_FG}Archive${E_RESET}
${E_CYAN_FG}-------${E_RESET}

${E_WHITE_FG}git${E_RESET} archive master | tar -x -C /somewhere/else
  Will export expanded tree as tar archive at given path

${E_WHITE_FG}git${E_RESET} archive master | bzip2 > source-tree.tar.bz2
  Will export archive as bz2

${E_WHITE_FG}git${E_RESET} archive --format zip --output /full/path master
  Will export as zip

${E_CYAN_FG}Git Instaweb${E_RESET}
${E_CYAN_FG}------------${E_RESET}

${E_WHITE_FG}git${E_RESET} instaweb --httpd=webrick [--start | --stop | --restart]


${E_CYAN_FG}Environment Variables${E_RESET}
${E_CYAN_FG}---------------------${E_RESET}

GIT_AUTHOR_NAME, GIT_COMMITTER_NAME
  Your full name to be recorded in any newly created commits.  Overrides
  user.name in .${E_WHITE_FG}git${E_RESET}/config

GIT_AUTHOR_EMAIL, GIT_COMMITTER_EMAIL
  Your email address to be recorded in any newly created commits.  Overrides
  user.email in .${E_WHITE_FG}git${E_RESET}/config

GIT_DIR
  Location of the repository to use (for out of working directory repositories)

GIT_WORKING_TREE
  Location of the Working Directory - use with GIT_DIR to specifiy the working
  directory root
  or to work without being in the working directory at all.

${E_CYAN_FG}Merge vs Rebase${E_RESET}
${E_CYAN_FG}---------------${E_RESET}
 Merge: take all the changes in one branch and merge them into another branch in one big commit
Rebase: move the point at which I branched to a new starting point; the current state of master

When do you use either one?

Assuming you have created a branch for the purpose of developing a single feature,
and you want to incorporate those changes into master, you probably want MERGE
(you don't care about maintaining all of the interim commits).

A second scenario would be if you started doing some development and then another
developer made an unrelated change. You probably want REBASE to base your changes
on the current version in the repo while still retaining your individual commits.

${E_CYAN_FG}Feature Development${E_RESET}
${E_CYAN_FG}-------------------${E_RESET}
Git feature development workflow consists of these steps:
1. Pull to update your local master
2. Check out a feature branch
3. Do work in your feature branch, committing early and often
4. Rebase frequently to incorporate upstream changes
5. Interactive rebase (squash) your commits
6. Merge your changes with master
7. Push your changes to the upstream repo

While in your master branch (${E_WHITE_FG}git${E_RESET} checkout master), pull in the most recent changes.
Then, update your master to reflect the current state ot the upstream repo:

> ${E_WHITE_FG}git${E_RESET} pull origin master

Check out a feature branch to begin working:

> ${E_WHITE_FG}git${E_RESET} checkout -b <some-branch>

${E_CYAN_FG}Sync with upstream:${E_RESET}
${E_CYAN_FG}------------------------------------------------------------------------------------------${E_RESET}
(rebase frequently to prevent your branch from diverging significantly with upstream)

Method 1)

> ${E_WHITE_FG}git${E_RESET} fetch origin master
> ${E_WHITE_FG}git${E_RESET} rebase origin/master

An alternative method is to checkout master and pull but this method requires extra steps:

Method 2)

> ${E_WHITE_FG}git${E_RESET} checkout master
> ${E_WHITE_FG}git${E_RESET} pull
> ${E_WHITE_FG}git${E_RESET} checkout <some-branch>
> ${E_WHITE_FG}git${E_RESET} rebase master
${E_CYAN_FG}------------------------------------------------------------------------------------------${E_RESET}

Once work on the feature is complete, you will have a branch with a lot of small commits like:

- “adding a model and a migration”,
- “adding a controller and some views”,
- “oh crap - adding tests” and so on.

This is useful while developing but larger, incremental commits are easier to maintain.
We will use an interactive rebase to squash them together.
Also, squashing these commits together will allow us to pretend that we wrote the tests first :-)

We want the rebase to affect only the commits we’ve made to this branch,
not the commits that exist on the upstream.

To ensure that we only deal with the “local” commits...

> ${E_WHITE_FG}git${E_RESET} rebase -i origin/master

Git will display an editor window with a list of the commits to be modified, something like:

pick 3dcd585 Adding Comment model, migrations, spec
pick 9f5c362 Adding Comment controller, helper, spec
pick dcd4813 Adding Comment relationship with Post
pick 977a754 Comment belongs to a User
pick 9ea48e3 Comment form on Post show page

Now we tell ${E_WHITE_FG}git${E_RESET} what we to do. Change these lines to:

pick 3dcd585 Adding Comment model, migrations, spec
squash 9f5c362 Adding Comment controller, helper, spec
squash dcd4813 Adding Comment relationship with Post
squash 977a754 Comment belongs to a User
squash 9ea48e3 Comment form on Post show page

Save and close the file. This will squash these commits together into one commit
and present us with a new editor window where we can give the new commit a message.

We’ll enter a synopsis:

[<some-branch>] Summary of branch purpose


Now, save and close your editor. This commit is now ready to be merged back into master.
First rebase against any recent changes in the upstream.
Then merge your changes back into master:

> ${E_WHITE_FG}git${E_RESET} checkout master
> ${E_WHITE_FG}git${E_RESET} merge 3275-add-commenting

And finally, push your changes to the upstream:

> ${E_WHITE_FG}git${E_RESET} push origin master

tip_git_EOF
}

tip_linux () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_linux_EOF

SSH setup

TO CHANGE LISTENING PORT USING SOCKET

 mkdir -p /etc/systemd/system/ssh.socket.d
 cat >/etc/systemd/system/ssh.socket.d/listen.conf <<EOF
 [Socket]
 ListenStream=2222
 EOF

 * This makes sshd listen on port 2222 AND port 22.
 
 -- For sshd to listen to ONLY 2222 you need to do this --
 mkdir -p /etc/systemd/system/ssh.socket.d
 cat >/etc/systemd/system/ssh.socket.d/listen.conf <<EOF
 [Socket]
 ListenStream=
 ListenStream=2222
 EOF
 
TO DISABLE SOCKET AND REVERT TO LEGACY

 IF IT EXISTS - DELETE /etc/systemd/system/ssh.service.d/00-socket.conf
 FOLLOW WITH: systemctl daemon-reload

 Then the /etc/ssh/sshd_config works again with Ports and Addresses settings (sshd_config)

 PERHAPS NEEDED:
 systemctl disable --now ssh.socket
 systemctl enable --now ssh.service

 KEYS and PERMISSIONS
 1) HOME directory: 750 user:user
 2) ~/.ssh 700 user:user
 3) ssh-keygen -t rsa -b 4096 -f ~/.ssh/KEM-AS_rsa.key -C "KEM-AS rsa key"
 4) cat KEM-AS_rsa.key.pub >> authorized_keys

File perms:
-rw-r--r--  1 kmiller kmiller  740 07-27-23 16:20 authorized_keys (644)
-rw-r--r--  1 kmiller kmiller  740 07-27-23 15:56 KEM-AS_rsa.key.pub (644)
-rw-------  1 kmiller kmiller 3381 07-27-23 15:56 KEM-AS_rsa.key (600)
-rw-------  1 kmiller kmiller  978 07-27-23 16:05 known_hosts (600)

Add/Modify sshd_config
----------------------
Port 64000
PermitRootLogin no

Add to ssh_config
-----------------
Host KEM-AS
HostName 192.168.18.100
User kmiller
IdentityFile=~/.ssh/KEM-AS_rsa.key
Port 64000

Decode Interface Names
----------------------
Short form example
wlo1
wl     -- wireless
o      -- onboard
1      -- slot 1

eno1
en     -- ethernet
o      -- onboard
1      -- slot 1

Long form example:
enp3s0:

en     -- ethernet
  p3   -- bus number  (3)
    s0 -- slot number (0)

wlp2s0:

wl     -- wireless
  p2   -- bus number  (2)
    s0 -- slot number (0)


auto login config
-----------------
To enable auto-login from the command line:

edit: /etc/gdm3/custom.conf

Get the last field with cut:
i.e. /usr/local/bin
	echo \${PWD} | rev | cut -d'/' -f1 | rev
yields: bin

Skip N first lines in file
--------------------------
tail -n +N

Skip N last lines in file
-------------------------
head -n -N

Extract N middle lines in file
------------------------------
Use the head and the tail together

Show 51st to the 55th line

$ tail -n +51 numbers_en.txt | head -n 5
fifty-one     : 51
fifty-two     : 52
fifty-three   : 53
fifty-four    : 54
fifty-five    : 55

alternate method:
head -n 55 numbers_en.txt | tail -n 5
tip_linux_EOF
}

tip_mail () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_mail_EOF
Basic postfix installation steps

install bind9

create: /var/cache/bind/db.test

$ORIGIN kem-as.com.
$TTL 1D
@       IN SOA     ns1 root(
                1 ;serial
                1D ;refresh
                2H ;retry
                2W ;expire
                5H ;minimum
);
@       IN        NS ns1
ns1     IN        A 192.168.18.100
mail    IN        A 192.168.18.100
@       IN        MX 5 mail

#Add zone:
sudo named-checkzone test.com. /var/cache/bind/db.test

#Edit:
/etc/bind/named.conf.default-zones

izone "kem-as.com." {
       type master;
       file "db.test";
};

#Edit:
/etc/bind/named.conf.options

Uncomment forwaders
Modify to 8.8.8.8

#Restart:
sudo systemctl restart bind9

#Add user:
sudo usermod -aG mail $(whoami)

#Install postfix
Select Internet Site
Server: kem-as.com

#Install mailutils

#Test:
mail kmiller@kem-as.com
tip_mail_EOF
}

tip_mime () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_mime_EOF

${E_BOLD}
STEPS TO CREATE A NEW FILE ASSOCIATION
--------------------------------------${E_RESET}
1) create xml file: ${E_WHITE_FG}/usr/share/mime/application/sh3d.xml${E_RESET}
${E_CYAN_FG}
<?xml version="1.0"?>
<mime-info xmlns='http://www.freedesktop.org/standards/shared-mime-info'>
  <mime-type type="application/sh3d">
    <comment>SweetHome3D Files</comment>
    <generic-icon name="text-html"/>
    <glob pattern="*.sh3d"/>
  </mime-type>
</mime-info>${E_RESET}

${E_BOLD}
2) register mime type${E_RESET}
${E_WHITE_FG}
sudo xdg-mime install --novendor --mode system /usr/share/mime/application/sh3d.xml${E_RESET}

${E_BOLD}
3) associate mime type with app${E_RESET}
${E_WHITE_FG}
sudo xdg-mime default SweetHome3D.desktop application/sh3d${E_RESET}

${E_BOLD}
4) update mime database${E_RESET}
${E_WHITE_FG}
update-mime-database /usr/share/mime${E_RESET}

tip_mime_EOF
}

tip_nfs () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_nfs_EOF

${E_CYAN_FG}Command		Description${E_RESET}
mapadmin	Manage User Name Mapping for Microsoft Services for Network File System.
mount		Mount Network File System (NFS) network shares.
nfsadmin	Manage Server for NFS and Client for NFS.
nfsshare	Control Network File System (NFS) shares.
nfsstat		Display or reset counts of calls made to Server for NFS.
rpcinfo		List programs on remote computers.
showmount	Display mounted directories.
tip_nfs_EOF
}

tip_perl () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_perl_EOF_1

${E_WHITE_FG}Word is in KW:${E_RESET}
perl -nle "if (index('${KW}', \$_) == 0) { exit 0 } else { exit 1 }" <<<${ARG}

is_valid_keyword () {
	local ARG=\${1}
	local KW=\${2}

	perl -nle "if (index('${KW}', \$_) == 0) { exit 0 } else { exit 1 }" <<<\${ARG}
	return \${?}
}

${E_WHITE_FG}Print only matching:${E_RESET}
	perl -ne '/\w+\.\w+\$/ && print "\$&"' <<<\${ARG}

${E_WHITE_FG}Exit status on match
	perl -ne 'if ( /REGEX/ ) { exit(0) } else { exit(1) }' <<<\${ARG}

${E_WHITE_FG}Strip Options:${E_RESET}
	while true;do #strip options
		grep -q '\-' <<<${RAW_PATH}
		[[ \${?} -ne 0 ]] && break
		RAW_PATH=\$(echo \${RAW_PATH} \| perl -pe 's/(-\w+)\s+(.*)/\2/g')
	done

${E_WHITE_FG}Keyword Arguments:${E_RESET}
	Name each parameter in the call:

	thefunc(INCREMENT => "20s", START => "+5m", FINISH => "+30m");
	thefunc(START => "+5m", FINISH => "+30m");
	thefunc(FINISH => "+30m");
	thefunc(START => "+5m", INCREMENT => "15s");
	Then in the subroutine, create a hash loaded up with default values plus the array of named pairs.

	sub thefunc {
		 my %args = (
			  INCREMENT   => '10s',
			  FINISH      => 0,
			  START       => 0,
			  @_,         # argument pair list goes here
		 );
		 if (${args}{INCREMENT}  =~ /m$/ ) { ..... }
	}

${E_WHITE_FG}Passing vars to a shell command:${E_RESET}
	ROWS=\$(perl -n -e '\${count}++ if /'\${ACTION_PATTERN}'/; END { print \${count} }' ~/.zsh_history)

${E_WHITE_FG}Replace only first instance:${E_RESET}
    perl -pe '!${x} && s/((.* \(\)|function .*) {)/#Functions\n${1}/ && (${x}=1)' ${1}

${E_WHITE_FG}Regex escaping special chars:${E_RESET}
    perl -pi'.bak' -e 's/(.*dbg ")(\$\{0}:)?(\s+)?([\(\$A-Za-z_-])/\1\$\{0}:\${LINENO} \4/' <FILE>

${E_WHITE_FG}A simple filter:${E_RESET}
    perl -ne 'print if /REGEX/'

${E_WHITE_FG}Filter out blank lines (in place):${E_RESET}
    perl -i -ne'print if /\w/'

${E_WHITE_FG}Search and replace (in place):${E_RESET}
    perl -i -pe's/SEARCH/REPLACE/' 

${E_WHITE_FG}Add first and penultimate columns:${E_RESET}
    perl -lane 'print \${F}[0] + \${F}[-2]'

${E_WHITE_FG}Just lines 15 to 17:${E_RESET}
    perl -ne 'print if 15 .. 17' *.pod

${E_WHITE_FG}In-place edit of *.c files changing all foo to bar:${E_RESET}
    perl -p -i.bak -e 's/\bfoo\b/bar/g' *.c

${E_WHITE_FG}Command-line that prints the first 50 lines (cheaply):${E_RESET}
    perl -pe 'exit if $. > 50' f1 f2 f3 ...

${E_WHITE_FG}Delete first 10 lines:${E_RESET}
    perl -i.old -ne 'print unless 1 .. 10' foo.txt

${E_WHITE_FG}Change all the isolated oldvar occurrences to newvar:${E_RESET}
    perl -i.old -pe 's{\boldvar\b}{newvar}g' *.[chy]

${E_WHITE_FG}Command-line that reverses the whole file by lines:${E_RESET}
    perl -e 'print reverse <>' file1 file2 file3 ....

${E_WHITE_FG}Find palindromes:${E_RESET}
    perl -lne 'print if ${_} eq reverse' /usr/dict/words

${E_WHITE_FG}Command-line that reverse all the bytes in a file:${E_RESET}
    perl -0777e 'print scalar reverse <>' f1 f2 f3 ...

${E_WHITE_FG}Command-line that reverses the whole file by paragraphs:${E_RESET}
    perl -00 -e 'print reverse <>' file1 file2 file3 ....

${E_WHITE_FG}Increment all numbers found in these files:${E_RESET}
    perl i.tiny -pe 's/(\d+)/ 1 + ${1} /ge' file1 file2 ....

${E_WHITE_FG}Command-line that shows each line with its characters backwards:${E_RESET}
    perl -nle 'print scalar reverse ${_}' file1 file2 file3 ....

${E_WHITE_FG}Delete all but lines between START and END:${E_RESET}
    perl -i.old -ne 'print unless /^START$/ .. /^END$/' foo.txt

${E_WHITE_FG}Binary edit (careful!):${E_RESET}
    perl -i.bak -pe 's/Mozilla/Slopoke/g' /usr/local/bin/netscape

${E_WHITE_FG}Duplicate words:${E_RESET}
    perl -0777 -ne 'print "$.: doubled ${_}\n" while /\b(\w+)\b\s+\b\1\b/gi'

${E_WHITE_FG}Print the last 50 lines (expensive!):${E_RESET}
    perl -e '@lines = <>; print @lines[ ${#lines} .. ${#lines}-50' f1 f2 f3 ...

${E_WHITE_FG}Move files < 1000 bytes to DIR:${E_RESET}
    ls -l *xls | perl -na -F'/\s+/' -e 'print "\${F}[8]\n" if \${F}[4] < 1000' |
    xargs -J % mv % DIR

${E_WHITE_FG}Print 1st, 2nd, and last columns (use -l for auto-line-end processing):${E_RESET}
    perl -F"\t" -nlae'print join "\t", @F[0,1,-1]' 

${E_WHITE_FG}Print columns 1-20:${E_RESET}
    perl -F"\t" -nlae'print join "\t", @F[0..19]'

${E_WHITE_FG}Print all filenames & their line #s w/ pattern:${E_RESET}
    perl -ne'if (/PATTERN/) { print "\${ARGV:} $.\n" }; $. = 0 if eof'

${E_WHITE_FG}Print file up to some pattern:${E_RESET}
    perl -ne'if (/PATTERN/) { close ARGV } else { print }'

${E_WHITE_FG}Inclusive of line w/ pattern:${E_RESET}
    perl -pe'if (/PATTERN/) { close ARGV }'

${E_WHITE_FG}Delete columns of file after column N+2:${E_RESET}
    perl -i -F'\t' -nlae'print join "\t", @F[0..N]' 

${E_WHITE_FG}Insert new column after column N:${E_RESET}
    perl -i -F'\t' -nae'print join "\t", @F[0..N], "new", @F[N+1..${#F}]'

${E_WHITE_FG}Cut files in dir at pattern & omit blank lines:${E_RESET}
    perl -i -ne 'if (/PATTERN/) { close ARGV } else { print unless /^$/ }'

${E_WHITE_FG}Insert line numbers in a file:${E_RESET}
    perl -i -ne 'printf "%04d %s", $., ${_}'

${E_WHITE_FG}Insert text at line N:${E_RESET}
    perl -i -pe 'print "text\n" if $. == N; $. = 0 if eof'

${E_WHITE_FG}Print filenames of files containing pattern in first N lines:${E_RESET}
    perl -n -e 'if (/PATTERN/) { print "\${ARGV}\n"; close ARGV }' 
            -e 'close \${ARGV} if $. = N'

${E_WHITE_FG}Return part of select filenames:${E_RESET}
    perl -ne '\${ARGV} =~ /^(.*)\.TXT$/; print "$&\n"; close ARGV'

${E_WHITE_FG}Add columns M thru N and insert total:${E_RESET}
    perl -F'\t' -nlae '${t}=0; ${t} += ${_} for @F[M..N]; print "${_}\t${t}" '

${E_WHITE_FG}Replace pattern on first line of each file:${E_RESET}
    perl -i -pe'
        ${new} = 1; 
        s/PATTERN/REPLACE/ if ${new}; 
        ${new} = eof(ARGV) ? 1 : 0'
tip_perl_EOF_1
cat << "tip_perl_EOF_2"

Command line switches
---------------------
SYNOPSIS
    perl [ -sTtuUWX ] [ -hv ] [ -V[:*configvar*] ]
    [ -cw ] [ -d[t][:*debugger*] ] [ -D[*number/list*] ]
    [ -pna ] [ -F*pattern* ] [ -l[*octal*] ] [ -0[*octal/hexadecimal*] ]
    [ -I*dir* ] [ -m[-]*module* ] [ -M[-]*'module...'* ] [ -f ]
    [ -C [*number/list*] ] [ -S ] [ -x[*dir*] ] [ -i[*extension*] ]
    [ [-e|-E] *'command'* ] [ -- ] [ *programfile* ] [ *argument* ]...

) | less -R
  Command Switches
    As with all standard commands, a single-character switch may be
    clustered with the following switch, if any.

        #!/usr/bin/perl -spi.orig   # same as -s -p -i.orig

    A "--" signals the end of options and disables further option
    processing. Any arguments after the "--" are treated as filenames and
    arguments.

    Switches include:

    -0[*octal/hexadecimal*]
         specifies the input record separator ($/) as an octal or
         hexadecimal number. If there are no digits, the null character is
         the separator. Other switches may precede or follow the digits. For
         example, if you have a version of *find* which can print filenames
         terminated by the null character, you can say this:

             find . -name '*.orig' -print0 | perl -n0e unlink

         The special value 00 will cause Perl to slurp files in paragraph
         mode. Any value 0400 or above will cause Perl to slurp files whole,
         but by convention the value 0777 is the one normally used for this
         purpose.

         You can also specify the separator character using hexadecimal
         notation: -0x*HHH...*, where the "*H*" are valid hexadecimal
         digits. Unlike the octal form, this one may be used to specify any
         Unicode character, even those beyond 0xFF. So if you *really* want
         a record separator of 0777, specify it as -0x1FF. (This means that
         you cannot use the "-x" option with a directory name that consists
         of hexadecimal digits, or else Perl will think you have specified a
         hex number to -0.)

    -a   turns on autosplit mode when used with a "-n" or "-p". An implicit
         split command to the @F array is done as the first thing inside the
         implicit while loop produced by the "-n" or "-p".

             perl -ane 'print pop(@F), "\n";'

         is equivalent to

             while (<>) {
                 @F = split(' ');
                 print pop(@F), "\n";
             }

         An alternate delimiter may be specified using -F.

         -a implicitly sets "-n".

    -C [*number/list*]
         The -C flag controls some of the Perl Unicode features.

         As of 5.8.1, the -C can be followed either by a number or a list of
         option letters. The letters, their numeric values, and effects are
         as follows; listing the letters is equal to summing the numbers.

             I     1   STDIN is assumed to be in UTF-8
             O     2   STDOUT will be in UTF-8
             E     4   STDERR will be in UTF-8
             S     7   I + O + E
             i     8   UTF-8 is the default PerlIO layer for input streams
             o    16   UTF-8 is the default PerlIO layer for output streams
             D    24   i + o
             A    32   the @ARGV elements are expected to be strings encoded
                       in UTF-8
             L    64   normally the "IOEioA" are unconditional, the L makes
                       them conditional on the locale environment variables
                       (the LC_ALL, LC_CTYPE, and LANG, in the order of
                       decreasing precedence) -- if the variables indicate
                       UTF-8, then the selected "IOEioA" are in effect
             a   256   Set ${^UTF8CACHE} to -1, to run the UTF-8 caching
                       code in debugging mode.

         For example, -COE and -C6 will both turn on UTF-8-ness on both
         STDOUT and STDERR. Repeating letters is just redundant, not
         cumulative nor toggling.

         The "io" options mean that any subsequent open() (or similar I/O
         operations) in main program scope will have the ":utf8" PerlIO
         layer implicitly applied to them, in other words, UTF-8 is expected
         from any input stream, and UTF-8 is produced to any output stream.
         This is just the default set via "${^OPEN}", with explicit layers
         in open() and with binmode() one can manipulate streams as usual.
         This has no effect on code run in modules.

         -C on its own (not followed by any number or option list), or the
         empty string "" for the "PERL_UNICODE" environment variable, has
         the same effect as -CSDL. In other words, the standard I/O handles
         and the default "open()" layer are UTF-8-fied *but* only if the
         locale environment variables indicate a UTF-8 locale. This
         behaviour follows the *implicit* (and problematic) UTF-8 behaviour
         of Perl 5.8.0. (See "UTF-8 no longer default under UTF-8 locales"
         in perl581delta.)

         You can use -C0 (or "0" for "PERL_UNICODE") to explicitly disable
         all the above Unicode features.

         The read-only magic variable "${^UNICODE}" reflects the numeric
         value of this setting. This variable is set during Perl startup and
         is thereafter read-only. If you want runtime effects, use the
         three-arg open() (see "open" in perlfunc), the two-arg binmode()
         (see "binmode" in perlfunc), and the "open" pragma (see open).

         (In Perls earlier than 5.8.1 the -C switch was a Win32-only switch
         that enabled the use of Unicode-aware "wide system call" Win32
         APIs. This feature was practically unused, however, and the command
         line switch was therefore "recycled".)

         Note: Since perl 5.10.1, if the -C option is used on the "#!" line,
         it must be specified on the command line as well, since the
         standard streams are already set up at this point in the execution
         of the perl interpreter. You can also use binmode() to set the
         encoding of an I/O stream.

    -c   causes Perl to check the syntax of the program and then exit
         without executing it. Actually, it *will* execute any "BEGIN",
         "UNITCHECK", or "CHECK" blocks and any "use" statements: these are
         considered as occurring outside the execution of your program.
         "INIT" and "END" blocks, however, will be skipped.

    -d
    -dt  runs the program under the Perl debugger. See perldebug. If t is
         specified, it indicates to the debugger that threads will be used
         in the code being debugged.
    -d:*MOD[=bar,baz]*
    -dt:*MOD[=bar,baz]*
         runs the program under the control of a debugging, profiling, or
         tracing module installed as "Devel::*MOD*". E.g., -d:DProf executes
         the program using the "Devel::DProf" profiler. As with the -M flag,
         options may be passed to the "Devel::*MOD*" package where they will
         be received and interpreted by the "Devel::*MOD*::import" routine.
         Again, like -M, use --d:-*MOD* to call "Devel::*MOD*::unimport"
         instead of import. The comma-separated list of options must follow
         a "=" character. If t is specified, it indicates to the debugger
         that threads will be used in the code being debugged. See
         perldebug.

    -D*letters*
    -D*number*
         sets debugging flags. This switch is enabled only if your perl
         binary has been built with debugging enabled: normal production
         perls won't have been.

         For example, to watch how perl executes your program, use -Dtls.
         Another nice value is -Dx, which lists your compiled syntax tree,
         and -Dr displays compiled regular expressions; the format of the
         output is explained in perldebguts.

         As an alternative, specify a number instead of list of letters
         (e.g., -D14 is equivalent to -Dtls):

                  1  p  Tokenizing and parsing (with v, displays parse
                        stack)
                  2  s  Stack snapshots (with v, displays all stacks)
                  4  l  Context (loop) stack processing
                  8  t  Trace execution
                 16  o  Method and overloading resolution
                 32  c  String/numeric conversions
                 64  P  Print profiling info, source file input state
                128  m  Memory and SV allocation
                256  f  Format processing
                512  r  Regular expression parsing and execution
               1024  x  Syntax tree dump
               2048  u  Tainting checks
               4096  U  Unofficial, User hacking (reserved for private,
                        unreleased use)
              16384  X  Scratchpad allocation
              32768  D  Cleaning up
              65536  S  Op slab allocation
             131072  T  Tokenizing
             262144  R  Include reference counts of dumped variables
                        (eg when using -Ds)
             524288  J  show s,t,P-debug (don't Jump over) on opcodes within
                        package DB
            1048576  v  Verbose: use in conjunction with other flags to
                        increase the verbosity of the output.  Is a no-op on
                        many of the other flags
            2097152  C  Copy On Write
            4194304  A  Consistency checks on internal structures
            8388608  q  quiet - currently only suppresses the "EXECUTING"
                        message
           16777216  M  trace smart match resolution
           33554432  B  dump suBroutine definitions, including special
                        Blocks like BEGIN
           67108864  L  trace Locale-related info; what gets output is very
                        subject to change
          134217728  i  trace PerlIO layer processing.  Set PERLIO_DEBUG to
                        the filename to trace to.
          268435456  y  trace y///, tr/// compilation and execution

         All these flags require -DDEBUGGING when you compile the Perl
         executable (but see ":opd" in Devel::Peek or "'debug' mode" in re
         which may change this). See the INSTALL file in the Perl source
         distribution for how to do this.

         If you're just trying to get a print out of each line of Perl code
         as it executes, the way that "sh -x" provides for shell scripts,
         you can't use Perl's -D switch. Instead do this

           # If you have "env" utility
           env PERLDB_OPTS="NonStop=1 AutoTrace=1 frame=2" perl -dS program

           # Bourne shell syntax
           $ PERLDB_OPTS="NonStop=1 AutoTrace=1 frame=2" perl -dS program

           # csh syntax
           % (setenv PERLDB_OPTS "NonStop=1 AutoTrace=1 frame=2"; perl -dS program)

         See perldebug for details and variations.

    -e *commandline*
         may be used to enter one line of program. If -e is given, Perl will
         not look for a filename in the argument list. Multiple -e commands
         may be given to build up a multi-line script. Make sure to use
         semicolons where you would in a normal program.

    -E *commandline*
         behaves just like -e, except that it implicitly enables all
         optional features (in the main compilation unit). See feature.

    -f   Disable executing ${Config}{sitelib}/sitecustomize.pl at startup.

         Perl can be built so that it by default will try to execute
         ${Config}{sitelib}/sitecustomize.pl at startup (in a BEGIN block).
         This is a hook that allows the sysadmin to customize how Perl
         behaves. It can for instance be used to add entries to the @INC
         array to make Perl find modules in non-standard locations.

         Perl actually inserts the following code:

             BEGIN {
                 do { local $!; -f "${Config}{sitelib}/sitecustomize.pl"; }
                     && do "${Config}{sitelib}/sitecustomize.pl";
             }

         Since it is an actual "do" (not a "require"), sitecustomize.pl
         doesn't need to return a true value. The code is run in package
         "main", in its own lexical scope. However, if the script dies, ${@}
         will not be set.

         The value of ${Config}{sitelib} is also determined in C code and not
         read from "Config.pm", which is not loaded.

         The code is executed *very* early. For example, any changes made to
         @INC will show up in the output of 'perl -V'. Of course, "END"
         blocks will be likewise executed very late.

         To determine at runtime if this capability has been compiled in
         your perl, you can check the value of ${Config}{usesitecustomize}.

    -F*pattern*
         specifies the pattern to split on for "-a". The pattern may be
         surrounded by "//", "", or '', otherwise it will be put in single
         quotes. You can't use literal whitespace or NUL characters in the
         pattern.

         -F implicitly sets both "-a" and "-n".

    -h   prints a summary of the options.

    -i[*extension*]
         specifies that files processed by the "<>" construct are to be
         edited in-place. It does this by renaming the input file, opening
         the output file by the original name, and selecting that output
         file as the default for print() statements. The extension, if
         supplied, is used to modify the name of the old file to make a
         backup copy, following these rules:

         If no extension is supplied, and your system supports it, the
         original *file* is kept open without a name while the output is
         redirected to a new file with the original *filename*. When perl
         exits, cleanly or not, the original *file* is unlinked.

         If the extension doesn't contain a "*", then it is appended to the
         end of the current filename as a suffix. If the extension does
         contain one or more "*" characters, then each "*" is replaced with
         the current filename. In Perl terms, you could think of this as:

             (${backup} = ${extension}) =~ s/\*/${file_name}/g;

         This allows you to add a prefix to the backup file, instead of (or
         in addition to) a suffix:

          $ perl -pi'orig_*' -e 's/bar/baz/' fileA  # backup to
                                                    # 'orig_fileA'

         Or even to place backup copies of the original files into another
         directory (provided the directory already exists):

          $ perl -pi'old/*.orig' -e 's/bar/baz/' fileA  # backup to
                                                        # 'old/fileA.orig'

         These sets of one-liners are equivalent:

          $ perl -pi -e 's/bar/baz/' fileA          # overwrite current file
          $ perl -pi'*' -e 's/bar/baz/' fileA       # overwrite current file

          $ perl -pi'.orig' -e 's/bar/baz/' fileA   # backup to 'fileA.orig'
          $ perl -pi'*.orig' -e 's/bar/baz/' fileA  # backup to 'fileA.orig'

         From the shell, saying

             $ perl -p -i.orig -e "s/foo/bar/; ... "

         is the same as using the program:

             #!/usr/bin/perl -pi.orig
             s/foo/bar/;

         which is equivalent to

             #!/usr/bin/perl
             ${extension} = '.orig';
             LINE: while (<>) {
                 if (${ARGV} ne ${oldargv}) {
                     if (${extension} !~ /\*/) {
                         ${backup} = ${ARGV} . ${extension};
                     }
                     else {
                         (${backup} = ${extension}) =~ s/\*/${ARGV}/g;
                     }
                     rename(${ARGV}, ${backup});
                     open(ARGVOUT, ">${ARGV}");
                     select(ARGVOUT);
                     ${oldargv} = ${ARGV};
                 }
                 s/foo/bar/;
             }
             continue {
                 print;  # this prints to original filename
             }
             select(STDOUT);

         except that the -i form doesn't need to compare ${ARGV} to ${oldargv}
         to know when the filename has changed. It does, however, use
         ARGVOUT for the selected filehandle. Note that STDOUT is restored
         as the default output filehandle after the loop.

         As shown above, Perl creates the backup file whether or not any
         output is actually changed. So this is just a fancy way to copy
         files:

             $ perl -p -i'/some/file/path/*' -e 1 file1 file2 file3...
         or
             $ perl -p -i'.orig' -e 1 file1 file2 file3...

         You can use "eof" without parentheses to locate the end of each
         input file, in case you want to append to each file, or reset line
         numbering (see example in "eof" in perlfunc).

         If, for a given file, Perl is unable to create the backup file as
         specified in the extension then it will skip that file and continue
         on with the next one (if it exists).

         For a discussion of issues surrounding file permissions and -i, see
         "Why does Perl let me delete read-only files? Why does -i clobber
         protected files? Isn't this a bug in Perl?" in perlfaq5.

         You cannot use -i to create directories or to strip extensions from
         files.

         Perl does not expand "~" in filenames, which is good, since some
         folks use it for their backup files:

             $ perl -pi~ -e 's/foo/bar/' file1 file2 file3...

         Note that because -i renames or deletes the original file before
         creating a new file of the same name, Unix-style soft and hard
         links will not be preserved.

         Finally, the -i switch does not impede execution when no files are
         given on the command line. In this case, no backup is made (the
         original file cannot, of course, be determined) and processing
         proceeds from STDIN to STDOUT as might be expected.

    -I*directory*
         Directories specified by -I are prepended to the search path for
         modules (@INC).

    -l[*octnum*]
         enables automatic line-ending processing. It has two separate
         effects. First, it automatically chomps $/ (the input record
         separator) when used with "-n" or "-p". Second, it assigns $\ (the
         output record separator) to have the value of *octnum* so that any
         print statements will have that separator added back on. If
         *octnum* is omitted, sets $\ to the current value of $/. For
         instance, to trim lines to 80 columns:

             perl -lpe 'substr(${_}, 80) = ""'

         Note that the assignment "$\ = $/" is done when the switch is
         processed, so the input record separator can be different than the
         output record separator if the -l switch is followed by a -0
         switch:

             gnufind / -print0 | perl -ln0e 'print "found ${_}" if -p'

         This sets $\ to newline and then sets $/ to the null character.

    -m[-]*module*
    -M[-]*module*
    -M[-]*'module ...'*
    -[mM][-]*module=arg[,arg]...*
         -m*module* executes "use" *module* "();" before executing your
         program. This loads the module, but does not call its "import"
         method, so does not import subroutines and does not give effect to
         a pragma.

         -M*module* executes "use" *module* ";" before executing your
         program. This loads the module and calls its "import" method,
         causing the module to have its default effect, typically importing
         subroutines or giving effect to a pragma. You can use quotes to add
         extra code after the module name, e.g., '-M*MODULE* qw(foo bar)'.

         If the first character after the -M or -m is a dash (-) then the
         'use' is replaced with 'no'. This makes no difference for -m.

         A little builtin syntactic sugar means you can also say
         -m*MODULE*=foo,bar or -M*MODULE*=foo,bar as a shortcut for
         '-M*MODULE* qw(foo bar)'. This avoids the need to use quotes when
         importing symbols. The actual code generated by -M*MODULE*=foo,bar
         is "use module split(/,/,q{foo,bar})". Note that the "=" form
         removes the distinction between -m and -M; that is,
         -m*MODULE*=foo,bar is the same as -M*MODULE*=foo,bar.

         A consequence of the "split" formulation is that -M*MODULE*=number
         never does a version check, unless "*MODULE*::import()" itself is
         set up to do a version check, which could happen for example if
         *MODULE* inherits from Exporter.

    -n   causes Perl to assume the following loop around your program, which
         makes it iterate over filename arguments somewhat like *sed -n* or
         *awk*:

           LINE:
             while (<>) {
                 ...             # your program goes here
             }

         Note that the lines are not printed by default. See "-p" to have
         lines printed. If a file named by an argument cannot be opened for
         some reason, Perl warns you about it and moves on to the next file.

         Also note that "<>" passes command line arguments to "open" in
         perlfunc, which doesn't necessarily interpret them as file names.
         See perlop for possible security implications.

         Here is an efficient way to delete all files that haven't been
         modified for at least a week:

             find . -mtime +7 -print | perl -nle unlink

         This is faster than using the -exec switch of *find* because you
         don't have to start a process on every filename found (but it's not
         faster than using the -delete switch available in newer versions of
         *find*. It does suffer from the bug of mishandling newlines in
         pathnames, which you can fix if you follow the example under -0.

         "BEGIN" and "END" blocks may be used to capture control before or
         after the implicit program loop, just as in *awk*.

    -p   causes Perl to assume the following loop around your program, which
         makes it iterate over filename arguments somewhat like *sed*:

           LINE:
             while (<>) {
                 ...             # your program goes here
             } continue {
                 print or die "-p destination: $!\n";
             }

         If a file named by an argument cannot be opened for some reason,
         Perl warns you about it, and moves on to the next file. Note that
         the lines are printed automatically. An error occurring during
         printing is treated as fatal. To suppress printing use the "-n"
         switch. A -p overrides a -n switch.

         "BEGIN" and "END" blocks may be used to capture control before or
         after the implicit loop, just as in *awk*.

    -s   enables rudimentary switch parsing for switches on the command line
         after the program name but before any filename arguments (or before
         an argument of --). Any switch found there is removed from @ARGV
         and sets the corresponding variable in the Perl program. The
         following program prints "1" if the program is invoked with a -xyz
         switch, and "abc" if it is invoked with -xyz=abc.

             #!/usr/bin/perl -s
             if (${xyz}) { print "${xyz}\n" }

         Do note that a switch like --help creates the variable "${-help}",
         which is not compliant with "use strict "refs"". Also, when using
         this option on a script with warnings enabled you may get a lot of
         spurious "used only once" warnings.

    -S   makes Perl use the "PATH" environment variable to search for the
         program unless the name of the program contains path separators.

         On some platforms, this also makes Perl append suffixes to the
         filename while searching for it. For example, on Win32 platforms,
         the ".bat" and ".cmd" suffixes are appended if a lookup for the
         original name fails, and if the name does not already end in one of
         those suffixes. If your Perl was compiled with "DEBUGGING" turned
         on, using the -Dp switch to Perl shows how the search progresses.

         Typically this is used to emulate "#!" startup on platforms that
         don't support "#!". It's also convenient when debugging a script
         that uses "#!", and is thus normally found by the shell's ${PATH}
         search mechanism.

         This example works on many platforms that have a shell compatible
         with Bourne shell:

             #!/usr/bin/perl
             eval 'exec /usr/bin/perl -wS ${0} ${1+"${@}"}'
                     if ${running_under_some_shell};

         The system ignores the first line and feeds the program to /bin/sh,
         which proceeds to try to execute the Perl program as a shell
         script. The shell executes the second line as a normal shell
         command, and thus starts up the Perl interpreter. On some systems
         ${0} doesn't always contain the full pathname, so the "-S" tells Perl
         to search for the program if necessary. After Perl locates the
         program, it parses the lines and ignores them because the variable
         ${running_under_some_shell} is never true. If the program will be
         interpreted by csh, you will need to replace "${1+"${@}"}" with $*,
         even though that doesn't understand embedded spaces (and such) in
         the argument list. To start up *sh* rather than *csh*, some systems
         may have to replace the "#!" line with a line containing just a
         colon, which will be politely ignored by Perl. Other systems can't
         control that, and need a totally devious construct that will work
         under any of *csh*, *sh*, or Perl, such as the following:

                 eval '(exit ${?0})' && eval 'exec perl -wS ${0} ${1+"${@}"}'
                 & eval 'exec /usr/bin/perl -wS ${0} ${argv:q}'
                         if ${running_under_some_shell};

         If the filename supplied contains directory separators (and so is
         an absolute or relative pathname), and if that file is not found,
         platforms that append file extensions will do so and try to look
         for the file with those extensions added, one by one.

         On DOS-like platforms, if the program does not contain directory
         separators, it will first be searched for in the current directory
         before being searched for on the PATH. On Unix platforms, the
         program will be searched for strictly on the PATH.

    -t   Like "-T", but taint checks will issue warnings rather than fatal
         errors. These warnings can now be controlled normally with "no
         warnings qw(taint)".

         Note: This is not a substitute for "-T"! This is meant to be used
         *only* as a temporary development aid while securing legacy code:
         for real production code and for new secure code written from
         scratch, always use the real "-T".

    -T   turns on "taint" so you can test them. Ordinarily these checks are
         done only when running setuid or setgid. It's a good idea to turn
         them on explicitly for programs that run on behalf of someone else
         whom you might not necessarily trust, such as CGI programs or any
         internet servers you might write in Perl. See perlsec for details.
         For security reasons, this option must be seen by Perl quite early;
         usually this means it must appear early on the command line or in
         the "#!" line for systems which support that construct.

    -u   This switch causes Perl to dump core after compiling your program.
         You can then in theory take this core dump and turn it into an
         executable file by using the *undump* program (not supplied). This
         speeds startup at the expense of some disk space (which you can
         minimize by stripping the executable). (Still, a "hello world"
         executable comes out to about 200K on my machine.) If you want to
         execute a portion of your program before dumping, use the
         "CORE::dump()" function instead. Note: availability of *undump* is
         platform specific and may not be available for a specific port of
         Perl.

    -U   allows Perl to do unsafe operations. Currently the only "unsafe"
         operations are attempting to unlink directories while running as
         superuser and running setuid programs with fatal taint checks
         turned into warnings. Note that warnings must be enabled along with
         this option to actually *generate* the taint-check warnings.

    -v   prints the version and patchlevel of your perl executable.

    -V   prints summary of the major perl configuration values and the
         current values of @INC.

    -V:*configvar*
         Prints to STDOUT the value of the named configuration variable(s),
         with multiples when your "*configvar*" argument looks like a regex
         (has non-letters). For example:

             $ perl -V:libc
                 libc='/lib/libc-2.2.4.so';
             $ perl -V:lib.
                 libs='-lnsl -lgdbm -ldb -ldl -lm -lcrypt -lutil -lc';
                 libc='/lib/libc-2.2.4.so';
             $ perl -V:lib.*
                 libpth='/usr/local/lib /lib /usr/lib';
                 libs='-lnsl -lgdbm -ldb -ldl -lm -lcrypt -lutil -lc';
                 lib_ext='.a';
                 libc='/lib/libc-2.2.4.so';
                 libperl='libperl.a';
                 ....

         Additionally, extra colons can be used to control formatting. A
         trailing colon suppresses the linefeed and terminator ";", allowing
         you to embed queries into shell commands. (mnemonic: PATH separator
         ":".)

             $ echo "compression-vars: " 'perl -V:z.*: ' " are here !"
             compression-vars:  zcat='' zip='zip'  are here !

         A leading colon removes the "name=" part of the response, this
         allows you to map to the name you need. (mnemonic: empty label)

             $ echo "goodvfork="'./perl -Ilib -V::usevfork'
             goodvfork=false;

         Leading and trailing colons can be used together if you need
         positional parameter values without the names. Note that in the
         case below, the "PERL_API" params are returned in alphabetical
         order.

             $ echo building_on 'perl -V::osname: -V::PERL_API_.*:' now
             building_on 'linux' '5' '1' '9' now

    -w   prints warnings about dubious constructs, such as variable names
         mentioned only once and scalar variables used before being set;
         redefined subroutines; references to undefined filehandles;
         filehandles opened read-only that you are attempting to write on;
         values used as a number that don't *look* like numbers; using an
         array as though it were a scalar; if your subroutines recurse more
         than 100 deep; and innumerable other things.

         This switch really just enables the global $^W variable; normally,
         the lexically scoped "use warnings" pragma is preferred. You can
         disable or promote into fatal errors specific warnings using
         "__WARN__" hooks, as described in perlvar and "warn" in perlfunc.
         See also perldiag and perltrap. A fine-grained warning facility is
         also available if you want to manipulate entire classes of
         warnings; see warnings.

    -W   Enables all warnings regardless of "no warnings" or $^W. See
         warnings.

    -X   Disables all warnings regardless of "use warnings" or $^W. See
         warnings.

         Forbidden in ""PERL5OPT"".

    -x
    -x*directory*
         tells Perl that the program is embedded in a larger chunk of
         unrelated text, such as in a mail message. Leading garbage will be
         discarded until the first line that starts with "#!" and contains
         the string "perl". Any meaningful switches on that line will be
         applied.

         All references to line numbers by the program (warnings, errors,
         ...) will treat the "#!" line as the first line. Thus a warning on
         the 2nd line of the program, which is on the 100th line in the file
         will be reported as line 2, not as line 100. This can be overridden
         by using the "#line" directive. (See "Plain Old Comments (Not!)" in
         perlsyn)

         If a directory name is specified, Perl will switch to that
         directory before running the program. The -x switch controls only
         the disposal of leading garbage. The program must be terminated
         with "__END__" if there is trailing garbage to be ignored; the
         program can process any or all of the trailing garbage via the
         "DATA" filehandle if desired.

         The directory, if specified, must appear immediately following the
         -x with no intervening whitespace.
tip_perl_EOF_2
}

tip_printf () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_printf_EOF


A ‘printf’ cheat sheet
 
${E_WHITE_FG}Format Specifiers${E_RESET}
${E_GREEN_FG}-----------------${E_RESET}
   %c character
   %d decimal (integer) number (base 10)
   %e exponential floating-point number
   %f floating-point number
   %i integer (base 10)
   %o octal number (base 8)
   %s a string of characters
   %u unsigned decimal (integer) number
   %x number in hexadecimal (base 16)
   %% print a percent sign
   \% print a percent sign

${E_WHITE_FG}Integer Width${E_RESET}
${E_GREEN_FG}-------------${E_RESET}
   The width specifier is used with integers. Default: right-justified.

   printf("%3d", 0);          0
   printf("%3d", 123456789);  123456789
   printf("%3d", -10);        -10
   printf("%3d", -123456789); -123456789

${E_WHITE_FG}Integer Left-Justifying${E_RESET}
${E_GREEN_FG}-----------------------${E_RESET}
   Left-justify integer, add minus sign (-) after the % symbol.

   printf("%-3d", 0);          0
   printf("%-3d", 123456789);  123456789
   printf("%-3d", -10);        -10
   printf("%-3d", -123456789); -123456789

${E_WHITE_FG}Integer Zero-Fill${E_RESET}
${E_GREEN_FG}-----------------${E_RESET}
   Zero-Fill integer output, add zero (0) after the % symbol.

   printf("%03d", 0);          000
   printf("%03d", 1);          001
   printf("%03d", 123456789);  123456789
   printf("%03d", -10);        -10
   printf("%03d", -123456789); -123456789

${E_WHITE_FG}Integer Formatting${E_RESET}
${E_GREEN_FG}------------------${E_RESET}
   Collection of integer formatting examples. Minimum width, left-justified, zero-filled, plus sign for positive numbers.

   Description                          Code                   Result
   ------------------------------------------------------------------
   At least five wide                   printf("'%5d'", 10);   '   10'
   At least five-wide, left-justified   printf("'%-5d'", 10);  '10   '
   At least five-wide, zero-filled      printf("'%05d'", 10);  '00010'
   At least five-wide, with a plus sign printf("'%+5d'", 10);  '  +10'
   Five-wide, plus sign, left-justified printf("'%-+5d'", 10); '+10  '

${E_WHITE_FG}Floating Point Formatting${E_RESET}
${E_GREEN_FG}-------------------------${E_RESET}
   Format Floating-point numbers.

   Description                                                 Code                                Result
   ------------------------------------------------------------------------------------------------------
   Print one position after the decimal                        printf("'%.1f'", 10.3456);          '10.3'
   Two positions after the decimal                             printf("'%.2f'", 10.3456);          '10.35'
   Eight-wide, two positions after the decimal                 printf("'%8.2f'", 10.3456);         '   10.35'
   Eight-wide, four positions after the decimal                printf("'%8.4f'", 10.3456);         ' 10.3456'
   Eight-wide, two positions after the decimal, zero-filled    printf("'%08.2f'", 10.3456);        '00010.35'
   Eight-wide, two positions after the decimal, left-justified printf("'%-8.2f'", 10.3456);        '10.35   '
   Printing a much larger number with that same format         printf("'%-8.2f'", 101234567.3456); '101234567.35'

${E_WHITE_FG}String Formatting${E_RESET}
${E_GREEN_FG}-----------------${E_RESET}
   To right justify text:
   1) Assign value to var with spaces embedded: LBL1="     Title", VAL="value"
   2) Quote the value to printf: printf "%s: %s\n" \${LBL1:q} \${VAL}
   3) Result:      Title: value

   Otherwise, printf will ignore leading space regardless of width specified...

   Format String Output.    

   Description                    Code                        Result
   -----------------------------------------------------------------
   A simple string                printf("'%s'", "Hello");    'Hello'
   A string with a minimum length printf("'%10s'", "Hello");  '     Hello'
   Minimum length, left-justified printf("'%-10s'", "Hello"); 'Hello     '
   Truncate: add a '.' after '%': %.25 will truncate past 25 chars...

${E_WHITE_FG}Special Characters${E_RESET}
${E_GREEN_FG}------------------${E_RESET}
   The following character sequences used as printf format specifiers:

   \a audible alert
   \b backspace
   \f form feed
   \n newline, or linefeed
   \r carriage return
   \t tab
   \v vertical tab
   \\ backslash 

${E_WHITE_FG}Printf Tricks${E_RESET}
${E_GREEN_FG}-------------${E_RESET}
${E_WHITE_FG}Runtime Width Specifier${E_RESET}
To calculate the width at runtime, use %*.  This says the next argument is the ${E_WHITE_FG}WIDTH${E_RESET}, followed by ${E_WHITE_FG}VALUE${E_RESET}.
Ex:${E_WHITE_FG}printf "%*d\n" 5 10 ${E_RESET}-> prints a "10" with a width of 5

${E_WHITE_FG}Leading Substrings${E_RESET}
%.*s  -> print a substring
With a variable precision, you can print a substring, or print a non-NUL-terminated string, if you
know its length. printf("%.*s\n", sublen, str) prints the first sublen characters of str.

Syntax: A '.' (period) in a printf format specification is FOLLOWED BY THE PRECISION
For STRINGS, the precision specificies HOW MANY CHARACTERS will be printed
A precision of '*' indicates that the precision is the next argument. 
If the precision is zero, nothing is printed. If a string has a precision specification, its length is ignored.

${E_WHITE_FG}HEX${E_RESET}
%04x -> 4-digit hex number with leading zeroes
%x   -> prints an int in hexadecimal
%4x  -> prints a hex int, right-justified to 4 places; less than 4 digits -> preceded by spaces 
%04x -> prints a hex int, right-justified to 4 places; less than 4 digits -> preceded by zeroes

${E_WHITE_FG}Integer to Decimal${E_RESET}
%d   -> prints signed int in decimal
%u   -> prints unsigned int in decimal

${E_WHITE_FG}Characters and Strings${E_RESET}
%c   -> prints a character
%s   -> prints a string; for wide (Unicode) strings, prefix with l (ell, or w): %lc and %ls.

${E_WHITE_FG}Note${E_RESET}: For the Unicode variants, such as wprintf and friends, %c and %s print wide strings. To force
a narrow string, no matter which variant, use the %h size prefix, and to force a wide string, use
the %l size prefix; e.g., %hs and %lc.

${E_WHITE_FG}64 Bit${E_RESET}
%I64d, %I64u, %I64x -> 64-bit integers
To print 64-bit numbers (__int64), use the I64 size prefix.

${E_WHITE_FG}Zero Suppresion${E_RESET}
%.0d -> print nothing for zero
Suppress output when a number is zero. A non-zero number will be printed. 
Similarly, %.0s swallows a string

${E_WHITE_FG}Leading Hex Zero${E_RESET}
%#x  -> print a leading 0x
If you want printf to automatically generate 0x before hex numbers, use %#x instead of %x.

tip_printf_EOF
}

tip_pup () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_pup_EOF

${E_WHITE_FG}Pup Documentation${E_RESET}
------------------------------------

${E_WHITE_FG}pup${E_RESET} is a command line tool for processing HTML. It reads from stdin, prints to stdout, and allows the user to filter 
parts of the page using CSS selectors.


${E_GREEN_FG}Implemented Selectors${E_RESET}
---------------------------------
${E_WHITE_FG}pup '.class'${E_RESET}
${E_WHITE_FG}pup '#id'${E_RESET}
${E_WHITE_FG}pup 'element'${E_RESET}
${E_WHITE_FG}pup 'selector + selector' (adjacent sibling)${E_RESET}
${E_WHITE_FG}pup 'selector > selector' (direct descendent)${E_RESET}
${E_WHITE_FG}pup '[attribute]'${E_RESET}
${E_WHITE_FG}pup '[attribute="value"]'${E_RESET}
${E_WHITE_FG}pup '[attribute*="value"]'${E_RESET}
${E_WHITE_FG}pup '[attribute~="value"]'${E_RESET}
${E_WHITE_FG}pup '[attribute^="value"]'${E_RESET}
${E_WHITE_FG}pup '[attribute\$="value"]'${E_RESET}
${E_WHITE_FG}pup ':empty'${E_RESET}
${E_WHITE_FG}pup ':first-child'${E_RESET}
${E_WHITE_FG}pup ':first-of-type'${E_RESET}
${E_WHITE_FG}pup ':last-child'${E_RESET}
${E_WHITE_FG}pup ':last-of-type'${E_RESET}
${E_WHITE_FG}pup ':only-child'${E_RESET}
${E_WHITE_FG}pup ':only-of-type'${E_RESET}
${E_WHITE_FG}pup ':contains("text")'${E_RESET}
${E_WHITE_FG}pup ':nth-child(n)' ${E_BOLD}${E_RED_FG}*${E_RESET}
${E_WHITE_FG}pup ':nth-of-type(n)' ${E_BOLD}${E_RED_FG}*${E_RESET}
${E_WHITE_FG}pup ':nth-last-child(n)' ${E_BOLD}${E_RED_FG}*${E_RESET}
${E_WHITE_FG}pup ':nth-last-of-type(n)' ${E_BOLD}${E_RED_FG}*${E_RESET}
${E_WHITE_FG}pup ':not(selector)'${E_RESET}
${E_WHITE_FG}pup ':parent-of(selector)'${E_RESET}

${E_GREEN_FG}Basic Usage${E_RESET}
-----------
$ cat index.html | ${E_WHITE_FG}pup [flags] '[selectors] [display function]'${E_RESET}

${E_GREEN_FG}Examples${E_RESET}
--------
$ curl -s https://news.ycombinator.com/

Ew, HTML. Let's run that through some ${E_WHITE_FG}pup${E_RESET} selectors:
$ curl -s https://news.ycombinator.com/ | ${E_WHITE_FG}pup 'table table tr:nth-last-of-type(n+2) td.title a'${E_RESET}

Okay, how about only the links?
$ curl -s https://news.ycombinator.com/ | ${E_WHITE_FG}pup 'table table tr:nth-last-of-type(n+2) td.title a attr{href}'${E_RESET}

Even better, let's grab the titles too:
$ curl -s https://news.ycombinator.com/ | ${E_WHITE_FG}pup 'table table tr:nth-last-of-type(n+2) td.title a json{}'${E_RESET}

--------
Download a webpage with wget.
--------

$ wget http://en.wikipedia.org/wiki/Robots_exclusion_standard -O robots.html

-->${E_GREEN_FG}Clean and indent${E_RESET}
-------------------
By default ${E_WHITE_FG}pup${E_RESET} will fill in missing tags and properly indent the page.

$ cat robots.html
# nasty looking HTML
$ cat robots.html | ${E_WHITE_FG}pup --color${E_RESET}
# cleaned, indented, and colorful HTML

-->${E_GREEN_FG}Filter by tag${E_RESET}
----------------
$ cat robots.html | ${E_WHITE_FG}pup 'title'${E_RESET}
<title>
 Robots exclusion standard - Wikipedia, the free encyclopedia
</title>

-->${E_GREEN_FG}Filter by id${E_RESET}
---------------
$ cat robots.html | ${E_WHITE_FG}pup 'span#See_also'${E_RESET}
<span class="mw-headline" id="See_also">
 See also
</span>

-->${E_GREEN_FG}Filter by attribute${E_RESET}
----------------------
$ cat robots.html | ${E_WHITE_FG}pup 'th[scope="row"]'${E_RESET}
<th scope="row" class="navbox-group">
 Exclusion standards
</th>
<th scope="row" class="navbox-group">
 Related marketing topics
</th>
<th scope="row" class="navbox-group">
 Search marketing related topics
</th>
<th scope="row" class="navbox-group">
 Search engine spam
</th>
<th scope="row" class="navbox-group">
 Linking
</th>
<th scope="row" class="navbox-group">
 People
</th>
<th scope="row" class="navbox-group">
 Other
</th>

${E_GREEN_FG}Pseudo Classes${E_RESET}
---------------------------------

CSS selectors have a group of specifiers called "pseudo classes" which are pretty cool. 
${E_WHITE_FG}pup${E_RESET} implements a majority of the relevant ones them.

${E_YELLOW_FG}Here are some examples.

$ cat robots.html | ${E_WHITE_FG}pup 'a[rel]:empty'${E_RESET}
<a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;">
</a>
$ cat robots.html | ${E_WHITE_FG}pup ':contains("History")'${E_RESET}
<span class="toctext">
 History
</span>
<span class="mw-headline" id="History">
 History
</span>
$ cat robots.html | ${E_WHITE_FG}pup ':parent-of([action="edit"])'${E_RESET}
<span class="wb-langlinks-edit wb-langlinks-link">
 <a action="edit" href="//www.wikidata.org/wiki/Q80776#sitelinks-wikipedia" text="Edit links" title="Edit interlanguage links" class="wbc-editpage">
  Edit links
 </a>
</span>

============================================================
For a complete list, view the implemented selectors section.
============================================================

${E_GREEN_FG}+, >, and ,${E_RESET}
---------------------------------
These are intermediate characters that declare special instructions. 

${E_GREEN_FG}For instance, a comma , allows ${E_WHITE_FG}pup${E_RESET} to specify multiple groups of selectors.${E_RESET}
---------------------------------------------------------------------------
$ cat robots.html | ${E_WHITE_FG}pup 'title, h1 span[dir="auto"]'${E_RESET}
<title>
 Robots exclusion standard - Wikipedia, the free encyclopedia
</title>
<span dir="auto">
 Robots exclusion standard
</span>

Chain selectors together...
${E_GREEN_FG}When combining selectors, the HTML nodes selected by the previous selector will be passed to the next ones.${E_RESET}
-----------------------------------------------------------------------------------------------------------
$ cat robots.html | ${E_WHITE_FG}pup 'h1#firstHeading'${E_RESET}
<h1 id="firstHeading" class="firstHeading" lang="en">
 <span dir="auto">
  Robots exclusion standard
 </span>
</h1>
$ cat robots.html | ${E_WHITE_FG}pup 'h1#firstHeading span'${E_RESET}
<span dir="auto">
 Robots exclusion standard
</span>


${E_BOLD}${E_RED_FG}*${E_RESET}${E_WHITE_FG} Optionally use a formula (an + b).${E_RESET}
Description: 'a' represents a cycle size, 'n' is a counter (starts at 0), and 'b' is an offset value.
So, ${E_WHITE_FG}p:nth-child(3n+0)${E_RESET} references all p elements whose index is a multiple of 3

${E_GREEN_FG}You can mix and match selectors as you wish.${E_RESET}
--------------------------------------------
cat index.html | ${E_WHITE_FG}pup 'element#id[attribute="value"]:first-of-type'${E_RESET}

${E_GREEN_FG}Display Functions${E_RESET}
---------------------------------
Non-HTML selectors which effect the output type are implemented as functions which can be provided as a final argument.

${E_WHITE_FG}text{}${E_RESET} -> Print all text from selected nodes and children in depth first order.
------------------------------------------------------------------------------
$ cat robots.html | ${E_WHITE_FG}pup '.mw-headline text{}'${E_RESET}
History
About the standard
Disadvantages
Alternatives
Examples
Nonstandard extensions
Crawl-delay directive
Allow directive
Sitemap
Host
Universal "*" match
Meta tags and headers
See also
References
External links

${E_WHITE_FG}attr{attrkey}${E_RESET} -> Print the values of all attributes with a given key from all selected nodes.${E_RESET}
---------------------------------------------------------------------------------------------
$ cat robots.html | ${E_WHITE_FG}pup '.catlinks div attr{id}'${E_RESET}
mw-normal-catlinks
mw-hidden-catlinks

${E_WHITE_FG}json{}${E_RESET} -> Print HTML as JSON.${E_RESET}
-----------------------------
$ cat robots.html  | ${E_WHITE_FG}pup 'div#p-namespaces a'${E_RESET}
<a href="/wiki/Robots_exclusion_standard" title="View the content page [c]" accesskey="c">
 Article
</a>
<a href="/wiki/Talk:Robots_exclusion_standard" title="Discussion about the content page [t]" accesskey="t">
 Talk
</a>
$ cat robots.html | ${E_WHITE_FG}pup 'div#p-namespaces a json{}'${E_RESET}
[
 {
  "accesskey": "c",
  "href": "/wiki/Robots_exclusion_standard",
  "tag": "a",
  "text": "Article",
  "title": "View the content page [c]"
 },
 {
  "accesskey": "t",
  "href": "/wiki/Talk:Robots_exclusion_standard",
  "tag": "a",
  "text": "Talk",
  "title": "Discussion about the content page [t]"
 }
]

${E_GREEN_FG}Use the -i / --indent flag to control the indent level.${E_RESET}
-------------------------------------------------------
$ cat robots.html | ${E_WHITE_FG}pup -i 4 'div#p-namespaces a json{}'${E_RESET}
[
    {
        "accesskey": "c",
        "href": "/wiki/Robots_exclusion_standard",
        "tag": "a",
        "text": "Article",
        "title": "View the content page [c]"
    },
    {
        "accesskey": "t",
        "href": "/wiki/Talk:Robots_exclusion_standard",
        "tag": "a",
        "text": "Talk",
        "title": "Discussion about the content page [t]"
    }
]

${E_GREEN_FG}If the selectors only return one element the results will be printed as a JSON object, not a list.${E_RESET}
--------------------------------------------------------------------------------------------------
$ cat robots.html  | ${E_WHITE_FG}pup --indent 4 'title json{}'${E_RESET}
{
    "tag": "title",
    "text": "Robots exclusion standard - Wikipedia, the free encyclopedia"
}

Because there is no universal standard for converting HTML/XML to JSON, a method has been 
chosen which hopefully fits. The goal is simply to get the output of ${E_WHITE_FG}pup${E_RESET} into a more consumable format.

${E_GREEN_FG}Flags${E_RESET}
---------------------------------
Run ${E_WHITE_FG}pup --help${E_RESET} for a list of further options:

Usage
    -pup [flags] [selectors] [optional display function]
Version
    0.4.0
Flags
    -c --color         print result with color
    -f --file          file to read from
    -h --help          display this help
    -i --indent        number of spaces to use for indent or character
    -n --number        print number of elements selected
    -l --limit         restrict number of levels printed
    -p --plain         don't escape html
    --pre              preserve preformatted text
    --charset          specify the charset for pup to use
    --version          display version


${E_BOLD}${E_WHITE_FG}Pup Tutorial${E_RESET}
------------------------------------
${E_WHITE_FG}Selecting elements by tag${E_RESET}

Given this HTML snippet below:
<img src="/files/pages/nyt-displays.jpg">
  the tag of this element is img

To select the img tag, via ${E_WHITE_FG}pup${E_RESET}: cat nyt-sample.html | ${E_WHITE_FG}pup${E_RESET} 'img' 
This returns:

${E_GREEN_FG}<img src="/files/pages/nyt-displays.jpg">${E_RESET}

${E_WHITE_FG}Selecting elements by id or class${E_RESET}

In HTML, there's relatively few kinds of tags. To differentiate between elements with the same tag, 
elements are given different ids or classes.

For example, try selecting all the h1 tags: cat nyt-sample.html | ${E_WHITE_FG}pup${E_RESET} 'h1'

You'll see output that includes this:

${E_GREEN_FG}<h1 id="main-title">
${E_GREEN_FG} Stories from the New York Times
${E_GREEN_FG}</h1>
${E_GREEN_FG}<h1 class="headline">
${E_GREEN_FG} <a href="http://www.nytimes.com/2015/01/09/business/honda-fined-70-million-in-underreporting-safety-issues-to-government.html">
${E_GREEN_FG}  Honda Hit With Record Fine for Not Reporting Deaths
${E_GREEN_FG} </a>
${E_GREEN_FG}</h1>${E_RESET}

${E_WHITE_FG}Selecting elements by id attribute${E_RESET}

To select the first h1 element (that has the text, Stories from the New York Times), 
we can select it exclusively by targeting its id attribute: cat nyt-sample.html | ${E_WHITE_FG}pup${E_RESET} 'h1#main-title'

In this case, since it happens to be the only element on the page with an 
id of main-title, this selector would work just as well:

cat nyt-sample.html | ${E_WHITE_FG}pup${E_RESET} '#main-title'

${E_WHITE_FG}Selecting elements by class attribute${E_RESET}

To get the other h1-tagged elements, we see that they all have a class of headline. 

The dot is used to select for class: cat nyt-sample.html | ${E_WHITE_FG}pup${E_RESET} 'h1.headline'

${E_WHITE_FG}Selecting child elements${E_RESET}

Given this HTML snippet:
<article>
  <h1 class="headline">
    <a href="http://www.nytimes.com/2015/01/09/sports/program-prepares-the...\>
  </h1>
  <p class="description">
    After becoming a grandmaster at the tender age of 13, Sam Sevian is getting some help from the chess champion Garry Kasparov.
  </p>
</article>

The p element can be thought of as the child of the article element. 

To target that p element: cat nyt-sample.html | ${E_WHITE_FG}pup${E_RESET} 'article p'

And you can also see that that a element is a child of the h1 element which itself is a 
child of that article. Here's the most specific way to target that a element:

cat nyt-sample.html | ${E_WHITE_FG}pup${E_RESET} 'article h1 a'

${E_WHITE_FG}Selecting the attribute value of an element${E_RESET}

In the img tag, the src attribute points to where the image file is physically located:
<img src="/files/pages/nyt-displays.jpg">

To get the src attribute of this img tag: cat nyt-sample.html | ${E_WHITE_FG}pup${E_RESET} 'img attr{src}' 

${E_GREEN_FG}/files/pages/nyt-displays.jpg${E_RESET}

The attribute that you'll deal with the most in web-scraping is the href attribute which 
is part of standard a-tagged elements (i.e. anchor links, or, "hyperlinks").

To get all the values of the href attributes for all the a tags on the page: cat nyt-sample.html | ${E_WHITE_FG}pup${E_RESET} 'a attr{href}'

${E_GREEN_FG}http://www.nytimes.com
${E_GREEN_FG}https://www.flickr.com/photos/zokuga/5804588208/in/photostream/
${E_GREEN_FG}http://www.nytimes.com/2015/01/09/business/honda-fined-70-million-in-underreporting-safety-issues-to-government.html
${E_GREEN_FG}http://www.nytimes.com/2015/01/09/sports/program-prepares-the-chess-prodigy-sam-sevian-for-his-next-moves.html
${E_GREEN_FG}http://www.nytimes.com/2015/01/09/us/in-san-franciscos-tenderloin-a-move-to-help-artists-as-wealth-moves-in.html
${E_GREEN_FG}http://nytimes.com/2015/01/09/opinion/the-stumbling-tumbling-euro.html
${E_GREEN_FG}http://www.nytimes.com/2015/01/09/business/democrats-step-up-efforts-to-block-obama-on-trade-promotion-authority.html
${E_RESET}

To get all the values of the href attributes for just the a-tagged elements that are 
children of the h1-tagged elements (with a class of headline): cat nyt-sample.html | ${E_WHITE_FG}pup${E_RESET} 'h1.headline a attr{href}'

${E_GREEN_FG}http://www.nytimes.com/2015/01/09/business/honda-fined-70-million-in-underreporting-safety-issues-to-government.html
${E_GREEN_FG}http://www.nytimes.com/2015/01/09/sports/program-prepares-the-chess-prodigy-sam-sevian-for-his-next-moves.html
${E_GREEN_FG}http://www.nytimes.com/2015/01/09/us/in-san-franciscos-tenderloin-a-move-to-help-artists-as-wealth-moves-in.html
${E_GREEN_FG}http://nytimes.com/2015/01/09/opinion/the-stumbling-tumbling-euro.html
${E_GREEN_FG}http://www.nytimes.com/2015/01/09/business/democrats-step-up-efforts-to-block-obama-on-trade-promotion-authority.html
${E_RESET}

${E_WHITE_FG}Selecting text elements${E_RESET}

Think of the text elements as the literal text that you see on a page when rendered by the browser.
For example, given this HTML snippet:

<h1 id="main-title">Stories from the New York Times</h1>

The text of the h1 element is "Stories from the New York Times"

Using ${E_WHITE_FG}pup${E_RESET} to select only the text of that h1 element: cat nyt-sample.html | ${E_WHITE_FG}pup${E_RESET} 'h1#main-title text{}'

${E_GREEN_FG}Stories from the New York Times${E_RESET}

${E_BOLD}${E_WHITE_FG}CSS Selector (30 Essential) Tutorial ${E_RESET}
------------------------------------
${E_BOLD}${E_CYAN_FG}1.${E_WHITE_FG} *${E_RESET}

${E_WHITE_FG}* {  
${E_WHITE_FG}    margin: 0;  
${E_WHITE_FG}    padding: 0; 
${E_WHITE_FG}}${E_RESET}

Let's knock the obvious ones out, for the beginners, before we move onto the
more advanced selectors.  The star symbol will target every single element on
the page. Many developers will use this trick to zero out the margins and
padding

While this is certainly fine for quick tests, I'd advise you to never use this
in production code.  It adds too much weight on the browser, and is unnecessary.
The * can also be used with child selectors.

${E_WHITE_FG}#container * {
${E_WHITE_FG}    border: 1px solid black; 
${E_WHITE_FG}}${E_RESET}

This will target every single element that is a child of the #container div.
Again, try not to use this technique very much, if ever.

${E_BOLD}${E_CYAN_FG}2.${E_WHITE_FG} #X${E_RESET}

${E_WHITE_FG}#container {
${E_WHITE_FG}    width: 960px;    
${E_WHITE_FG}    margin: auto; 
${E_WHITE_FG}}${E_RESET}

Prefixing the hash symbol to a selector allows us to target by using id. This is
easily the most common usage, however be cautious when selectors.

Ask yourself: do I absolutely need to apply an id to this element in order to
target it?  selectors are rigid and don't allow for reuse.  If possible, first
try to use a tag name, one of the new HTML5 elements, or even a pseudo-class.

${E_BOLD}${E_CYAN_FG}3.${E_WHITE_FG} .X${E_RESET}

${E_WHITE_FG}.error {
${E_WHITE_FG}  color: red; 
${E_WHITE_FG}}${E_RESET}

This is a class selector. The difference between id's and classes is that, with
the latter, you can target multiple elements. Use classes when you want your
styling to apply to a group of elements. Alternatively, use id's to find a
needle-in-a-haystack, and style only that specific element.

${E_BOLD}${E_CYAN_FG}4.${E_WHITE_FG} X Y${E_RESET}

${E_WHITE_FG}li a {
${E_WHITE_FG}  text-decoration: none; 
${E_WHITE_FG}}${E_RESET}

The next most comment selector is the descendant selector.  When you need to be
more specific with your selectors, you use these. For example, what if, rather
than targeting all anchor tags, you only need to target the anchors which are
within an unordered list? This is specifically when you'd use a descendant
selector.

${E_BOLD}${E_CYAN_FG}5.${E_WHITE_FG} X${E_RESET}

${E_WHITE_FG}a {
${E_WHITE_FG}    color: red; 
${E_WHITE_FG}}
${E_WHITE_FG}ul { 
${E_WHITE_FG}    margin-left: 0; 
${E_WHITE_FG}}${E_RESET}

What if you want to target all elements on a page, according to their type,
     rather than an id or class name? Keep it simple, and use a type selector.
     If you need to target all unordered lists, use ul {}

${E_BOLD}${E_CYAN_FG}6.${E_WHITE_FG} X:visited and X:link${E_RESET}

${E_WHITE_FG}a:link {
${E_WHITE_FG}    color: red; 
${E_WHITE_FG}} 
${E_WHITE_FG}a:visted { 
${E_WHITE_FG}    color: purple; 
${E_WHITE_FG}}${E_RESET}

We use the :link pseudo-class to target all anchors tags which have yet to be
clicked on.  Alternatively, we also have the :visited pseudo class, which, as
you'd expected, allows us to apply specific styling to only the anchor tags on
the page which have been clicked on, or visited.

${E_BOLD}${E_CYAN_FG}7.${E_WHITE_FG} X + Y${E_RESET}

${E_WHITE_FG}ul + p {
${E_WHITE_FG}   color: red; 
${E_WHITE_FG}}${E_RESET}

This is referred to as an adjacent selector. It will select only the element
that is immediately preceded by the former element. In this case, only the first
paragraph after each ul will have red text.

${E_BOLD}${E_CYAN_FG}8.${E_WHITE_FG} X > Y${E_RESET}

${E_WHITE_FG}div#container > ul {
${E_WHITE_FG}  border: 1px solid black; 
${E_WHITE_FG}}${E_RESET}

The difference between the standard X Y and X > Y is that the latter will only
select direct children.  For example, consider the following markup.

${E_WHITE_FG}<div id="container">    
${E_WHITE_FG}    <ul>       
${E_WHITE_FG}        <li> List Item
${E_WHITE_FG}            <ul>            
${E_WHITE_FG}                <li> Child </li>         
${E_WHITE_FG}            </ul>       
${E_WHITE_FG}        </li>       
${E_WHITE_FG}        <li> List Item </li>       
${E_WHITE_FG}        <li> List Item </li>       
${E_WHITE_FG}        <li> List Item </li>    
${E_WHITE_FG}    </ul> 
${E_WHITE_FG}</div>${E_RESET}

A selector of #container > ul will only target the ul' which are direct children
of the div with an id of container. It will not target, for instance, the ul
that is a child of the first li.  

For this reason, there are performance benefits in using the child combinator.
In fact, it's recommended particularly when working with JavaScript-based CSS
selector engines.

${E_BOLD}${E_CYAN_FG}9.${E_WHITE_FG} X ~ Y${E_RESET}

${E_WHITE_FG}ul ~ p {
${E_WHITE_FG}   color: red; 
${E_WHITE_FG}}${E_RESET}

This sibling combinator is similar to X + Y, however, it's less strict.  While
an adjacent selector ( ul + p ) will only select the first element that is
immediately preceded by the former selector, this one is more generalized.  It
will select, referring to our example above, any p elements, as long as they
follow a ul.

${E_BOLD}${E_CYAN_FG}10.${E_WHITE_FG} X[title]${E_RESET}

${E_WHITE_FG}a[title] {
${E_WHITE_FG}   color: green; 
${E_WHITE_FG}}${E_RESET}

Referred to as an attributes selector, in our example above, this will only
select the anchor tags that have a title attribute. Anchor tags which do not
will not receive this particular styling. But, what if you need to be more
specific? Well...

${E_BOLD}${E_CYAN_FG}11.${E_WHITE_FG} X[href="foo"]${E_RESET}

${E_WHITE_FG}a[href="http://net.tutsplus.com"] {
${E_WHITE_FG}  color: #1f6053; /* nettuts green */ 
${E_WHITE_FG}}${E_RESET}

The snippet above will style all anchor tags which link to
http://net.tutsplus.com; they'll receive our branded green color. All other
anchor tags will remain unaffected.  Note that we're wrapping the value in
quotes.  Remember to also do this when using a JavaScript CSS selector engine.
When possible, always use CSS3 selectors over unofficial methods.

This works well, though, it's a bit rigid. What if the link does indeed direct
to Nettuts+, but, maybe, the path is nettuts.com rather than the full url? In
those cases we can use a bit of the regular expressions syntax.

${E_BOLD}${E_CYAN_FG}12.${E_WHITE_FG} X[href*="nettuts"]${E_RESET}

${E_WHITE_FG}a[href*="tuts"] {
${E_WHITE_FG}  color: #1f6053; /* nettuts green */ 
${E_WHITE_FG}}${E_RESET}

There we go; that's what we need. The star designates that the proceeding value
must appear somewhere in the attribute's value. That way, this covers
nettuts.com, net.tutsplus.com, and even tutsplus.com.  Keep in mind that this is
a broad statement. What if the anchor tag linked to some non-Envato site with
the string tuts in the url? 

When you need to be more specific, use ^ and $, to reference the beginning and
end of a string, respectively.

${E_BOLD}${E_CYAN_FG}13.${E_WHITE_FG} X[href^="http"]${E_RESET}

${E_WHITE_FG}a[href^="http"] { 
${E_WHITE_FG}    background: url(path/to/external/icon.png) no-repeat;
${E_WHITE_FG}    padding-left: 10px;
${E_WHITE_FG}}${E_RESET}

Ever wonder how some websites are able to display a little icon next to the
links which are external? I'm sure you've seen these before; they're nice
reminders that the link will direct you to an entirely different website.  This
is a cinch with the carat symbol. It's most commonly used in regular expressions
to designate the beginning of a string. If we want to target all anchor tags
that have a href which begins with http, we could use a selector similar to the 
snippet shown above.

Notice that we're not searching for with https://; that's unnecessary, and doesn't 
account for the urls that begin http://

Now, what if we wanted to instead style all anchors which link to, say, a photo?
In those cases, let's search for the end of the string.

${E_BOLD}${E_CYAN_FG}14.${E_WHITE_FG} X[href\$=".jpg"]${E_RESET}

${E_WHITE_FG}a[href\$=".jpg"] {
${E_WHITE_FG}    color: red; 
${E_WHITE_FG}}${E_RESET}

Again, we use a regular expressions symbol, an image -- or at least a url that
ends with $, to refer to the end of a string. 
In this case, we're searching for all anchors which link to .jpg
Keep in mind that this certainly won't work for gifs and pngs.

Refer back to number eight; how do we compensate for all of the various image
types: png , jpeg, jpg , gif? Well, we could create multiple selectors, such as:

${E_WHITE_FG}a[href\$=".jpg"], a[href\$=".jpeg"], a[href\$=".png"], a[href\$=".gif"] {
${E_WHITE_FG}    color:
${E_WHITE_FG}    red; 
${E_WHITE_FG}}${E_RESET}

But, that's a pain in the butt, and is inefficient. Another possible solution is
to use custom attributes. What if we added our own filetype data-attribute to each
anchor that links to an image?  

${E_WHITE_FG}<a href="path/to/image.jpg" data-filetype="image"> Image Link </a>${E_RESET}

Then, with that hook in place, we can use a standard attributes selector to
target only those anchors.

${E_WHITE_FG}a[data-filetype="image"] {
${E_WHITE_FG}    color: red; 
${E_WHITE_FG}}${E_RESET}

${E_BOLD}${E_CYAN_FG}16.${E_WHITE_FG} X[foo~="bar"]${E_RESET}

${E_WHITE_FG}a[data-info~="external"] {
${E_WHITE_FG}    color: red; 
${E_WHITE_FG}}${E_RESET}

${E_WHITE_FG}a[data-info~="image"] {
${E_WHITE_FG}    border:
${E_WHITE_FG}    1px solid black; 
${E_WHITE_FG}}${E_RESET}

Here's a special one that'll impress your friends. Not too many people know
about this trick. The tilda ( ~ ) symbol allows us to target an attribute which
has a spaced-separated list of values.  Going along with our custom attribute
from number fifteen, above, we could create a data-info attribute, which can 
receive a space-separated list of anything we need to make note of. 
In this case, we'll make note of external links and links to images -- just for the example.

${E_WHITE_FG}"<a href="path/to/image.jpg" data-info="external image"> Click Me, Fool </a>${E_RESET}

With that markup in place, now we can target any tags that have either of those
values, by using the ~ attributes selector trick.

/* Target data-info attr that contains the value "external" */

${E_WHITE_FG}a[data-info~="external"] {
${E_WHITE_FG}    color: red;
${E_WHITE_FG}}${E_RESET}

/* And which contain the value "image" */

${E_WHITE_FG}a[data-info~="image"] {
${E_WHITE_FG}    border: 1px solid black;
${E_WHITE_FG}}${E_RESET}

Pretty nifty, ay?

${E_BOLD}${E_CYAN_FG}17.${E_WHITE_FG} X:checked${E_RESET}

${E_WHITE_FG}input[type=radio]:checked {
${E_WHITE_FG}    border: 1px solid black;
${E_WHITE_FG}}${E_RESET}

This pseudo class will only target a user interface element that has been
checked - like a radio button, or checkbox. It's as simple as that.

${E_BOLD}${E_CYAN_FG}18.${E_WHITE_FG} X:after The before and after pseudo classes kick butt. 

Every day, it seems, people are finding new and creative ways 
to use them effectively.

They simply generate content around the selected element.  Many were first
introduced to these classes when they encountered the clear-fix hack.

${E_WHITE_FG}.clearfix:after {
${E_WHITE_FG}    content: "";     
${E_WHITE_FG}    display: block;     
${E_WHITE_FG}      clear: both;
${E_WHITE_FG} visibility: hidden;     
${E_WHITE_FG}  font-size: 0;     
${E_WHITE_FG}     height: 0;    
${E_WHITE_FG}}${E_RESET}

${E_WHITE_FG}.clearfix {
${E_WHITE_FG}    *display: inline-block;    
${E_WHITE_FG}     _height: 1%; 
${E_WHITE_FG}}${E_RESET}

This hack uses the :after pseudo class to append a space after the element,
and then clear it. It's an excellent trick to have in your tool bag, 
particularly in the cases when the overflow: hidden; method isn't possible.

For another creative use of this, refer to my quick tip on creating shadows.

According to the CSS3 Selectors specification, you should technically use the
pseudo element syntax of two colons :: . However, to remain compatible, the
user-agent will accept a single colon usage as well. In fact, at this point,
it's smarter to use the single-colon version in your projects.

${E_BOLD}${E_CYAN_FG}19.${E_WHITE_FG} X:hover${E_RESET}

${E_WHITE_FG}div:hover {
${E_WHITE_FG}    background: #e3e3e3;
${E_WHITE_FG}}${E_RESET}

Oh come on. You know this one. The official term for this is user action pseudo class. 
It sounds confusing, but it really isn't. Want to apply specific styling when a user 
hovers over an element? This will get the job done!

Keep in mind that older version of Internet Explorer don't respond 
to anything other than an anchor tag when the :hover pseudo class is applied

You'll most often use this selector when applying, for example, 
a border-bottom to anchor tags, when hovered over.

${E_WHITE_FG}a:hover {  border-bottom: 1px solid black; }${E_RESET}

Pro-tip - border-bottom: 1px solid black; 
looks better than text-decoration: underline.

${E_BOLD}${E_CYAN_FG}20.${E_WHITE_FG} X:not(selector)${E_RESET}

${E_WHITE_FG}The div:not(#container) {
${E_WHITE_FG}    color: blue;
${E_WHITE_FG}}${E_RESET}

negation pseudo class is particularly helpful. Let's say I want to select all divs,
except for the one which has an id of container.
The snippet above will handle that task perfectly.  Or, if I wanted to select
every single element (not advised) except for paragraph tags, we could do: 

${E_WHITE_FG}*:not(p) {
${E_WHITE_FG}      color: green; 
${E_WHITE_FG}}${E_RESET}

${E_BOLD}${E_CYAN_FG}21.${E_WHITE_FG} X::pseudoElement${E_RESET}

${E_WHITE_FG}p::first-line {
${E_WHITE_FG}    font-weight: bold;
${E_WHITE_FG}    font-size: 1.2em;
${E_WHITE_FG}}${E_RESET}

We can use pseudo elements (designated by :: ) to style fragments of an element,
such as the first line, or the first letter.  Keep in mind that these must be 
applied to block level elements in order to take effect.

A pseudo-element is composed of two colons: ::

Target the First Letter of a Paragraph

${E_WHITE_FG}p::first-letter {
${E_WHITE_FG}    float: left;
${E_WHITE_FG}    font-size: 2em;
${E_WHITE_FG}    font-size: 2em;    
${E_WHITE_FG}    font-weight: bold;    
${E_WHITE_FG}    font-family: cursive;
${E_WHITE_FG}    padding-right: 2px;
${E_WHITE_FG}}${E_RESET}

This snippet is an abstraction that will find all paragraphs on the page, and
then sub-target only the first letter of that element.  This is most often used
to create newspaper-like styling for the first-letter of an article.  

Target the First Line of a Paragraph

${E_WHITE_FG}p::first-line {
${E_WHITE_FG}    font-weight: bold;
${E_WHITE_FG}    font-size: 1.2em;
${E_WHITE_FG}}${E_RESET}

Similarly, the ::first-line pseudo element will, as expected, style the first line 
of the element only.

"For compatibility with existing style sheets, user agents must also accept the
previous one-colon notation for pseudo-elements introduced in CSS levels 1 and 2
(namely, :first-line, :first-letter, :before and :after). This compatibility is
not allowed for the new pseudo-elements introduced in this specification." -

${E_BOLD}${E_CYAN_FG}22.${E_WHITE_FG} X:nth-child(n)${E_RESET}

${E_WHITE_FG}li:nth-child(3) {
${E_WHITE_FG}    color: red; 
${E_WHITE_FG}}${E_RESET}

Remember the days when we had no way to target specific elements in a stack? 
The nth-child pseudo class solves that!

Please note that nth-child accepts an integer as a parameter, however, this is not zero-based.

If you wish to target the second list item, use li:nth-child(2) 

We can even use this to select a variable set of children. For example, we could
do  li:nth-child(4n)  to select every fourth list item.


${E_BOLD}${E_CYAN_FG}23.${E_WHITE_FG} X:nth-last-child(n)${E_RESET}

${E_WHITE_FG}li:nth-last-child(2) {
${E_WHITE_FG}    color: red; 
${E_WHITE_FG}}${E_RESET}

What if you had a huge list of items in a ul, and only needed to access, say, the 
third to the last item?  Rather than doing nth-last-child(397), you could instead 
use the nth-child pseudo class.

This technique works almost identically from number sixteen above, however, the
difference is that it begins at the end of the collection, and works its way
back.

${E_BOLD}${E_CYAN_FG}24.${E_WHITE_FG} X:nth-of-type(n)${E_RESET}

${E_WHITE_FG}ul:nth-of-type(3) {
${E_WHITE_FG}    border: 1px solid black;
${E_WHITE_FG}}${E_RESET}

There will be times when, rather than selecting a child, you instead need to select 
according to the type of element.

Imagine mark-up that contains five unordered lists. If you wanted to style only
the third, and didn't have a unique id to hook into, you could use the nth-of-type(n) 
pseudo class. In the snippet above, only the third ul will have a border around it.

${E_BOLD}${E_CYAN_FG}25.${E_WHITE_FG} X:nth-last-of-type(n)${E_RESET}

${E_WHITE_FG}ul:nth-last-of-type(3) {
${E_WHITE_FG}    border: 1px solid black;
${E_WHITE_FG}}${E_RESET}

And yes, to remain consistent, we can also use nth-last-of-type to begin at the end 
of the selectors list, and work our way back to target the desired element.

${E_BOLD}${E_CYAN_FG}26.${E_WHITE_FG} X: first-child${E_RESET}

${E_WHITE_FG}ul li:first-child {
${E_WHITE_FG}    border-top: none; 
${E_WHITE_FG}}${E_RESET}

This structural pseudo class allows us to target only the first child of the element's 
parent. You'll often use this to remove borders from the first and last list items.  

For example, let's say you have a list of rows, and each one has a border-top and a
border-bottom. Well, with that arrangement, the first and last item in that set will 
look a bit odd.  Many designers apply classes of first and last to compensate for this. 
Instead, you can use these pseudo classes.

${E_BOLD}${E_CYAN_FG}27.${E_WHITE_FG} X:last-child${E_RESET}

${E_WHITE_FG}ul > li:last-child {
${E_WHITE_FG}    color: green; 
${E_WHITE_FG}}${E_RESET}

The opposite of first-child, last-child will target the last item of the element's parent.

Example Let's build a simple example to demonstrate one possible use of these
classes. We'll create a styled list item.  

Markup 

${E_WHITE_FG}<ul>
${E_WHITE_FG}    <li> List Item </li>
${E_WHITE_FG}    <li> List Item </li>
${E_WHITE_FG}    <li> List Item </li>
${E_WHITE_FG}</ul>${E_RESET}

Nothing special here; just a simple list.  

CSS

${E_WHITE_FG}ul {
${E_WHITE_FG}    width: 200px;  
${E_WHITE_FG}    background: #292929;  
${E_WHITE_FG}    color: white;  
${E_WHITE_FG}    list-style: none;
${E_WHITE_FG}    padding-left: 0; 
${E_WHITE_FG}}${E_RESET}

${E_WHITE_FG}li {  
${E_WHITE_FG}    padding: 10px;  
${E_WHITE_FG}    border-bottom: 1px solid black;
${E_WHITE_FG}    border-top: 1px solid #3c3c3c; 
${E_WHITE_FG}}${E_RESET}

This styling will set a background, remove the browser-default padding on the ul, 
and apply borders to each li to provide a bit of depth.

To add depth to your lists, apply a border-bottom to each li that is a shade or
two darker than the li's background color. Next, apply a border-top which is a couple
shades lighter.  

The only problem, as shown in the image above, is that a border will be applied
to the very top and bottom of the unordered list - which looks odd. Let's use
the :first-child and :last-child pseudo classes to fix this.

${E_WHITE_FG}li:first-child {
${E_WHITE_FG}    border-top: none; 
${E_WHITE_FG}}${E_RESET}  

${E_WHITE_FG}li:last-child {
${E_WHITE_FG}    border-bottom:
${E_WHITE_FG}    none; 
${E_WHITE_FG}${E_RESET}}

There we go; that fixes it!

${E_BOLD}${E_CYAN_FG}28.${E_WHITE_FG} X:only-child${E_RESET}

${E_WHITE_FG}div p:only-child {
${E_WHITE_FG}    color: red; 
${E_WHITE_FG}}${E_RESET}

Truthfully, you probably won't find yourself using the only-child pseudo class too often.
Nonetheless, it's available, should you need it.

It allows you to target elements which are the only child of its parent. For
example, referencing the snippet above, only the paragraph that is the only
child of the div will be colored, red.

Let's assume the following markup.

${E_WHITE_FG}<div> <p> My paragraph here. </p> </div>${E_RESET}

${E_WHITE_FG}<div>
${E_WHITE_FG}    <p> Two paragraphs total. </p>
${E_WHITE_FG}    <p> Two paragraphs total. </p> 
${E_WHITE_FG}</div>${E_RESET}

In this case, the second div's paragraphs will not be targeted; only the first
div. As soon as you apply more than one child to an element, the only-child
pseudo class ceases to take effect.

${E_BOLD}${E_CYAN_FG}29.${E_WHITE_FG} X:only-of-type${E_RESET}

${E_WHITE_FG}li:only-of-type {
${E_WHITE_FG}    font-weight: bold; 
${E_WHITE_FG}}${E_RESET}

This structural pseudo class can be used in some clever ways. It will target
elements that do not have any siblings within its parent container. As an
example, let's target all ul's, which have only a single list item.

First, ask yourself how you would accomplish this task? You could do ul li, 
but, this would target all list items. The only solution is to use only-of-type.  

${E_WHITE_FG}ul > li:only-of-type {
${E_WHITE_FG}    font-weight: bold;
${E_WHITE_FG}}${E_RESET}

${E_BOLD}${E_CYAN_FG}30.${E_WHITE_FG} X: first-of-type ${E_RESET}

The first-of-type pseudo class allows you to select the first siblings of its type.

A Test To better understand this, let's have a test. Copy the following mark-up
into your code editor:

${E_WHITE_FG}<div> 
${E_WHITE_FG}    <p> My paragraph here. </p>
${E_WHITE_FG}    <ul>
${E_WHITE_FG}        <li> List Item 1 </li>
${E_WHITE_FG}        <li> List Item 2 </li>    
${E_WHITE_FG}    </ul>      
${E_WHITE_FG}    <ul>       
${E_WHITE_FG}        <li> List Item 3 </li>
${E_WHITE_FG}        <li> List Item 4 </li>    
${E_WHITE_FG}    </ul>   
${E_WHITE_FG}</div>${E_RESET}

Now, without reading further, try to figure out how to target only "List Item
2".  When you've figured it out (or given up), read on.

Solution 1 There are a variety of ways to solve this test. We'll review a
handful of them. Let's begin by using first-of-type.

${E_WHITE_FG}ul:first-of-type > li:nth-child(2) {
${E_WHITE_FG}    font-weight: bold; 
${E_WHITE_FG}}${E_RESET}

This snippet essentially says, "find the first unordered list on the page, then
find only the immediate children, which are list items. Next, filter that
down to only the second list item in that set.  

Solution 2 Another option is to use the adjacent selector.

${E_WHITE_FG}p + ul li:last-child {
${E_WHITE_FG}    font-weight: bold;
${E_WHITE_FG}}${E_RESET}

In this scenario, we find the ul that immediately proceeds the p tag, and then
find the very last child of the element.

Solution 3 We can be as obnoxious or as playful as we want with these selectors.

${E_WHITE_FG}ul:first-of-type li:nth-last-child(1) {
${E_WHITE_FG}    font-weight: bold;
${E_WHITE_FG}}${E_RESET}

This time, we grab the first ul on the page, and then find the very first list
item, but starting from the bottom! :)

${E_WHITE_FG}And don't forget HTML-XML-utils${E_RESET}

HTML-XML-utils provides a number of simple utilities for manipulating and
converting HTML and XML files in various ways. The suite consists of the
following tools:

asc2xml      -  convert from UTF-8 to &#nnn; entities 
xml2asc      -  convert from &#nnn; entities to UTF-8 
hxaddid      -  add IDs to selected elements
hxcite       -  replace bibliographic references by hyperlinks 
hxcite-mkbib -  expand references and create bibliography 
hxclean      -  apply heuristics to correct an HTML file 
hxcopy       -  copy an HTML file while preserving relative links 
hxcount      -  count elements and attributes in HTML or XML files
hxextract    -  extract selected elements 
hxincl       -  expand included HTML or XML files 
hxindex      -  create an alphabetically sorted index 
hxmkbib      -  create bibliography from a template 
hxmultitoc   -  create a table of contents for a set of HTML files 
hxname2id    -  move some ID= or NAME= from A elements to their parents 
hxnormalize  -  pretty-print an HTML file 
hxnum        -  number section headings in an HTML file 
hxpipe       -  convert XML to a format easier to parse with Perl or AWK 
hxprintlinks -  number links & add table of URLs at end of an HTML file 
hxprune      -  remove marked elements from an HTML file 
hxselect     -  extract elements that match a (CSS) selector 
hxref        -  generate cross-references 
hxtoc        -  insert a table of contents in an HTML file 
hxuncdata    -  replace CDATA sections by character entities 
hxunent      -  replace HTML predefined character entities to UTF-8 
hxunpipe     -  convert output of pipe back to XML format 
hxunxmlns    -  replace "global names" by XML Namespace prefixes 
hxwls        -  list links in an HTML file 
hxxmlns      -  replace XML Namespace prefixes by "global names"
tip_pup_EOF
}

tip_regex () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_regex_EOF_1

${E_WHITE_FG}Regular expressions in Perl${E_RESET}

This document presents a tabular summary of the regular expression
(regexp) syntax in Perl, then illustrates it with a collection of
annotated examples.

${E_WHITE_FG}Metacharacters${E_RESET}

${E_WHITE_FG}Char    Meaning${E_RESET}

^       beginning of string
$       end of string
.       any character except newline
*       match 0 or more times
+       match 1 or more times
?       match 0 or 1 times; or: shortest match
|       alternative
( )     grouping; storing
[ ]     set of characters
{ }     repetition modifier
\       quote or special

To present a metacharacter as a data character standing for itself,
precede it with \ (e.g. \. matches only the period character '.').

In the table above, the characters themselves, in the first column,
are links to descriptions of characters in the ISO Latin 1 character
set - a description with usage notes. Note that the physical
appearance (glyph) of a character may vary from one device or program
or font to another.

${E_WHITE_FG}Repetition${E_RESET}

a*          zero or more a's
a+          one or more a's
a?          zero or one a's (i.e., optional a)
a{m}        exactly m a's
a{m,}       at least m a's
a{m,n}      at least m but at most n a's
a?          shortest match is taken (non greedy)

Read the notation as an occurrences of strings, each of which matches
the pattern a. Read repetition as any of the repetition expressions
listed above it. Shortest match means that the shortest string matching
the pattern is taken. The default is greedy matching, which finds the
longest match. The repetition? construct was introduced in Perl version 5.

${E_WHITE_FG}Special notations with \ (backslash)${E_RESET}

${E_WHITE_FG}Single characters${E_RESET}

\t     tab
\n     newline
\r     return (CR)
\xhh   character with hex code hh

${E_WHITE_FG}Zero-width assertions ${E_RESET}

\b     word boundary
\B     not a word boundary
\w     matches any single character classified as a word character (alphanumeric or _)
\W     matches any non-word character
\s     matches any whitespace character (space, tab, newline)
\S     matches any non-whitespace character
\d     matches any digit character, equiv. to [0-9]
\D     matches any non-digit character

${E_WHITE_FG}Character sets: specialities inside [...]${E_RESET}

Different meanings apply inside a character set (character class)
denoted by [...] so that, instead of the normal rules given here, the
following apply:

[characters]   matches any of the characters in the sequence
[x-y]          matches any of the characters from x to y (inclusively) in the ASCII code
[\-]           matches the hyphen character -
[\n]           matches the newline; other single character denotations with \ apply normally, too
[^something]   matches any character except those that [something] denotes; that is, 
               immediately after the leading [, the circumflex ^ means not applied to all of the rest

${E_WHITE_FG}Examples${E_RESET}
--------

${E_WHITE_FG}Expression  Matches${E_RESET}

abc         abc (that exact character sequence, but anywhere in the string)
^abc        abc at the beginning of the string
abc$        abc at the end of the string
a|b         either of a and b
^abc|abc$   the string abc at the beginning or at the end of the string
ab{2,4}c    an a followed by two, three or four bs followed by a c
ab{2,}c     an a followed by at least two bs followed by a c
ab*c        an a followed by any number (zero or more) of bs followed by a c
ab+c        an a followed by one or more bs followed by a c
ab?c        an a followed by an optional b followed by a c; that is, either abc or ac
a.c         an a followed by any single character (not newline) followed by a c
a\.c        a.c exactly
[abc]       any one of a, b and c
[Aa]bc      either of Abc and abc
[abc]+      any (nonempty) string of as, bs and cs (such as a, abba, acbabcacaa)
[^abc]+     any (nonempty) string which does not contain any of a, b and c (such as defg)
\d\d        any two decimal digits, such as 42; same as \d{2}
\w+         a word: a nonempty sequence of alphanumeric characters and low lines (underscores), such as foo and 12bar8 and foo_1
100\s*mk    the strings 100 and mk optionally separated by any amount of white space (spaces, tabs, newlines)
abc\b       abc when followed by a word boundary (e.g. in abc! but not in abcd)
perl\B      perl when not followed by a word boundary (e.g. in perlert but not in perl stuff)

${E_WHITE_FG}LOOK-AHEAD${E_RESET}

(?=foo)     look-ahead: Asserts that what immediately ${E_ITALIC}${E_WHITE_FG}follows the current position${E_RESET} in the string is ${E_WHITE_FG}foo${E_RESET}
(?<=foo)    look-behind: Asserts that what immediately ${E_ITALIC}${E_WHITE_FG}precedes the current position${E_RESET} in the string is ${E_WHITE_FG}foo${E_RESET}
(?!foo)     Negative look-ahead: Asserts that what immediately${E_ITALIC}${E_WHITE_FG}follows the current position${E_RESET} in the string is ${E_BOLD}${E_ITALIC}${E_RED_FG}not${E_RESET} ${E_WHITE_FG}foo${E_RESET}
(?<!foo)    Negative look-behind: Asserts that what immediately${E_ITALIC}${E_WHITE_FG}precedes the current position${E_RESET} in the string is ${E_BOLD}${E_ITALIC}${E_RED_FG}not${E_RESET} ${E_WHITE_FG}foo${E_RESET}

${E_WHITE_FG}COMMON TASKS${E_RESET}

${E_WHITE_FG}Finding the last occurrence${E_RESET}

There are actually a number of ways to get the last occurrence that don't involve look-around, but if you think of "the last foo" 
as "foo that isn't followed by a string containing foo", you can express that notion like this: ${E_WHITE_FG}/foo(?!.*foo)/${E_RESET}

The regular expression engine will do its best to match ${E_WHITE_FG}.*foo${E_RESET}, starting at the end of the string "foo". If it is 
able to match that, then the negative look-ahead will fail, which will force the engine to progress through the string to try the
next foo.  

${E_WHITE_FG}Substituting before, after, or between characters${E_RESET}

Many substitutions match a chunk of text and then replace part or all of it. You can often avoid that by using look-arounds. 
For example, if you want to put a comma after every foo: ${E_WHITE_FG}s/(?<=foo)/,/g;${E_RESET} (without lookbehind: s/foo/foo,/g or s/(foo)/${1},/g)
or to put the hyphen in look-ahead: ${E_WHITE_FG}s/(?<=look)(?=ahead)/-/g;${E_RESET}

This kind of thing is likely to be the bulk of what you use look-arounds for. It is ${E_BOLD}important${E_RESET} to remember that look-behind expressions 
cannot be of variable length. That means you cannot use quantifiers (?, *, +, or {1,5}) or alternation of different-length items inside them.

${E_WHITE_FG}Matching a pattern that doesn't include another pattern${E_RESET}

You might want to capture everything between foo and bar that doesn't include baz. The technique is to have the regex engine 
look-ahead at every character to ensure that it isn't the beginning of the undesired pattern:

${E_WHITE_FG}/foo((?:(?!baz).)*)bar/x;${E_RESET}

/foo       # ${E_WHITE_FG}Match starting at foo${E_RESET}
 (         # ${E_WHITE_FG}Capture${E_RESET}
 (?:       # ${E_WHITE_FG}Complex expression:${E_RESET}
   (?!baz) # ${E_WHITE_FG}make sure we're not at the beginning of baz${E_RESET}
   .       # ${E_WHITE_FG}accept any character${E_RESET}
 )*        # ${E_WHITE_FG}any number of times${E_RESET}
 )         # ${E_WHITE_FG}End capture${E_RESET}
 bar       # ${E_WHITE_FG}and ending at bar${E_RESET}
/x;

${E_WHITE_FG}Nesting${E_RESET}

You can put look-arounds inside of other look-arounds. This has been known to induce a flight response in certain readers 
(me, for example, the first time I saw it), but it's really not such a hard concept. A look-around sub-expression inherits a 
starting position from the enclosing expression, and can walk all around relative to that position without affecting the position 
of the enclosing expression. They all have independent (though initially inherited) bookkeeping for where they are in the string.

The concept is pretty simple, but the notation becomes hairy very quickly, so commented regular expressions are recommended. 
Let's look at the real example of Regex to add space after punctuation sign. The poster wants to put a space after any comma 
(punctuation, actually, but for simplicity, let's say comma) that is not nestled between two digits. Building up the s/// expression:

${E_WHITE_FG}s/(?<=,(?!(?<=\d,)(?=\d)))/ /gx;${E_RESET}

s/(?<=,        # ${E_WHITE_FG}after a comma,${E_RESET}
    (?!        # ${E_WHITE_FG}but not matching${E_RESET}
      (?<=\d,) # ${E_WHITE_FG}digit-comma before, AND${E_RESET}
      (?=\d)   # ${E_WHITE_FG}digit afterward${E_RESET}
    )
  )/ /gx;      # ${E_WHITE_FG}substitute a space${E_RESET}

Note: that multiple lookarounds can be used to enforce multiple conditions at the same place, like an AND condition that complements 
the alternation (vertical bar)'s OR. In fact, you can use Boolean algebra ( NOT (a AND b) === (NOT a OR NOT b) ) to convert the 
expression to use OR:

${E_WHITE_FG}s/(?<=,(?:(?<!\d,)|(?!\d)))/ /gx;${E_RESET}

s/(?<=,        # ${E_WHITE_FG}after a comma, but either${E_RESET}
    (?:
      (?<!\d,) # ${E_WHITE_FG}not matching digit-comma before${E_RESET}
      |        # ${E_WHITE_FG}OR${E_RESET}
      (?!\d)   # ${E_WHITE_FG}not matching digit afterward${E_RESET}
    )
  )/ /gx;      # ${E_WHITE_FG}substitute a space${E_RESET}

${E_WHITE_FG}Capturing${E_RESET}

It is sometimes useful to use capturing parentheses within a look-around. You might think that you wouldn't be able to do that, 
since you're just browsing, but you can. 

But ${E_BOLD}remember${E_RESET}: ${E_ITALIC}the capturing parentheses must be within the look-around expression${E_RESET}; from the enclosing expression's point of view, 
no actual matching was done by the zero-width look-around.

This is most useful for finding overlapping matches in a global pattern match. You can capture substrings without consuming them, 
so they are available for further matching later. Probably the simplest example is to get all right-substrings of a string:

${E_WHITE_FG}print "${1}\n" while /(?=(.*))/g;${E_RESET}

Note: that the pattern technically consumes no characters at all, but Perl knows to advance a character on an empty match, 
to prevent infinite looping.

${E_WHITE_FG}Simple examples of regex use in Perl statements${E_RESET}

These examples use very simple regexps only. The intent is just to show
contexts where regexps might be used, as well as the effect of some
flags to matching and replacements. Note in particular that matching
is by default case-sensitive (Abc does not match abc unless specified
otherwise).

${E_WHITE_FG}s/foo/bar/;${E_RESET}
replaces the first occurrence of the exact character sequence foo in the
current string (in special variable ${_}) by the character sequence bar;
for example, foolish bigfoot would become barlish bigfoot

${E_WHITE_FG}s/foo/bar/g;${E_RESET}
replaces any occurrence of the exact character sequence foo in the current
string by the character sequence bar; for example, foolish bigfoot would
become barlish bigbart

${E_WHITE_FG}s/foo/bar/gi;${E_RESET}
replaces any occurrence of foo case-insensitively in the current string
by the character sequence bar (e.g. Foo and FOO get replaced by bar too)

${E_WHITE_FG}if(m/foo/)...${E_RESET}
tests whether the current string contains the string foo


${E_WHITE_FG}If-Then-Else Conditionals in Regular Expressions${E_RESET}

A special construct ${E_WHITE_FG}(?ifthen|else)${E_RESET} allows you to create conditional regular
expressions. If the if part evaluates to true, then the regex engine will
attempt to match the then part. Otherwise, the else part is attempted instead.
The syntax consists of a pair of parentheses. The opening bracket must be
followed by a question mark, immediately followed by the if part, immediately
followed by the then part. This part can be followed by a vertical bar and the
else part. You may omit the else part, and the vertical bar with it.

For the if part, you can use the look-ahead and look-behind constructs. Using
positive look-ahead, the syntax becomes ${E_WHITE_FG}(?(?=regex)then|else)${E_RESET}. Because the
look-ahead has its own parentheses, the if and then parts are clearly separated.

Remember that the look-around constructs do not consume any characters. If you
use a look-ahead as the if part, then the regex engine will attempt to match the
then or else part (depending on the outcome of the look-ahead) at the same
position where the if was attempted.

Alternatively, you can check in the if part whether a capturing group has taken
part in the match thus far. Place the number of the capturing group inside
parentheses, and use that as the if part. Note that although the syntax for a
conditional check on a backreference is the same as a number inside a capturing
group, no capturing group is created. The number and the parentheses are part
of the if-then-else syntax started with (?.

For the then and else, you can use any regular expression. If you want to use
alternation, you will have to group the then or else together using parentheses
, like in ${E_WHITE_FG}(?(?=condition)(then1|then2|then3)|(else1|else2|else3))${E_RESET}. Otherwise,
there is no need to use parentheses around the then and else parts.

${E_WHITE_FG}Looking Inside The Regex Engine${E_RESET}

The regex ${E_WHITE_FG}(a)?b(?(1)c|d)${E_RESET} consists of the optional capturing group ${E_WHITE_FG}(a)?${E_RESET}, the
literal ${E_WHITE_FG}b${E_RESET}, and the conditional ${E_WHITE_FG}(?(1)c|d)${E_RESET} that tests the capturing group. This
regex matches ${E_WHITE_FG}bd${E_RESET} and ${E_WHITE_FG}abc${E_RESET}. It does not match ${E_WHITE_FG}bc${E_RESET}, but does match ${E_WHITE_FG}bd${E_RESET} in ${E_WHITE_FG}abd${E_RESET}. Let's
see how this regular expression works on each of these four subject strings.

When applied to ${E_WHITE_FG}bd${E_RESET}, ${E_WHITE_FG}a${E_RESET} fails to match. Since the capturing group containing ${E_WHITE_FG}a${E_RESET} is
optional, the engine continues with ${E_WHITE_FG}b${E_RESET} at the start of the subject string. Since
the whole group was optional, the group did not take part in the match. Any
subsequent backreference to it like ${E_WHITE_FG}\1${E_RESET} will fail. Note that ${E_WHITE_FG}(a)?${E_RESET} is very
different from ${E_WHITE_FG}(a?)${E_RESET}. In the former regex, the capturing group does not take
part in the match if ${E_WHITE_FG}a${E_RESET} fails, and backreferences to the group will fail. In the
latter group, the capturing group always takes part in the match, capturing
either ${E_WHITE_FG}a${E_RESET} or nothing. Backreferences to a capturing group that took part in the
match and captured nothing always succeed. Conditionals evaluating such groups
execute the "then" part. In short: if you want to use a reference to a group in
a conditional, use ${E_WHITE_FG}(a)?${E_RESET} instead of ${E_WHITE_FG}(a?)${E_RESET}.

Continuing with our regex, ${E_WHITE_FG}b${E_RESET} matches ${E_WHITE_FG}b${E_RESET}. The regex engine now evaluates the
conditional. The first capturing group did not take part in the match at all,
so the "else" part or ${E_WHITE_FG}d${E_RESET} is attempted. ${E_WHITE_FG}d${E_RESET} matches ${E_WHITE_FG}d${E_RESET} and an overall match is
found.

Moving on to our second subject string ${E_WHITE_FG}abc${E_RESET}, ${E_WHITE_FG}a${E_RESET} matches ${E_WHITE_FG}a${E_RESET}, which is captured by
the capturing group. Subsequently, ${E_WHITE_FG}b${E_RESET} matches ${E_WHITE_FG}b${E_RESET}. The regex engine again
evaluates the conditional. The capturing group took part in the match, so the
"then" part or ${E_WHITE_FG}c${E_RESET} is attempted. ${E_WHITE_FG}c${E_RESET} matches ${E_WHITE_FG}c${E_RESET} and an overall match is found.

Our third subject ${E_WHITE_FG}bc${E_RESET} does not start with ${E_WHITE_FG}a${E_RESET}, so the capturing group does not
take part in the match attempt, like we saw with the first subject string. ${E_WHITE_FG}b${E_RESET}
still matches ${E_WHITE_FG}b${E_RESET}, and the engine moves on to the conditional. The first
capturing group did not take part in the match at all, so the "else" part or ${E_WHITE_FG}d${E_RESET}
is attempted. ${E_WHITE_FG}d${E_RESET} does not match ${E_WHITE_FG}c${E_RESET} and the match attempt at the start of the
string fails. The engine does try again starting at the second character in the
string, but fails since ${E_WHITE_FG}b${E_RESET} does not match ${E_WHITE_FG}c${E_RESET}.

The fourth subject ${E_WHITE_FG}abd${E_RESET} is the most interesting one. Like in the second string,
the capturing group grabs the ${E_WHITE_FG}a${E_RESET} and the ${E_WHITE_FG}b${E_RESET} matches. The capturing group took
part in the match, so the "then" part or ${E_WHITE_FG}c${E_RESET} is attempted. ${E_WHITE_FG}c${E_RESET} fails to match ${E_WHITE_FG}d${E_RESET},
and the match attempt fails. Note that the "else" part is not attempted at this
point. The capturing group took part in the match, so only the "then" part is
used. However, the regex engine isn't done yet. It restarts the regular
expression from the beginning, moving ahead one character in the subject
string.

Starting at the second character in the string, ${E_WHITE_FG}a${E_RESET} fails to match ${E_WHITE_FG}b${E_RESET}. The
capturing group does not take part in the second match attempt which started at
the second character in the string. The regex engine moves beyond the optional
group, and attempts ${E_WHITE_FG}b${E_RESET}, which matches. The regex engine now arrives at the
conditional in the regex, and at the third character in the subject string. The
first capturing group did not take part in the current match attempt, so the
"else" part or ${E_WHITE_FG}d${E_RESET} is attempted. ${E_WHITE_FG}d${E_RESET} matches ${E_WHITE_FG}d${E_RESET} and an overall match ${E_WHITE_FG}bd${E_RESET} is found.

If you want to avoid this last match result, you need to use anchors. 
${E_WHITE_FG}^(a)?b(?(1)c|d)$ ${E_RESET}does not find any matches in the last subject string. The caret fails
to match before the second and third characters in the string.

${E_WHITE_FG}Named and Relative Conditionals${E_RESET}

Conditionals are supported by the JGsoft engine, Perl, PCRE, Python, and the
.NET framework. Ruby supports them starting with version 2.0. Languages such as
Delphi, PHP, and R that have regex features based on PCRE also support
conditionals.

All these flavors also support named capturing groups. You can use the name of
a capturing group instead of its number as the if test. The syntax is slightly
inconsistent between regex flavors. In Python, .NET, and the JGsoft
applications, you simply specify the name of the group between parentheses. 
${E_WHITE_FG}(? <test>a)?b(?(test)c|d)${E_RESET} is the regex from the previous section using named
capture. In Perl or Ruby, you have to put angle brackets or quotes around the
name of the group, and put that between the conditional's 
parentheses: ${E_WHITE_FG}(?<test>a)?b(?(<test>)c|d)${E_RESET} or 
${E_WHITE_FG}(?'test'a)?b(?('test')c|d)${E_RESET}. PCRE supports all three
variants.

PCRE 7.2 and later and JGsoft V2 also support relative conditionals. The syntax
is the same as that of a conditional that references a numbered capturing group
with an added plus or minus sign before the group number. The conditional then
counts the opening parentheses to the left (minus) or to the right (plus)
starting at the ${E_WHITE_FG}(?(${E_RESET} that opens the conditional. ${E_WHITE_FG}(a)?b(?(-1)c|d)${E_RESET} is another way
of writing the above regex. The benefit is that this regex won't break if you
add capturing groups at the start or the end of the regex.

Python supports conditionals using a numbered or named capturing group. Python
does not support conditionals using look-around, even though Python does support
look-around outside conditionals. Instead of a conditional like ${E_WHITE_FG}(?(?=regex)then|
else)${E_RESET}, you can alternate two opposite look-arounds: ${E_WHITE_FG}(?=regex)then|(?!regex)else${E_RESET}.

${E_WHITE_FG}Conditionals Referencing Non-Existent Capturing Groups${E_RESET}

Boost and Ruby treat a conditional that references a non-existent capturing
group as an error. The latest versions of all other flavors discussed in this
tutorial don't. They simply let such conditionals always attempt the "else"
part. A few flavors changed their minds, though. Python 3.4 and prior and PCRE
7.6 and prior (and thus PHP 5.2.5 and prior) used to treat them as errors.

${E_WHITE_FG}Example: Extract Email Headers${E_RESET}

The regex ${E_WHITE_FG}^((From|To)|Subject): ((?(2)\w+@\w+\.[a-z]+|.+))${E_RESET} extracts the From,
To, and Subject headers from an email message. The name of the header is
captured into the first backreference. If the header is the ${E_WHITE_FG}From${E_RESET} or ${E_WHITE_FG}To${E_RESET} header,
it is captured into the second backreference as well.

The second part of the pattern is the if-then-else conditional 
${E_WHITE_FG}(?(2)\w+@\w+\.[a-z]+|.+))${E_RESET}. The if part checks whether the second capturing group took part in
the match thus far. It will have taken part if the header is the ${E_WHITE_FG}From${E_RESET} or ${E_WHITE_FG}To${E_RESET}
header. In that case, the then part of the conditional ${E_WHITE_FG}\w+@\w+\.[a-z]+${E_RESET} tries to
match an email address. To keep the example simple, we use an overly simple
regex to match the email address, and we don't try to match the display name
that is usually also part of the ${E_WHITE_FG}From${E_RESET} or ${E_WHITE_FG}To${E_RESET} header.

If the second capturing group did not participate in the match this far, the
else part ${E_WHITE_FG}.+${E_RESET} is attempted instead. This simply matches the remainder of the
line, allowing for any test subject.

Finally, we place an extra pair of parentheses around the conditional. This
captures the contents of the email header matched by the conditional into the
third backreference. The conditional itself does not capture anything. When
implementing this regular expression, the first capturing group will store the
name of the header ${E_WHITE_FG}("From", "To", or "Subject")${E_RESET}, and the third capturing group
will store the value of the header.

You could try to match even more headers by putting another conditional into
the "else" part. 
E.g. ${E_WHITE_FG}^((From|To)|(Date)|Subject): ((?(2)\w+@\w+\.[a-z]+|(?(3) mm/dd/yyyy|.+)))${E_RESET} 
would match a "From", "To", "Date" or "Subject", and use the
regex ${E_WHITE_FG}mm/dd/yyyy${E_RESET} to check whether the date is valid. Obviously, the date
validation regex is just a dummy to keep the example simple. The header is
captured in the first group, and its validated contents in the fourth group.

As you can see, regular expressions using conditionals quickly become unwieldy.
I recommend that you only use them if one regular expression is all your tool
allows you to use. When programming, you're far better of using the regex 
${E_WHITE_FG}^(From|To|Date|Subject): (.+)${E_RESET} to capture one header with its unvalidated
contents. In your source code, check the name of the header returned in the
first capturing group, and then use a second regular expression to validate the
contents of the header returned in the second capturing group of the first
regex. Though you'll have to write a few lines of extra code, this code will be
much easier to understand and maintain. If you precompile all the regular
expressions, using multiple regular expressions will be just as fast, if not
faster, than the one big regex stuffed with conditionals.

${E_WHITE_FG}In Depth - look-ahead - look-behind${E_RESET}

look-ahead Example: Simple Password Validation
Let's get our feet wet right away with an expression that validates a password. The technique shown here will be useful for all 
kinds of other data you might want to validate (such as email addresses or phone numbers). 
Our password must meet four conditions:

1. The password must have between six and ten word characters \w
2. It must include at least one lowercase character [a-z]
3. It must include at least three uppercase characters [A-Z]
4. It must include at least one digit \d

We'll assume we're working in a regex flavor where \d only matches ASCII digits 0 through 9, unlike .NET and Python where that 
token can match any Unicode digit.

With look-arounds, ${E_WHITE_FG}your feet stay planted on the string. You're just looking, not moving${E_RESET}! Our initial strategy (which we'll later 
tweak) will be to stand at the beginning of the string and look ahead four times—once for each condition. We'll look to check we 
have the right number of characters, then we'll look for a lowercase letter, and so on. If all the look-aheads are successful, we'll 
know the string is a valid password… And we'll simply gobble it all up with a plain .* 

${E_WHITE_FG}Condition 1${E_RESET}

A string that is made of six-to-ten word characters can be written like this: ${E_WHITE_FG}\A\w{6,10}\z${E_RESET}
The ${E_WHITE_FG}\A${E_RESET} anchor asserts that the current position is the beginning of the string. After matching the six to ten word characters, the 
${E_WHITE_FG}\z${E_RESET} anchor asserts that the current position is the end of the string. 

Within a look-ahead, this pattern becomes ${E_WHITE_FG}(?=\A\w{6,10}\z)${E_RESET}. This look-ahead asserts: at the current position in the string, what 
follows is the beginning of the string, six to ten word characters, and the very end of the string. 

We want to make this assertion at the very beginning of the string. Therefore, to continue building our pattern, we want to anchor 
the look-ahead with an ${E_WHITE_FG}\A${E_RESET}. There is no need to duplicate the ${E_WHITE_FG}\A${E_RESET}, so we can take it out of the look-ahead. Our pattern becomes:
${E_WHITE_FG}\A(?=\w{6,10}\z)${E_RESET}

So far, we have an expression that validates that a string is entirely composed of six to ten word characters. Note that we haven't 
matched any of these characters yet: we have only looked ahead. The current position after the look-ahead is still the beginning of 
the string. To check the other conditions, we just add look-aheads.

${E_WHITE_FG}Condition 2${E_RESET}

For our second condition, we need to check that the password contains one lowercase letter. To find one lowercase letter, the 
simplest idea is to use ${E_WHITE_FG}.*[a-z]${E_RESET}. That works, but the ${E_WHITE_FG}dot-star${E_RESET} first shoots down to the end of the string, so we will always need to 
backtrack. Just for the sport, can we think of something more efficient? You might think of making the star quantifier reluctant by 
adding a ${E_WHITE_FG}?${E_RESET}, giving us ${E_WHITE_FG}.*?[a-z]${E_RESET}, but that too requires backtracking as a lazy quantifier requires backtracking at each step.

For this type of situation, I recommend you use something like [^a-z]*[a-z] (or even better, depending on your engine, the atomic 
${E_WHITE_FG}(?>[^a-z]*)[a-z]${E_RESET} or possessive version ${E_WHITE_FG}[^a-z]*+[a-z]${E_RESET} — but we'll discuss that in the footnotes). The negated character class [^a-z] 
is the counterclass of the lowercase letter [a-z] we are looking for: it matches one character that is not a lowercase letter, and 
the ${E_WHITE_FG}*${E_RESET} quantifier makes us match zero or more such characters. The pattern  ${E_WHITE_FG}[^a-z]*[a-z]${E_RESET} is a good example of the principle of 
contrast recommended by the regex style guide. 

Let's use this pattern inside a look-ahead: ${E_WHITE_FG}(?=[^a-z]*[a-z])${E_RESET}
The look-ahead asserts: at this position in the string (i.e., the beginning of the string), we can match zero or more characters 
that are not lowercase letters, then we can match one lowercase letter: ${E_WHITE_FG}[a-z${E_RESET}
Our pattern becomes: ${E_WHITE_FG}\A(?=\w{6,10}\z)(?=[^a-z]*[a-z])${E_RESET}

At this stage, we have asserted that we are at the beginning of the string, and we have looked ahead twice. We still haven't 
matched any characters. Note that on a logical level it doesn't matter which condition we check first. If we swapped the order of 
the look-aheads, the result would be the same. 

We have two more conditions to satisfy: two more look-aheads. 

${E_WHITE_FG}Condition 3${E_RESET}

For our third condition, we need to check that the password contains at least three uppercase letters. The logic is similar to 
condition 2: we look for an optional number of non-uppercase letters, then one uppercase letter… But we need to repeat that three 
times, for which we'll use the quantifier ${E_WHITE_FG}{3}${E_RESET}. 
We'll use this look-ahead: ${E_WHITE_FG}(?=(?:[^A-Z]*[A-Z]){3})${E_RESET} 

The look-ahead asserts: at this position in the string (i.e., the beginning of the string), we can do the following three times: 
match zero or more characters that are not uppercase letters (the job of the negated character class ${E_WHITE_FG}[^A-Z]${E_RESET} with the quantifier ${E_WHITE_FG}*)${E_RESET}, 
then match one uppercase letter: ${E_WHITE_FG}[A-Z]${E_RESET}
Our pattern becomes: 
${E_WHITE_FG}\A(?=\w{6,10}\z)(?=[^a-z]*[a-z])(?=(?:[^A-Z]*[A-Z]){3})${E_RESET}

At this stage, we have asserted that we are at the beginning of the string, and we have looked ahead three times. We still haven't 
matched any characters. 

${E_WHITE_FG}Condition 4${E_RESET}

To check that the string contains at least one digit, we use this look-ahead: ${E_WHITE_FG}(?=\D*\d)${E_RESET}. Opposing ${E_WHITE_FG}\d${E_RESET} to its counterclass ${E_WHITE_FG}\D${E_RESET} makes 
good use of the regex principle of contrast. 

The look-ahead asserts: at this position in the string (i.e., the beginning of the string), we can match zero or more characters 
that are not digits (the job of the "not-a-digit" character class ${E_WHITE_FG}\D${E_RESET} and the * quantifier), then we can match one digit: ${E_WHITE_FG}\d${E_RESET}
Our pattern becomes: ${E_WHITE_FG}\A(?=\w{6,10}\z)(?=[^a-z]*[a-z])(?=(?:[^A-Z]*[A-Z]){3})(?=\D*\d)${E_RESET}

At this stage, we have asserted that we are at the beginning of the string, and we have looked ahead four times to check our four 
conditions. We still haven't matched any characters, but we have validated our string: we know that it is a valid password. 

If all we wanted was to validate the password, we could stop right there. But if for any reason we also need to match and return 
the entire string—perhaps because we ran the regex on the output of a function and the password's characters haven't yet been 
assigned to a variable — we can easily do so now. 

${E_WHITE_FG}Matching the Validated String${E_RESET}

After checking that the string conforms to all four conditions, we are still standing at the beginning of the string. The five 
assertions we have made (the anchor ${E_WHITE_FG}\A${E_RESET} and the four look-aheads) have not changed our position. At this stage, we can use a simple 
.* to gobble up the string: we know that whatever characters are matched by the ${E_WHITE_FG}dot-star${E_RESET}, the string is a valid password. The 
pattern becomes: ${E_WHITE_FG}\A(?=\w{6,10}\z)(?=[^a-z]*[a-z])(?=(?:[^A-Z]*[A-Z]){3})(?=\D*\d).*${E_RESET}

${E_WHITE_FG}Fine-Tuning: Removing One Condition${E_RESET}

For ${E_WHITE_FG}n${E_RESET} conditions,
use ${E_WHITE_FG}n-1${E_RESET} look-aheads If you examine our look-aheads, you may notice that the pattern ${E_WHITE_FG}\w{6,10}\z${E_RESET} inside the first one examines all the 
characters in the string. Therefore, we could have used this pattern to match the whole string instead of the ${E_WHITE_FG}dot-star .*${E_RESET} 

This allows us to remove one look-ahead and to simplify the pattern to this:

${E_WHITE_FG}\A(?=[^a-z]*[a-z])(?=(?:[^A-Z]*[A-Z]){3})(?=\D*\d)\w{6,10}\z${E_RESET}

The pattern ${E_WHITE_FG}\w{6,10}\z${E_RESET} now serves the double purpose of matching the whole string and of ensuring that the string is entirely 
composed of six to ten word characters. 

Generalizing this result, if you must check for ${E_WHITE_FG}n${E_RESET} conditions, your pattern only needs to include ${E_WHITE_FG}n-1${E_RESET} look-aheads at the most. Often, 
you are even able to combine several conditions into a single look-ahead. 

You may object that we were able to use \w{6,10}\z because it happened to match the whole string. Indeed that was the case. But we 
could also have converted any of the other three look-aheads to match the entire string. For instance, taking the look-ahead 
${E_WHITE_FG}(?=\D*\d)${E_RESET} which checks for the presence of one digit, we can add a simple ${E_WHITE_FG}.*\z${E_RESET} to get us to the end of the string.

The pattern would have become:
${E_WHITE_FG}\A(?=\w{6,10}\z)(?=[^a-z]*[a-z])(?=(?:[^A-Z]*[A-Z]){3})\D*\d.*\z${E_RESET}

By the way, you may wonder why I bother using the ${E_WHITE_FG}\z${E_RESET} after the ${E_WHITE_FG}.*${E_RESET}: shouldn't it get me to the end of the string? In general, not 
so: unless we're in DOTALL mode, the dot doesn't match line breaks. Therefore, the ${E_WHITE_FG}.*${E_RESET} only gets you to the end of the first line. 
After this, the string may have line breaks and many more line. A ${E_WHITE_FG}\z${E_RESET} anchor ensures that after the .* we have reached not only the 
end of the line, but also the end of the string. 

In this particular pattern, the first look-around ${E_WHITE_FG}(?=\w{6,10}\z)${E_RESET} already ensures that there cannot be any line breaks in the string, 
so the final ${E_WHITE_FG}\z${E_RESET} is not strictly necessary. 

${E_WHITE_FG}The Order of look-aheads Doesn't Matter… Almost${E_RESET}

In our password validation pattern, since the three look-aheads don't change our position in the string, we can rearrange them in 
any order without affecting the overall logic. 

While the order of look-aheads doesn't matter on a logical level, keep in mind that it may matter for matching speed. If one 
look-ahead is more likely to fail than the other two, it makes little sense to place it in third position and expend a lot of energy 
checking the first two conditions. Make it first, so that if we're going to fail, we fail early—an application of the design to 
fail principle from the regex style guide. 

In fact, this is what we do by placing the anchor ${E_WHITE_FG}\A${E_RESET} in first position. Since it is an assertion that doesn't consume characters, 
it too could swap positions with any of the look-aheads. We'll see why this is a bad idea, but first… 

In passing, consider that ${E_WHITE_FG}\A${E_RESET} can be written with look-arounds: in DOTALL mode, where the dot matches any character including line 
breaks, the negative look-behind ${E_WHITE_FG}(?<!.)${E_RESET} asserts that what precedes the current position is not any character—therefore the 
position must be the beginning of the string. Without DOTALL mode, the negative look-behind ${E_WHITE_FG}(?<![\D\d])${E_RESET} asserts the same, since 
${E_WHITE_FG}[\D\d]${E_RESET} matches one character that is either a digit or a non-digit—in other words, any character. 

Now imagine we set ${E_WHITE_FG}\A${E_RESET} in fourth position, after the three look-aheads. The resulting match would be the same, but it could take a 
lot more time. For instance, suppose the third look-ahead (whose job it is to assert that the string contains at least one digit) 
fails. After failing to find a match at the first position in the string, the engine advances to the second position and tries the 
look-aheads again, one after the other. Once more, the third look-ahead is bound to fail to find a digit. After each failure, the 
engine will start a new match attempt starting at the next position in the string. Even when the two first look-aheads succeed (and 
they may fail, as the uppercase or lowercase letter they check for may have been the lone one in the string, and at a position 
already passed), the third look-ahead will always fail to find a digit. Therefore the anchor ${E_WHITE_FG}\A${E_RESET} is never even attempted: the pattern 
fails before the engine reaches that token. 

In contrast, when ${E_WHITE_FG}\A${E_RESET} is first, it can only match at the first position in the string. The third look-ahead still fails, but when the 
engine tries to match at further positions, the ${E_WHITE_FG}\A${E_RESET} immediately fails, so the engine doesn't need to waste any more time with the 
look-aheads. 

${E_WHITE_FG}Lookarounds Stand their Ground${E_RESET}

If I seem to be flogging a dead horse here, it's only because this point is the most common source of confusion with look-arounds. 
As the password validation example made clear, look-arounds stand their ground. They look immediately to the left or right of the 
engine's current position on the string—but do not alter that position. 

Therefore, do not expect the pattern ${E_WHITE_FG}A(?=5)${E_RESET} to match the ${E_WHITE_FG}A${E_RESET} in the string ${E_WHITE_FG}AB25${E_RESET}. Many beginners assume that the look-ahead says that 
"there is a ${E_WHITE_FG}5${E_RESET} somewhere to the right", but that is not so. After the engine matches the ${E_WHITE_FG}A${E_RESET}, the look-ahead ${E_WHITE_FG}(?=5)${E_RESET} asserts that at the 
current position in the string, what immediately follows is a 5. If you want to check if there is a 5 somewhere (anywhere) to the 
right, you can use ${E_WHITE_FG}(?=[^5]*5)${E_RESET}. 

Moreover, don't expect the pattern ${E_WHITE_FG}A(?=5)(?=[A-Z])${E_RESET} to match the ${E_WHITE_FG}A${E_RESET} in the string ${E_WHITE_FG}A5B${E_RESET}. Many beginners assume that the second 
look-ahead looks to the right of the first look-ahead. It is not so. At the end of the first look-ahead, the engine is still planted 
at the very same spot in the string, after the ${E_WHITE_FG}A${E_RESET}. When the look-ahead ${E_WHITE_FG}(?=[A-Z])${E_RESET} tries to assert that what immediately follows the 
current position is an uppercase letter, it fails because the next character is still the ${E_WHITE_FG}5${E_RESET}. If you want to check that the ${E_WHITE_FG}5${E_RESET} is 
followed by an uppercase letter, just state it in the first look-ahead: ${E_WHITE_FG}(?=5[A-Z])${E_RESET} 

So look-ahead and look-behind don't mean "look way ahead into the distance". They mean "look at the text immediately to the left or 
to the right". If you want to inspect a piece of string further down, you will need to insert "binoculars" inside the look-ahead to 
get you to the part of the string you want to inspect — for instance a ${E_WHITE_FG}.*${E_RESET}, or, ideally, more specific tokens.

${E_WHITE_FG}Various Uses for Lookarounds${E_RESET}

Before we dive into interesting but sometimes terse details, let's get excited about look-arounds by surveying some of their 
terrific uses. 

${E_WHITE_FG}Validation${E_RESET}

The password validation section showed how the combination of several look-aheads can impose a number of conditions on the string to 
be matched, allowing us to validate it with a single pattern. 

${E_WHITE_FG}Restricting a Character Range (Subtraction, Intersection)${E_RESET}

Suppose you want to match one word character \w as long as it is not the letter Q. There are several ways to do it without 
look-arounds:
✽ In engines that support character class subtraction, you can use ${E_WHITE_FG}[\w-[Q]]${E_RESET} (.NET), ${E_WHITE_FG}[\w&&[^Q]]${E_RESET} (Java and Ruby 1.9+) or ${E_WHITE_FG}[\w--Q]${E_RESET} 
(Python with the alternate regex module)
✽ You can build a character class such as ${E_WHITE_FG}[_0-9a-zA-PR-Z]${E_RESET}
✽ You can use ${E_WHITE_FG}[^\WQ]${E_RESET} — an example of an obnoxious double-negative character range. 

If your engine doesn't support character class subtraction, the simplest may be to use the workaround shown on the page about class 
operations. This uses a look-ahead to restrict the character class ${E_WHITE_FG}\w: (?!Q)\w${E_RESET}
After the negative look-ahead asserts that what follows the current position is not a ${E_WHITE_FG}Q${E_RESET}, the ${E_WHITE_FG}\w${E_RESET} matches a word character. 

Not only is this solution easy to read, it is also easy to maintain if we ever decide to exclude the letter ${E_WHITE_FG}K${E_RESET} instead of ${E_WHITE_FG}Q${E_RESET}, or to 
exclude both: ${E_WHITE_FG}(?![QK])\w${E_RESET}

Note that we can also perform the same exclusion task with a negative look-behind:
${E_WHITE_FG}\w(?<!Q)${E_RESET}
After the ${E_WHITE_FG}\w${E_RESET} matches a word character, the negative look-behind asserts that what precedes the current position is not a ${E_WHITE_FG}Q${E_RESET}. 

Using the same idea, if we wanted to match one character in the Arabic script as long as it is not a number, we could use this 
pattern:
${E_WHITE_FG}(?!\p{N})\p{Arabic}${E_RESET}
This would work in Perl, PCRE (C, PHP, R…) and Ruby 2+. In .NET and Java, you would use ${E_WHITE_FG}(?!\p{N})\p{IsArabic}${E_RESET}

Likewise, we can use this technique to perform a DIY character class intersection. For instance, to match one character in the 
Arabic script as long as it is a number, we transform the negative look-ahead above to a positive look-ahead. In the Perl / PCRE / 
Ruby version, this gives us:
${E_WHITE_FG}(?=\p{N})\p{Arabic}${E_RESET}

This is basically the password validation technique with two conditions applied to a single character. 

Needless to say, you can interchange the content of the look-ahead with the token to be matched:
${E_WHITE_FG}(?=\p{Arabic})\p{N}${E_RESET}

${E_WHITE_FG}Tempering the scope of a token${E_RESET}

This use is similar to the last. Instead of removing characters from a class, it restricts the scope within which a token is 
allowed to match.

For instance, suppose we want to match any character as long as it is not followed by ${E_WHITE_FG}{END}${E_RESET}. Using a negative look-ahead, we can use:
${E_WHITE_FG}(?:(?!{END}).)*${E_RESET}
Each . token is tempered by ${E_WHITE_FG}(?!{END})${E_RESET}, which specifies that the dot cannot be the beginning of ${E_WHITE_FG}{END}${E_RESET}. This technique is called 
tempered greedy token on the Quantifiers page.

Another technique is:
${E_WHITE_FG}(?:[^{]++|{(?!END}))*+${E_RESET}
On the left side of the alternation, ${E_WHITE_FG}[^{]++${E_RESET} matches characters that are not an opening brace. On the right side, ${E_WHITE_FG}{(?!END})${E_RESET} matches 
an opening brace that is not followed by ${E_WHITE_FG}END}${E_RESET}. This technique appears in the Explicit Greedy Alternation section of the Quantifiers 
page.

${E_WHITE_FG}Delimiter${E_RESET}

Do you have a string where you want to start matching all characters once the first instance of ${E_WHITE_FG}#START#${E_RESET} is passed? No problem, just 
use a look-behind to make a delimiter:
${E_WHITE_FG}(?<=#START#).*${E_RESET}
After the look-behind asserts that what immediately precedes the current position is ${E_WHITE_FG}#START#${E_RESET}, the ${E_WHITE_FG}dot-star .*${E_RESET} matches all the 
characters to the right. 

Or would you like to match all characters in a string up to, but not including the characters #END#? Make a delimiter using a 
look-ahead:
${E_WHITE_FG}.*?(?=#END#)${E_RESET}

You can, of course, combine the two:
${E_WHITE_FG}(?<=#START#).*?(?=#END#)${E_RESET}

See the page on boundaries for advice on building fancy DIY delimiters. 

${E_WHITE_FG}Inserting Text at a Position${E_RESET}

Someone gave you a file full of film titles in CamelCase, such as HaroldAndKumarGoToWhiteCastle. To make it easier to read, you 
want to insert a space at each position between a lowercase letter and an uppercase letter. This regex matches these exact 
positions: 
${E_WHITE_FG}(?<=[a-z])(?=[A-Z])${E_RESET}

In your text editor's regex replacement function, all you have to do is replace the matches space characters, and spaces be 
inserted in the right spot. 

This regex is what's known as a "zero-width match" because it matches a position without matching any actual characters. How does 
it work? The look-behind asserts that what immediately precedes the current position is a lowercase letter. And the look-ahead 
asserts that what immediately follows the current position is an uppercase letter. 

${E_WHITE_FG}Splitting a String at a Position${E_RESET}

We can use the exact same regex from the previous example to split the string ${E_WHITE_FG}AppleOrangeBananaStrawberryPeach${E_RESET} into a list of 
fruits. Once again, the regex
${E_WHITE_FG}(?<=[a-z])(?=[A-Z])${E_RESET}
matches the positions between a lowercase letter and an uppercase letter. 

In most languages, when you feed this regex to the function that uses a regex pattern to split strings, it returns an array of 
words. 

Note that Python's re module does not split on zero-width matches—but the far superior regex module does. 

${E_WHITE_FG}Finding Overlapping Matches${E_RESET}

Sometimes, you need several matches within the same word. For instance, suppose that from a string such as ${E_WHITE_FG}ABCD${E_RESET} you want to extract 
${E_WHITE_FG}ABCD, BCD, CD and D${E_RESET}. You can do it with this single regex:
${E_WHITE_FG}(?=(\w+))${E_RESET}
When you allow the engine to find all matches, all the substrings will be captured to Group 1

How does this work?

At the first position in the string (before the ${E_WHITE_FG}A)${E_RESET}, the engine starts the first match attempt. The look-ahead asserts that what 
immediately follows the current position is one or more word characters, and captures these characters to Group 1. The look-ahead 
succeeds, and so does the match attempt. Since the pattern didn't match any actual characters (the look-ahead only looks), the 
engine returns a zero-width match (the empty string). It also returns what was captured by Group 1: ${E_WHITE_FG}ABCD${E_RESET}

The engine then moves to the next position in the string and starts the next match attempt. Again, the look-ahead asserts that what 
immediately follows that position is word characters, and captures these characters to Group 1. The match succeeds, and Group 1 
contains ${E_WHITE_FG}BCD${E_RESET}. 

The engine moves to the next position in the string, and the process repeats itself for ${E_WHITE_FG}CD${E_RESET} then ${E_WHITE_FG}D${E_RESET}. 

In .NET, which has infinite look-behind, you can find overlapping matches from the other side of the string. For instance, on the 
same string ${E_WHITE_FG}ABCD${E_RESET}, consider this pattern:
${E_WHITE_FG}(?<=(\w+))${E_RESET}

It will capture ${E_WHITE_FG}A, AB, ABC and ABCD${E_RESET}. To achieve the same in an engine that doesn't support infinite look-behind, you would have to 
reverse the string, use the look-ahead version  ${E_WHITE_FG}(?=(\w+))${E_RESET} then reverse the captures.

${E_WHITE_FG}Zero-Width Matches${E_RESET}

As we've seen, a look-around looks left or right but it doesn't add any characters to the match to be returned by the regex engine. 
Likewise, an anchor such as ^ and a boundary such as ${E_WHITE_FG}\b${E_RESET} can match at a given position in the string, but they do not add any 
characters to the match.

Usually, look-aheads, look-behinds, anchors and boundaries appear in patterns that contain tokens that do match characters, allowing 
the engine to return a matched string. For instance, in ${E_WHITE_FG}(?<=start_)\d+${E_RESET}, the engine matches and returns some digits, but not the 
prefix ${E_WHITE_FG}start_${E_RESET}

However, if a pattern only contains look-arounds, anchors and boundaries, the engine may be able to match the pattern without 
matching any characters. The resulting match is called a zero-width match because it contains no characters.

This can be a useful technique, and we have already seen some applications of zero-width matches in the section on uses for 
look-arounds. To bring them together under one heading, here are some of their main uses. 

${E_WHITE_FG}Validation${E_RESET}

If you string several look-arounds in a row, you can validate that a string conforms to a set of rules, as in the password 
validation technique. 

We saw that when you have n conditions, if you also want to match the string, you usually need n-1 look-arounds at the most as one 
condition can be removed and used in the matching section of the pattern. But if all you want to do is validate, all the conditions 
can stay inside look-arounds, giving you a zero-width match. 

${E_WHITE_FG}Inserting${E_RESET}

You can use a zero-width match regex to match a position in a string and insert text at that position. For instance, by matching 
${E_WHITE_FG}(?m)^${E_RESET} (the beginning of a line in multiline mode) and replacing the match with ${E_WHITE_FG}//${E_RESET} , you can add a prefix to every line of a file.

Likewise, we saw how the zero-width pattern ${E_WHITE_FG}(?<=[a-z])(?=[A-Z])${E_RESET} allows you to insert characters in a CamelCase word. 

${E_WHITE_FG}Splitting${E_RESET}

We saw how the same zero-width pattern ${E_WHITE_FG}(?<=[a-z])(?=[A-Z])${E_RESET} allows you to split a CamelCase word into its components. 

${E_WHITE_FG}Overlapping Matches${E_RESET}

We saw how an unanchored look-around that contains capture groups—such as ${E_WHITE_FG}(?=(\w+))${E_RESET} — allows you to match overlapping string 
segments. 

${E_WHITE_FG}Positioning the Lookaround${E_RESET}

Often, you have two options for positioning a look-around: before the text to be matched, or after. Usually, one of the options is 
more efficient because it requires less work of the engine.

To illustrate this, here are examples for each kind of look-around. I borrowed them from the look-arounds section of the main syntax 
page, where they are discussed in greater detail. 

${E_WHITE_FG}look-ahead${E_RESET}

${E_WHITE_FG}\d+(?= dollars)${E_RESET} and ${E_WHITE_FG}(?=\d+ dollars)\d+${E_RESET} both match ${E_WHITE_FG}100${E_RESET} in ${E_WHITE_FG}100${E_RESET} dollars, but the first is more efficient because the engine needs to 
match ${E_WHITE_FG}\d+${E_RESET} only once. 

${E_WHITE_FG}Negative look-ahead${E_RESET}

${E_WHITE_FG}\d+(?! dollars)${E_RESET} and ${E_WHITE_FG}(?!\d+ dollars)\d+${E_RESET} both match 100 in 100 pesos, but the first is more efficient because the engine needs to 
match \d+ only once. 

${E_WHITE_FG}look-behind${E_RESET}

${E_WHITE_FG}(?<=USD)\d{3}${E_RESET} and ${E_WHITE_FG}\d{3}(?<=USD\d{3})${E_RESET} both match ${E_WHITE_FG}100${E_RESET} in ${E_WHITE_FG}USD100${E_RESET}, but the first is more efficient because the engine needs to match 
${E_WHITE_FG}\d{3}${E_RESET} only once. 

${E_WHITE_FG}Negative look-behind${E_RESET}

${E_WHITE_FG}(?<!USD)\d{3}${E_RESET} and ${E_WHITE_FG}\d{3}(?<!USD\d{3})${E_RESET} both match ${E_WHITE_FG}100${E_RESET} in ${E_WHITE_FG}JPY100${E_RESET}, but the first is more efficient because the engine needs to match 
${E_WHITE_FG}\d{3}${E_RESET} only once. 

What may not be so clear is that each of these look-arounds can be used in two main ways: before the expression to be matched, or 
after it. These two ways have a slightly different feel. Please don't obsess over the differences; rather, just cruise through 
these simple examples to become familiar with the types of effects you can achieve. 

When you compare each pair, the two methods have a different feel. The point of the examples is not to make you memorize "the right 
position", but to expose you to those two basic feels. Once you're familiar with them, you will naturally think of rewriting a 
look-around that feels too heavy. With a bit of practice, the efficient way of positioning your look-arounds will probably come to 
you naturally. 

${E_WHITE_FG}Lookarounds that Look on Both Sides: Back to the Future${E_RESET}

Suppose you want to match a two-digit number surrounded by underscores as in ${E_WHITE_FG}_12_${E_RESET} but not the underscores. 

We have already seen three ways to do this:
✽ You can match everything and capture the digits to Group 1: ${E_WHITE_FG}_(\d{2})_${E_RESET}
✽ You can use a look-behind and a look-ahead: ${E_WHITE_FG}(?<=_)\d{2}(?=_)${E_RESET}
✽ You can use ${E_WHITE_FG}\K${E_RESET} to drop the first underscore from the match: ${E_WHITE_FG}_\K\d{2}(?=_)${E_RESET}

There is a fourth technique I'd like to introduce you to. I call it the "back to the future look-behind." There shouldn't be any 
reason to use it on its own, but sometimes within an intricate pattern it may just what you need, so it's nice to be familiar with 
it and add it to your repertoire.

We can position our back-to-the-future look-behind before or after the digits. Let's start with the before version:
${E_WHITE_FG}(?<=_(?=\d{2}_))\d+${E_RESET}

Wowzy, what does this do? The look-behind asserts that what immediately precedes the current position in the string is an 
underscore, then a position where the look-ahead ${E_WHITE_FG}(?=\d{2}_)${E_RESET} can assert that what immediately follows is two digits and an underscore.

This is interesting for several reasons. First, we have a look-ahead within a look-behind, and even though we were supposed to look 
backwards, this look-ahead jumps over the current position by matching the two digits and the trailing underscore. That's acrobatic. 

Second, note that even though it looks complex, this is a fixed-width look-behind (the width is one character, the underscore), so 
it should work in all flavors of look-behind. (However, it does not work in Ruby as Ruby does not allow look-aheads and negative 
look-behinds inside look-behind.) 

Another interesting feature is how the notion of "current position in the string" is not the same for the look-behind and for the 
look-ahead. You'll remember that look-arounds stand their ground, so that after checking the assertion made by a look-around, the 
engine hasn't moved in the string. Are we breaking that rule?

We're not. In the string ${E_WHITE_FG}10 _16_ 20${E_RESET}, let's say the engine has reached the position between the underscore and the ${E_WHITE_FG}1${E_RESET} in ${E_WHITE_FG}16${E_RESET}. The 
look-behind makes an assertion about what can be matched at that position. When the engine exits the look-behind, it is still 
standing in that same spot, and the token ${E_WHITE_FG}\d{2}${E_RESET} can proceed to match the characters ${E_WHITE_FG}16${E_RESET}. 

But within the look-behind itself, we enter a different little world. You can imagine that outside that world the engine is red, and 
inside the little world of the look-behind, there is another little engine which is yellow. That yellow engine keeps track of its 
own position in the string. In most engines (.NET proceeds differently), the yellow engine is initially dropped at a position in 
the string that is found by taking the red engine's position and subtracting the width of the look-behind, which is 1. The yellow 
engine therefore starts its work before the leading underscore. Within the look-behind's little world, after matching the underscore 
token, the yellow engine's position in the string is between the underscore and the 1. It is that position that the look-ahead 
refers to when it asserts that at the current position in the string (according to the little world of the look-behind and its 
yellow engine), what immediately follows is two digits and an underscore.

After the digits
Here is a second version where the "back-to-the-future look-behind" comes after the digits:
${E_WHITE_FG}\d+(?<=_\d{2}(?=_))${E_RESET}

The look-behind states: what immediately precedes this position in the string is an underscore and two digits, then a position where 
the look-ahead ${E_WHITE_FG}(?=_)${E_RESET} can assert that what immediately follows the current position in the string (according to the yellow engine and 
the look-behind's little world) is an underscore. 

This too is a fixed-width look-behind (the width is three character, i.e. the leading underscore and the two digits), so it should 
work in all flavors of look-behind except Ruby. 

${E_WHITE_FG}Compound look-ahead and Compound look-behind${E_RESET}

The back-to-the-future look-behind introduced us to what I call compound look-arounds, i.e., look-arounds that contain other 
look-arounds. You could also call them nested look-arounds, but for me the idea of compounding captures something more about the feel 
of working with these constructs. 

Let's look at some examples.

Token followed by one character, but not more
How can you match a number that is followed by one underscore, but not more?

You can use this:
${E_WHITE_FG}\d+(?=_(?!_))${E_RESET}
The look-ahead asserts: what follows the current position in the string is one underscore, then a position where the negative 
look-ahead ${E_WHITE_FG}(?!_)${E_RESET} can assert that what follows is not an underscore. A less elegant variation would be ${E_WHITE_FG}\d+(?=(?!__)_)${E_RESET}

Token preceded by one character, but not more
How can you match a number that is preceded by one underscore, but not more?

You can use this:
${E_WHITE_FG}(?<=(?<!_)_)\d+${E_RESET}
The look-behind asserts: what precedes the current position in the string is a position where the negative look-behind ${E_WHITE_FG}(?<!_)${E_RESET} can 
assert that what immediately precedes is not an underscore, then an underscore. A variation would be ${E_WHITE_FG}(?<=_(?<!__))\d+${E_RESET} 

${E_WHITE_FG}Multiple Compounding${E_RESET}

Needless to say, it won't be long until you find occasions to add levels of compounding beyond the two we've just seen. But that 
quickly becomes obnoxious, and it becomes simpler to rearrange the regex. For instance, building on the previous pattern,
${E_WHITE_FG}(?<=(?<!(?<!X)_)_)\d+${E_RESET}
matches a number that is precede by an underscore that is not preceded by an underscore unless that underscore is preceded by an X. 

In .NET, PCRE, Java and Ruby, this could be simplified to ${E_WHITE_FG}(?<=(?<!_)_|X__)\d+ ${E_RESET}
In Perl and Python, you could use ${E_WHITE_FG}(?:(?<=(?<!_)_)|(?<=X__))\d+ ${E_RESET}

${E_WHITE_FG}The Engine Doesn't Backtrack into Lookarounds…${E_WHITE_FG}because they're atomic${E_RESET}

Here's a fun regex task. You have a string like this:
${E_WHITE_FG}_rabbit _dog _mouse DIC:cat:dog:mouse${E_RESET}

The ${E_WHITE_FG}DIC${E_RESET} section at the end contains a list of allowed animals. Our job is to match all the _tokens named after an allowed animal. 
Therefore, we expect to match ${E_WHITE_FG}_dog${E_RESET} and ${E_WHITE_FG}_mouse${E_RESET}. A look-around helps us do this:

${E_WHITE_FG}_(\w+)\b(?=.*:\1\b)${E_RESET}

After matching the underscore, we capture a word to Group 1. Then the look-ahead ${E_WHITE_FG}(?=.*:\1\b)${E_RESET} asserts what follows the current 
position in the string is zero or more characters, then a colon, then the word captured to Group 1. As hoped, this matches both 
${E_WHITE_FG}_dog and _mouse${E_RESET}.

Now suppose we try a "reversed" approach:

${E_WHITE_FG}_(?=.*:(\w+)\b)\1\b${E_RESET}

This only matches ${E_WHITE_FG}_mouse${E_RESET}. Why?

First let's try to understand what this regex hopes to accomplish. It may not be that obvious, but it illustrates an important 
feature of look-arounds. 

After the engine matches the underscore, the look-ahead ${E_WHITE_FG}(?=.*:(\w+)\b)${E_RESET} asserts that what follows the current position in the string 
is any number of characters, then a colon, then a word (captured to Group 1). After passing that assertion, the back-reference ${E_WHITE_FG}\1${E_RESET} 
matches what was captured into Group 1. 

Let's see how this works out. Remember that our string is 
${E_WHITE_FG}_rabbit _dog _mouse DIC:cat:dog:mouse${E_RESET}

After the ${E_WHITE_FG}underscore${E_RESET} that precedes ${E_WHITE_FG}rabbit${E_RESET}, we expect the look-ahead to fail because there is no ${E_WHITE_FG}rabbit${E_RESET} in the ${E_WHITE_FG}DIC section${E_RESET}—and it 
does. The next time we match an ${E_WHITE_FG}underscore${E_RESET} is before ${E_WHITE_FG}dog${E_RESET}. At that stage, inside the look-ahead ${E_WHITE_FG}(?=.*:(\w+)\b)${E_RESET}, the ${E_WHITE_FG}dot-star${E_RESET} shoots 
down to the end of the string, then backtracks just far enough to allow the colon to match, after which the word ${E_WHITE_FG}mouse${E_RESET} is matched 
and captured to Group 1. The look-ahead succeeds. The next token ${E_WHITE_FG}\1${E_RESET} tries to match ${E_WHITE_FG}mouse${E_RESET}, but the next character in the string is 
the ${E_WHITE_FG}d${E_RESET} from ${E_WHITE_FG}dog${E_RESET}, so the token fails. At this stage, having learned everything about backtracking, we might assume that the regex 
engine allows the ${E_WHITE_FG}dot-star${E_RESET} to backtrack even more inside the look-ahead, up to the previous ${E_WHITE_FG}colon${E_RESET}, which would then allow ${E_WHITE_FG}(\w+)${E_RESET} to 
match and capture ${E_WHITE_FG}mouse${E_RESET}. Then the back-reference ${E_WHITE_FG}\1${E_RESET} would match ${E_WHITE_FG}mouse${E_RESET}, and the engine would return a successful match.

However, it does not work that way. Once the regex engine has left a look-around, it will not backtrack into it if something fails 
somewhere down the pattern. On a logical level, that is because the official point of a look-around is to return one of two values: 
true or false. Once a look-ahead evaluates to true at a given position in the string, it is always true. From the engine's 
standpoint, there is nothing to backtrack. What would be the point—since the only other available value is false, and that would 
fail the pattern? 

The fact that the engine will not backtrack into a look-around means that it is an atomic block. This property of look-arounds will 
rarely matter, but if someday, in the middle of building an intricate pattern, a look-ahead refuses to cooperate… This may be the 
reason. 

${E_WHITE_FG}Fixed-Width, Constrained-Width and Infinite-Width look-behind${E_RESET}

In strings such as 123456_ORANGE abc12_APPLE, suppose you are interested in matching uppercase words, provided they are preceded by 
a prefix composed of digits and an underscore character. Therefore, in this string, you want to match ORANGE but not APPLE. 

It's worth remembering that in most regex flavors (.NET is one of the few exceptions), the following pattern is invalid:

${E_WHITE_FG}(?<=\b\d+_)[A-Z]+${E_RESET}

That is because the width of the text matched by the token ${E_WHITE_FG}\d+${E_RESET} can be anything. Most engines require the width of the subexpression 
within a look-behind to be known in advance, as in ${E_WHITE_FG}(?<=\d{3}) ${E_RESET}

Some engines allow the width of the subexpression within a look-behind to take various pre-determined values found on the various 
sides of an alternation, as in ${E_WHITE_FG}(?<=0|128|\d{6})${E_RESET}. Yet others allow the width to vary within a pre-determined range, as in 
${E_WHITE_FG}(?<=d{2,6})${E_RESET} 

For details of what kinds of widths various engines allow in a look-behind, see the look-behind: Fixed-Width / Constrained Width / 
Infinite Width section of the main syntax page. To honor the winners, I'll just repeat here that the only two programming-language 
flavors that support infinite-width look-behind are .NET (C#, VB.NET, …) and Matthew Barnett's regex module for Python. I've also 
implemented an infinite look-behind demo for PCRE. 

Capture Group Inside Variable look-behind: Difference between Java and .NET
Both Java and .NET allow this pattern: 
${E_WHITE_FG}(?<=(\d{1,5}))Z${E_RESET}

.NET allows it because it supports infinite-width look-behind. Java allows it because it supports look-behind whose width falls 
within a defined range. However, they operate differently. As a result, against the string ${E_WHITE_FG}123Z${E_RESET}, this pattern will return different 
Group 1 captures in the two engines.

✽ Java captures ${E_WHITE_FG}3${E_RESET} to Group 1. The engine sees that the width of the string to be matched inside the look-behind must fall between 
one and five characters. Java tries all the possible fixed-width patterns in the range, from the shortest to the longest, until one 
succeeds. The shortest possible fixed-width pattern is ${E_WHITE_FG}(?<=(\d{1}))${E_RESET}. The engine temporarily skips back one character in the string, 
tries to match ${E_WHITE_FG}\d{1}${E_RESET} and succeeds. The look-around succeeds, and Group 1 contains ${E_WHITE_FG}3${E_RESET}.

✽ .NET captures ${E_WHITE_FG}123${E_RESET} to Group 1. The .NET engine has a far more efficient way of processing variable-width look-behinds. Instead of 
trying multiple fixed-width patterns starting at points further and further back in the string, .NET reverses the string as well as 
the pattern inside the look-behind, then attempts to match that single pattern on the reversed string. Therefore, in ${E_WHITE_FG}123Z${E_RESET}, to try 
the look-behind at the point before ${E_WHITE_FG}Z${E_RESET}, it reverses the portion of string to be tested from ${E_WHITE_FG}123${E_RESET} to ${E_WHITE_FG}321${E_RESET}. Likewise, the look-behind 
${E_WHITE_FG}(?<=(\d{1,5}))${E_RESET} is flipped into the look-ahead ${E_WHITE_FG}(?=(\d{1,5}))${E_RESET}. ${E_WHITE_FG}\d{1,5}${E_RESET} matches ${E_WHITE_FG}321${E_RESET}. Reversing that string, Group 1 contains ${E_WHITE_FG}123${E_RESET}. To 
only capture ${E_WHITE_FG}3${E_RESET} as in Java, you would have to make the quantifier lazy:  ${E_WHITE_FG}(?<=(\d{1,5}?))Z${E_RESET} 

✽ Like .NET, the regex alternate regular expressions module for Python captures ${E_WHITE_FG}123${E_RESET} to Group 1.

${E_WHITE_FG}Workarounds${E_RESET}

There are two main workarounds to the lack of support for variable-width (or infinite-width) look-behind:

✽ Capture groups.
Instead of ${E_WHITE_FG}(?<=\b\d+_)[A-Z]+${E_RESET} , you can use ${E_WHITE_FG}\b\d+_([A-Z]+)${E_RESET}, which matches the digits and underscore you don't want to see, then 
matches and captures to Group 1 the uppercase text you want to inspect. This will work in all major regex flavors.

✽ The ${E_WHITE_FG}\K${E_RESET} "keep out" verb, which is available in Perl, PCRE (C, PHP, R…), Ruby 2+ and Python\'s alternate regex engine.
${E_WHITE_FG}\K${E_RESET} tells the engine to drop whatever it has matched so far from the match to be returned. Instead of ${E_WHITE_FG}(?<=\b\d+_)[A-Z]+${E_RESET}, you can 
therefore use ${E_WHITE_FG}\b\d+_\K[A-Z]+${E_RESET}

Compared with look-behinds, both the ${E_WHITE_FG}\K${E_RESET} and capture group workarounds have limitations:

✽ When you look for multiple matches in a string, at the starting position of each match attempt, a look-behind can inspect the 
characters behind the current position in the string. Therefore, against ${E_WHITE_FG}123${E_RESET}, the pattern ${E_WHITE_FG}(?<=\d)\d${E_RESET} (match a digit preceded by a 
digit) will match both ${E_WHITE_FG}2${E_RESET} and ${E_WHITE_FG}3${E_RESET}. In contrast, ${E_WHITE_FG}\d\K\d${E_RESET} can only match ${E_WHITE_FG}2${E_RESET}, as the starting position after the first match is immediately 
before the ${E_WHITE_FG}3${E_RESET}, and there are not enough digits left for a second match. Likewise, \d(\d) can only capture ${E_WHITE_FG}2${E_RESET}. 

✽ With look-behinds, you can impose multiple conditions (similar to our password validation technique) by using multiple 
look-behinds. For instance, to match a digit that is preceded by a lower-case Greek letter, you can use ${E_WHITE_FG}(?<=\p{Ll})(?<=\p{Greek})\d${E_RESET}. 
The first look-behind ${E_WHITE_FG}(?<=\p{Ll})${E_RESET} ensures that the character immediately to the left is a lower-case letter, and the second 
look-behind ${E_WHITE_FG}(?<=\p{Greek})${E_RESET} ensures that the character immediately to the left belongs to the Greek script. With the workarounds, you 
could use ${E_WHITE_FG}\p{Greek}\K\d${E_RESET} to match a digit preceded by a character in the Greek script (or ${E_WHITE_FG}\p{Greek}(\d)${E_RESET} to capture it), but you 
cannot impose a second condition. To get over this limitation, you could capture the Greek character and use a second regex to 
check that it is a lower-case letter. 

${E_WHITE_FG}Lookarounds (Usually) Want to be Anchored${E_RESET}

Let's imagine we want to match a string consisting of one word, provided it contains at least one digit. This pattern offers a 
reasonable solution—one of several:
${E_WHITE_FG}\A(?=\D*\d)\w+\z${E_RESET}

The ${E_WHITE_FG}\A${E_RESET} anchor asserts that the current position is the beginning of the string. The look-ahead ${E_WHITE_FG}(?=\D*\d)${E_RESET} asserts that at the current 
position (which is still the beginning of the string), we can match zero or more non-digits, then one digit. Next, ${E_WHITE_FG}\w+${E_RESET} matches our 
word. Finally, the ${E_WHITE_FG}\z${E_RESET} anchor asserts that the current position is the end of the string. 

Now consider what happens when we forget the anchor ${E_WHITE_FG}\A${E_RESET} and use ${E_WHITE_FG}(?=\D*\d)\w+\z${E_RESET}. To make our oversight seem less severe, let's assume 
we know that our string always contains an uninterrupted string of word characters. This guarantees that if we find a match, it 
will have to be the right one—at the beginning of the string, as we wanted. So what's the problem? 

Suppose we use our regex on a string composed of one hundred characters ${E_WHITE_FG}V${E_RESET}. Since the string doesn't contain a single digit, you and 
I can immediately see that the regex must fail. Let's see how fast the engine comes to the same conclusion. 

As always, the engine begins by trying to match the pattern at the first position in the string. Starting with the first token 
${E_WHITE_FG}(?=\D*\d)${E_RESET}, it tries to assert that at the current position, i.e. the beginning of the string, it can match zero or more non-digits, 
then one digit. Within the subexpression, the \D* matches all the ${E_WHITE_FG}V${E_RESET} characters. The engine then tries to match a digit, but since 
we have reached the end of the string, that fails. 

If we're using a smart engine such as PCRE, at this stage the engine fails the look-around for this first match attempt. That's 
because before starting the match attempt, the engine has studied the pattern and noticed that the \D and \d tokens are mutually 
exclusive, and it has turned the ${E_WHITE_FG}*${E_RESET} quantifier into a possessive quantifier ${E_WHITE_FG}*+${E_RESET}, a process known to PCRE as auto-possessification 
(see footnote). 

A less clever engine will backtrack, giving up all the \D characters it has matched one by one, each time attempting to match a ${E_WHITE_FG}\d${E_RESET} 
after giving up a ${E_WHITE_FG}\D${E_RESET}. Eventually, the engine runs out of characters to backtrack, and the look-ahead fails.

Once the engine understands that the look-ahead must fail (whether it comes to this conclusion cleverly or clumsily), it gives up on 
the entire first match attempt. Next, as always in such cases, the engine moves to the next position in the string (past the first 
${E_WHITE_FG}V)${E_RESET} and starts a new match attempt. Again, the ${E_WHITE_FG}\D*${E_RESET} eats up all the ${E_WHITE_FG}V${E_RESET} characters—although this time, there are only 99 of them. 
Again, the look-ahead fails, either fast if the engine is smart, or, more likely, after backtracking all the way back to the 
starting position. 

After failing a second time, the engine moves past the second ${E_WHITE_FG}V${E_RESET}, starts a new match attempt, and fails… And so on, all the way to 
the end of the string. 

Because the pattern is not anchored at the beginning of the string, at each match attempt, the engine checks whether the look-ahead 
matches at the current position. In doing so, in the best case, it matches 100 ${E_WHITE_FG}V${E_RESET} characters, then 99 on the second attempt, and so 
on—so it needs about 5000 steps before it can see that the pattern will never match. In the more usual case, the engine needs to 
backtrack and try the ${E_WHITE_FG}\d${E_RESET} at each position, adding two steps at each V position. Altogether, it needs about 15,000 steps before it 
can see that the pattern will never match. 

In contrast, with the original anchored pattern ${E_WHITE_FG}\A(?=\D*\d)\w+\z${E_RESET}, after the engine fails the first match attempt, each of the 
following match attempts at further positions in the string fail instantly, because the ${E_WHITE_FG}\A${E_RESET} fails before the engine gets to the 
look-ahead. In the best case, the engine takes about 200 steps to fail (100 steps to match all the V characters, then one step at 
each of the further match attempts.) In the more usual case, the engine takes about 400 steps to fail (300 steps on the first match 
attempt, then one step at each of the further match attempts.) 

Needless to say, the ratio of (15,000 / 400) steps is the kind of performance hit we try to avoid in computing. This makes a solid 
case for helping the engine along by minimizing the number of times look-aheads must be attempted, either by using anchors such as ${E_WHITE_FG}^${E_RESET} 
and ${E_WHITE_FG}\A${E_RESET}, or by matching literal characters immediately before the look-ahead. 

${E_WHITE_FG}One Exception: Overlapping Matches${E_RESET}

There are times when we do want the engine to attempt the look-ahead at every single position in the string. Usually, the purpose of 
such a maneuver is to match a number of overlapping substrings. For instance, against the string word, if the regex ${E_WHITE_FG}(?=(\w+))${E_RESET} is 
allowed to match repeatedly, it will match four times, and each match will capture a different string to Group 1: ${E_WHITE_FG}word, ord, rd, 
then d${E_RESET}. The section on overlapping matches explains how this works. 

${E_WHITE_FG}Footnotes${E_RESET}

Atomic tweak
The atomic variation ${E_WHITE_FG}(?>[^a-z]*)[a-z]${E_RESET} or possessive version ${E_WHITE_FG}[^a-z]*+[a-z]${E_RESET} are tweaks that ensure that if the engine fails to find 
the lowercase letter, it won't "stupidly" backtrack, giving up the non-lowercase letters one by one to see if a lowercase letter 
might fit at that stage. 

Note that before they start matching, some engines notice the mutually exclusive character of ${E_WHITE_FG}[a-z]${E_RESET} and its counterclass and 
automatically make the ${E_WHITE_FG}*${E_RESET} quantifier possessive for you. This optimization is what PCRE calls auto-possessification. It allows you 
to turn it off with the Special Start-of-Pattern Modifier ${E_WHITE_FG}(*NO_AUTO_POSSESS)${E_RESET} — but why would you ever want to? 

tip_regex_EOF_1

cat << tip_regex_EOF_2
${E_WHITE_FG}look-ahead and look-behind Zero-Length Assertions${E_RESET}

look-ahead and look-behind, collectively called “look-around”, are zero-length
assertions just like the start and end of line, and start and end of word
anchors explained earlier in this tutorial. The difference is that look-around
actually matches characters, but then gives up the match, returning only the
result: match or no match. That is why they are called “assertions”.  They do
not consume characters in the string, but only assert whether a match is
possible or not. Lookaround allows you to create regular expressions that are
impossible to create without them, or that would get very longwinded without
them.

Positive and Negative look-ahead Negative look-ahead is indispensable if you want
to match something not followed by something else. When explaining character
classes, this tutorial explained why you cannot use a negated character class to
match a ${E_WHITE_FG}q${E_RESET} not followed by a ${E_WHITE_FG}u${E_RESET}. Negative look-ahead provides the solution: ${E_WHITE_FG}q(?!u)${E_RESET}.
The negative look-ahead construct is the pair of parentheses, with the opening
parenthesis followed by a question mark and an exclamation point. Inside the
look-ahead, we have the trivial regex ${E_WHITE_FG}u${E_RESET}.

Positive look-ahead works just the same. ${E_WHITE_FG}q(?=u)${E_RESET} matches a ${E_WHITE_FG}q${E_RESET} that is followed by a
${E_WHITE_FG}u${E_RESET}, without making the ${E_WHITE_FG}u${E_RESET} part of the match. The positive look-ahead construct is a
pair of parentheses, with the opening parenthesis followed by a question mark
and an equals sign.

You can use any regular expression inside the look-ahead (but not look-behind, as
explained below). Any valid regular expression can be used inside the
look-ahead. If it contains capturing groups then those groups will capture as
normal and backreferences to them will work normally, even outside the
look-ahead. (The only exception is Tcl, which treats all groups inside look-ahead
as non-capturing.) The look-ahead itself is not a capturing group. It is
not included in the count towards numbering the backreferences. If you want to
store the match of the regex inside a look-ahead, you have to put capturing
parentheses around the regex inside the look-ahead, like this: ${E_WHITE_FG}(?=(regex))${E_RESET}. The
other way around will not work, because the look-ahead will already have
discarded the regex match by the time the capturing group is to store its match.

Regex Engine Internals First, let’s see how the engine applies ${E_WHITE_FG}q(?!u)${E_RESET} to the
string ${E_WHITE_FG}Iraq${E_RESET}. The first token in the regex is the literal ${E_WHITE_FG}q${E_RESET}. As we already know,
this causes the engine to traverse the string until the ${E_WHITE_FG}q${E_RESET} in the string
is matched. The position in the string is now the void after the string.
The next token is the look-ahead. The engine takes note that it is inside
a look-ahead construct now, and begins matching the regex inside the
look-ahead. So the next token is ${E_WHITE_FG}u${E_RESET}. This does not match the void after the
string. The engine notes that the regex inside the look-ahead failed.
Because the look-ahead is negative, this means that the look-ahead has
successfully matched at the current position. At this point, the entire
regex has matched, and ${E_WHITE_FG}q${E_RESET} is returned as the match.

Let’s try applying the same regex to quit. ${E_WHITE_FG}q${E_RESET} matches ${E_WHITE_FG}q${E_RESET}. The next token is the ${E_WHITE_FG}u
${E_RESET}inside the look-ahead. The next character is the ${E_WHITE_FG}u${E_RESET}. These match. The engine
advances to the next character: ${E_WHITE_FG}i${E_RESET}. However, it is done with the regex inside the
look-ahead. The engine notes success, and discards the regex match. This causes
the engine to step back in the string to ${E_WHITE_FG}u${E_RESET}.

Because the look-ahead is negative, the successful match inside it causes the
look-ahead to fail. Since there are no other permutations of this regex, the
engine has to start again at the beginning. Since ${E_WHITE_FG}q${E_RESET} cannot match anywhere else,
the engine reports failure.

Let’s take one more look inside, to make sure you understand the implications of
the look-ahead. Let’s apply ${E_WHITE_FG}q(?=u)i${E_RESET} to quit. The look-ahead is now positive and is
followed by another token. Again, ${E_WHITE_FG}q${E_RESET} matches ${E_WHITE_FG}q${E_RESET} and ${E_WHITE_FG}u${E_RESET} matches ${E_WHITE_FG}u${E_RESET}. Again, the match
from the look-ahead must be discarded, so the engine steps back from ${E_WHITE_FG}i${E_RESET} in the
string to ${E_WHITE_FG}u${E_RESET}. The look-ahead was successful, so the engine continues with ${E_WHITE_FG}i${E_RESET}. But ${E_WHITE_FG}i
${E_RESET}cannot match ${E_WHITE_FG}u${E_RESET}. So this match attempt fails. All remaining attempts fail as
well, because there are no more ${E_WHITE_FG}q${E_RESET}’s in the string.

The regex ${E_WHITE_FG}q(?=u)i${E_RESET} can never match anything. It tries to match ${E_WHITE_FG}u${E_RESET} and ${E_WHITE_FG}i${E_RESET} at the
same position. If there is a ${E_WHITE_FG}u${E_RESET} immediately after the ${E_WHITE_FG}q${E_RESET} then the look-ahead
succeeds but then ${E_WHITE_FG}i${E_RESET} fails to match ${E_WHITE_FG}u${E_RESET}. If there is anything other than a ${E_WHITE_FG}u
${E_RESET}immediately after the ${E_WHITE_FG}q${E_RESET} then the look-ahead fails.

Positive and Negative look-behind look-behind has the same effect, but works
backwards. It tells the regex engine to temporarily step backwards in the
string, to check if the text inside the look-behind can be matched there. ${E_WHITE_FG}(?<!a)b
${E_RESET}matches a “${E_WHITE_FG}b${E_RESET}” that is not preceded by an “${E_WHITE_FG}a${E_RESET}”, using negative look-behind. It
doesn’t match cab, but matches the ${E_WHITE_FG}b${E_RESET} (and only the ${E_WHITE_FG}b${E_RESET}) in ${E_WHITE_FG}bed${E_RESET} or ${E_WHITE_FG}debt${E_RESET}. ${E_WHITE_FG}(?<=a)b
${E_RESET}(positive look-behind) matches the ${E_WHITE_FG}b${E_RESET} (and only the ${E_WHITE_FG}b${E_RESET}) in ${E_WHITE_FG}cab${E_RESET}, but does not match
${E_WHITE_FG}bed${E_RESET} or ${E_WHITE_FG}debt${E_RESET}.

The construct for positive look-behind is ${E_WHITE_FG}(?<=text)${E_RESET}: a pair of parentheses, with
the opening parenthesis followed by a question mark, “less than” symbol, and an
equals sign. Negative look-behind is written as ${E_WHITE_FG}(?<!text)${E_RESET}, using an exclamation
point instead of an equals sign.

More Regex Engine Internals Let’s apply ${E_WHITE_FG}(?<=a)b${E_RESET} to thingamabob. The engine
starts with the look-behind and the first character in the string. In this case,
the look-behind tells the engine to step back one character, and see if ${E_WHITE_FG}a
${E_RESET}can be matched there. The engine cannot step back one character because
there are no characters before the ${E_WHITE_FG}t${E_RESET}. So the look-behind fails, and the
engine starts again at the next character, the ${E_WHITE_FG}h${E_RESET}. (Note that a negative
look-behind would have succeeded here.) Again, the engine
temporarily steps back one character to check if an “${E_WHITE_FG}a${E_RESET}” can be found
there. It finds a ${E_WHITE_FG}t${E_RESET}, so the positive look-behind fails again.

The look-behind continues to fail until the regex reaches the ${E_WHITE_FG}m${E_RESET} in the string.
The engine again steps back one character, and notices that the ${E_WHITE_FG}a${E_RESET} can be matched
there. The positive look-behind matches. Because it is zero-length, the current
position in the string remains at the ${E_WHITE_FG}m${E_RESET}. The next token is ${E_WHITE_FG}b${E_RESET}, which cannot match
here. The next character is the second ${E_WHITE_FG}a${E_RESET} in the string. The engine steps back,
and finds out that the ${E_WHITE_FG}m${E_RESET} does not match ${E_WHITE_FG}a${E_RESET}.

The next character is the first ${E_WHITE_FG}b${E_RESET} in the string. The engine steps back and finds
out that a satisfies the look-behind. ${E_WHITE_FG}b${E_RESET} matches ${E_WHITE_FG}b${E_RESET}, and the entire regex has been
matched successfully. It matches one character: the first ${E_WHITE_FG}b${E_RESET} in the string.

Important Notes About look-behind The good news is that you can use look-behind
anywhere in the regex, not only at the start. If you want to find a word not
ending with an “${E_WHITE_FG}s${E_RESET}”, you could use ${E_WHITE_FG}\b\w+(?<!s)\b${E_RESET}. This is definitely not the same
as ${E_WHITE_FG}\b\w+[^s]\b${E_RESET}. When applied to ${E_WHITE_FG}John's${E_RESET}, the former matches ${E_WHITE_FG}John${E_RESET} and the latter
matches ${E_WHITE_FG}John'${E_RESET} (including the apostrophe). I will leave it up to you to figure
out why. (Hint: ${E_WHITE_FG}\b${E_RESET} matches between the apostrophe and the ${E_WHITE_FG}s${E_RESET}). The latter also
doesn’t match single-letter words like “${E_WHITE_FG}a${E_RESET}” or “${E_WHITE_FG}I${E_RESET}”. The correct regex without
using look-behind is ${E_WHITE_FG}\b\w*[^s\W]\b${E_RESET} (star instead of plus, and ${E_WHITE_FG}\W${E_RESET} in the character
class). Personally, I find the look-behind easier to understand. The last
regex, which works correctly, has a double negation (the ${E_WHITE_FG}\W${E_RESET} in the negated
character class). Double negations tend to be confusing to humans. Not to
regex engines, though. (Except perhaps for Tcl, which treats negated shorthands
in negated character classes as an error.)

The bad news is that most regex flavors do not allow you to use just any regex
inside a look-behind, because they cannot apply a regular expression backwards.
The regular expression engine needs to be able to figure out how many characters
to step back before checking the look-behind. When evaluating the look-behind, the
regex engine determines the length of the regex inside the look-behind, steps
back that many characters in the subject string, and then applies the regex
inside the look-behind from left to right just as it would with a normal regex.

Many regex flavors, including those used by Perl, Python, and Boost only allow
fixed-length strings. You can use literal text, character escapes, Unicode
escapes other than \X, and character classes. You cannot use quantifiers or
backreferences. You can use alternation, but only if all alternatives have the
same length. These flavors evaluate look-behind by first stepping back through
the subject string for as many characters as the look-behind needs, and then
attempting the regex inside the look-behind from left to right.

Perl 5.30 supports variable-length look-behind as an experimental feature. But
there are many cases in which it does not work correctly. So in practice, the
above is still true for Perl 5.30.

PCRE is not fully Perl-compatible when it comes to look-behind. While Perl
requires alternatives inside look-behind to have the same length, PCRE allows
alternatives of variable length. PHP, Delphi, R, and Ruby also allow this. Each
alternative still has to be fixed-length. Each alternative is treated as a
separate fixed-length look-behind.

Java takes things a step further by allowing finite repetition. You can use the
question mark and the curly braces with the max parameter specified. Java
determines the minimum and maximum possible lengths of the look-behind. The
look-behind in the regex (?<!ab{2,4}c{3,5}d)test has 5 possible lengths. It can
be from 7 through 11 characters long. When Java (version 6 or later) tries to
match the look-behind, it first steps back the minimum number of characters (7 in
this example) in the string and then evaluates the regex inside the
look-behind as usual, from left to right. If it fails, Java steps back one more
character and tries again. If the look-behind continues to fail, Java continues
to step back until the look-behind either matches or it has stepped back the
maximum number of characters (11 in this example). This repeated stepping back
through the subject string kills performance when the number of possible lengths
of the look-behind grows. Keep this in mind. Don’t choose an arbitrarily large
maximum number of repetitions to work around the lack of infinite quantifiers
inside look-behind. Java 4 and 5 have bugs that cause look-behind with alternation
or variable quantifiers to fail when it should succeed in some situations. These
bugs were fixed in Java 6.

Java 13 allows you to use the star and plus inside look-behind, as well as curly
braces without an upper limit. But Java 13 still uses the laborious method of
matching look-behind introduced with Java 6. Java 13 also does not correctly
handle look-behind with multiple quantifiers if one of them is unbounded. In some
situations you may get an error. In other situations you may get incorrect
matches. So for both correctness and performance, we recommend you only use
quantifiers with a low upper bound in look-behind with Java 6 through 13.

The only regex engines that allow you to use a full regular expression inside
look-behind, including infinite repetition and backreferences, are the JGsoft
engine and the .NET framework RegEx classes. These regex engines really apply
the regex inside the look-behind backwards, going through the regex inside the
look-behind and through the subject string from right to left. They only need to
evaluate the look-behind once, regardless of how many different possible lengths
it has.

Finally, flavors like std::regex and Tcl do not support look-behind at all, even
though they do support look-ahead. JavaScript was like that for the longest time
since its inception. But now look-behind is part of the ECMAScript 2018
specification. As of this writing (late 2019), Google’s Chrome browser is the
only popular JavaScript implementation that supports look-behind. So if
cross-browser compatibility matters, you can’t use look-behind in JavaScript.

Lookaround Is Atomic The fact that look-around is zero-length automatically makes
it atomic. As soon as the look-around condition is satisfied, the regex engine
forgets about everything inside the look-around. It will not backtrack inside the
look-around to try different permutations.

The only situation in which this makes any difference is when you use capturing
groups inside the look-around. Since the regex engine does not backtrack into the
look-around, it will not try different permutations of the capturing groups.

For this reason, the regex ${E_WHITE_FG}(?=(\d+))\w+\1${E_RESET} never matches ${E_WHITE_FG}123x12${E_RESET}. First the
look-around captures ${E_WHITE_FG}123${E_RESET} into ${E_WHITE_FG}\1${E_RESET}. ${E_WHITE_FG}\w+${E_RESET} then matches the whole string and
backtracks until it matches only ${E_WHITE_FG}1${E_RESET}. Finally, ${E_WHITE_FG}\w+${E_RESET} fails since ${E_WHITE_FG}\1${E_RESET} cannot be
matched at any position. Now, the regex engine has nothing to backtrack to, and
the overall regex fails. The backtracking steps created by ${E_WHITE_FG}\d+${E_RESET} have been
discarded. It never gets to the point where the look-ahead captures only ${E_WHITE_FG}12${E_RESET}.

Obviously, the regex engine does try further positions in the string. If we
change the subject string, the regex ${E_WHITE_FG}(?=(\d+))\w+\1${E_RESET} does match ${E_WHITE_FG}56x56${E_RESET} in ${E_WHITE_FG}456x56${E_RESET}.

If you don’t use capturing groups inside look-around, then all this doesn’t
matter. Either the look-around condition can be satisfied or it cannot be. In how
many ways it can be satisfied is irrelevant.
tip_regex_EOF_2
cat << tip_regex_EOF_3

${E_WHITE_FG}Basic topics${E_RESET}

${E_WHITE_FG}Anchors — ^ and \$${E_RESET}

/^The/       matches any string that starts with "The"
/end$/       matches a string that ends with "end"
/^The end$/  exact string match that starts and ends with "The end"
/roar/       matches any string that has the text "roar" in it

${E_WHITE_FG}Quantifiers — * + ? and {}${E_RESET}

/abc*/        matches a string that has ab followed by zero or more "c"
/abc+/        matches a string that has ab followed by one or more "c"
/abc?/        matches a string that has ab followed by zero or one "c"
/abc{2}/      matches a string that has ab followed by 2 "c"
/abc{2,}/     matches a string that has ab followed by 2 or more "c"
/abc{2,5}/    matches a string that has ab followed by 2 up to 5 "c"
/a(bc)*/      matches a string that has a followed by zero or more copies of the sequence "bc"
/a(bc){2,5}/  matches a string that has a followed by 2 up to 5 copies of the sequence "bc"

${E_WHITE_FG}OR operator — | or []${E_RESET}

/a(b|c)/     matches a string that has "a" followed by "b" or "c" (and captures "b" or "c")  
/a[bc]/      same as previous, but without capturing "b" or "c"

${E_WHITE_FG}Character classes — \d \w \s and .${E_RESET}

/\d/         matches a single character that is a digit  
/\w/         matches a word character (alphanumeric character plus underscore)  
/\s/         matches a whitespace character (includes tabs and line breaks)
/./          matches any character  

Use the . operator carefully since often class or negated character class (which we’ll cover next) 
are faster and more precise.

\d, \w and \s also present their negations with \D, \W and \S respectively.

For example, \D will perform the inverse match with respect to that obtained with \d.

/\D/         matches a single non-digit character  

In order to be taken literally, you must escape the characters "^.[$()|*+?{\" with
a backslash "\" as they have special meaning.

/\$\d/       matches a string that has a "$" before one digit  

Notice that you can match also non-printable characters like tabs \t, new-lines \n, 
carriage returns \r.

${E_WHITE_FG}Flags${E_RESET}

We are learning how to construct a regex but forgetting a fundamental concept: flags.

A regex usually comes within this form /abc/, where the search pattern is delimited 
by two slash characters /.  At the end we can specify a flag with these values 
(we can also combine them each other): g (global) does not return after the first match, 
restarting the subsequent searches from the end of the previous match

m (multi-line) when enabled ^ and $ will match the start and end of a line, instead of the whole string

i (insensitive) makes the whole expression case-insensitive (for instance /aBc/i would match AbC)

${E_WHITE_FG}Intermediate topics${E_RESET}

${E_WHITE_FG}Grouping and capturing — ()${E_RESET}

/a(bc)/           parentheses create a capturing group with value "bc"
/a(?:bc)*/        using ?: we disable the capturing group  
/a(?<foo>bc)/     using ?<foo> we put a name to the group  

This operator is very useful when we need to extract information from strings or data using your preferred 
programming language. Any multiple occurrences captured by several groups will be exposed in the form of a 
classical array: we will access their values specifying using an index on the result of the match.

If we choose to put a name to the groups (using (?<foo>...)) we will be able to retrieve the group values 
using the match result like a dictionary where the keys will be the name of each group.

${E_WHITE_FG}Bracket expressions — []${E_RESET}

/[abc]/           matches a string that has either an "a" or "a b" or "a c"  is the same as a|b|c  
/[a-c]/           same as previous
/[a-fA-F0-9]/     a string that represents a single hexadecimal digit, case insensitively  
/[0-9]%/          a string that has a character from 0 to 9 before a "%" sign
/[^a-zA-Z]/       a string that has not a letter from a to z or from A to Z. In this case the ^ is 
                  used as negation of the expression  

${E_WHITE_FG}Greedy and Lazy match${E_RESET}

The quantifiers ( * + {}) are greedy operators, so they expand the match as far as they can through 
the provided text.

For example, /<.+>/ matches "<div>simple div</div>" in This is a <div> simple div</div> test. In order 
to catch only the div tag we can use a ? to make it lazy:

/<.+?>/          matches any character one or more times included inside < and >, expanding as needed  

Notice that a better solution should avoid the usage of . in favor of a more strict regex:

/<[^<>]+>/       matches any character except < or > one or more times included inside < and >  

${E_WHITE_FG}Advanced topics${E_RESET}

${E_WHITE_FG}Boundaries — \b and \B${E_RESET}

/\babc\b/        performs a "whole words only" search  

\b represents an anchor like caret (it is similar to $ and ^) matching positions where one side is a 
word character (like \w) and the other side is not a word character (for instance it may be the 
beginning of the string or a space character).

It comes with its negation, \B. This matches all positions where \b doesn’t match and could be if we 
want to find a search pattern fully surrounded by word characters.

/\Babc\B/        matches only if the pattern is fully surrounded by word characters  

${E_WHITE_FG}Back-references — \1${E_RESET}

/([abc])\1/              using \1 it matches the same text that was matched by the first capturing group  

/([abc])([de])\2\1/      we can use \2 (\3, \4, etc.) to identify the same text that was matched by the 
                         second (third, fourth, etc.) capturing group  

/(?<foo>[abc])\k<foo>/   we put the name foo to the group and we reference it later (\k<foo>). 
                         The result is the same of the first regex  

${E_WHITE_FG}Look-ahead and Look-behind — (?=) and (?<=)${E_RESET}

/d(?=r)/       matches a "d" only if is followed by "r", but "r" will not be part of the overall regex match  
/(?<=r)d/      matches a "d" only if is preceded by an "r", but "r" will not be part of the overall regex match  

${E_WHITE_FG}You can use also the negation operator!${E_RESET}

/d(?!r)/       matches a "d" only if is not followed by "r", but "r" will not be part of the overall regex match  
/(?<!r)d/      matches a "d" only if is not preceded by an "r", but "r" will not be part of the overall regex match  

${E_WHITE_FG}Summary${E_RESET}

As you’ve seen, the application fields of regex can be multiple and I’m sure that you’ve recognized at least one of 
these tasks among those seen in your developer career, here a quick list:

data validation (for example check if a time string i well-formed)

data scraping (especially web scraping, find all pages that contain a certain set of words eventually in a 
specific order)

data wrangling (transform data from “raw” to another format)

string parsing (for example catch all URL GET parameters, capture text inside a set of parenthesis)

string replacement (for example, even during a code session using a common IDE to translate a Java or C# class 
in the respective JSON object — replace “;” with “,” make it lowercase, avoid type declaration, etc.)

syntax highlightning, file renaming, packet sniffing and many other applications involving strings 
(where data need not be textual)
tip_regex_EOF_3
}

tip_rsync () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_rsync_EOF

Rsync – To Slash or Not To Slash?

Without a slash, copy the hierarchy ${E_WHITE_FG}including${E_RESET} top level directory
With a slash, copy the hierarchy ${E_WHITE_FG}below${E_RESET} the top level directory

If we take the following as the source directory:

$ tree testing

testing
|-- another
|   |-- wilma
|-- betty
|-- fred
|-- nested
    |-- barney

The destination is an empty directory named test_backup.

${E_WHITE_FG}No Slashes${E_RESET}
The first test has no slashes on any of the directories.

$ rsync --archive --recursive testing ${E_CYAN_FG}test_backup${E_RESET}
$ tree test_backup

test_backup
|${E_WHITE_FG}--testing${E_RESET}
   |-- another
   |   |-- wilma
   |-- betty
   |-- fred
   |-- nested
       |-- barney

You can see that the ${E_WHITE_FG}whole hierarchy${E_RESET} of the testing directory has been
recreated within the destination directory.

${E_WHITE_FG}Slash on Source${E_RESET}
$ rsync --archive --recursive ${E_CYAN_FG}testing/${E_RESET} test_backup
$ tree test_backup

test_backup
|${E_WHITE_FG}-- another${E_RESET}
|   |-- wilma
|-- betty
|-- fred
|-- nested
    |-- barney

This is different. The contents of the source directory have been duplicated into the destination
directory.

As to slashes following the destination, if the source is a file ${E_WHITE_FG}and destination doesn't exist${E_RESET}
— this will make a copy of SRC called DEST:

rsync SRC DEST

, whereas, with a slash, this will create directory DEST and copy the SRC file into it:

rsync SRC DEST/
tip_rsync_EOF
}

tip_sed () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_sed_EOF

=====================
advanced sed examples
=====================
${E_WHITE_FG}Example 1${E_RESET}

sed '/PATTERN_1/,/PATTERN_2/d' FILE # pattern inclusive
sed '/PATTERN_1/,/PATTERN_2/-1d' FILE # first pattern inclusive - leave last pattern

sed -i "/PATTERN_1/,/PATTERN_2/{PATTERN_1/!{PATTERN_2/!d}}" FILE # pattern non inclusive (between)

Explanation:

/PATTERN_1/,/PATTERN_2/ will match all the text between lines starting with PATTERN_1 to PATTERN_2
/PATTERN_1/! means do following if start of line is not PATTERN_1
/PATTERN_2/! means do following if start of line is not PATTERN_2

So overall it is first matching all the lines from PATTERN_1 to PATTERN_2 
then from those matched lines, finding lines that don't match PATTERN_1 and don't match PATTERN_2 and deleting

${E_WHITE_FG}Example 2${E_RESET}

sed ':a; N; \$!ba; s/\n/ /g'

This command will progess through entire file, removing all newlines while stringing all lines
together on a single line of output

1) ${E_WHITE_FG}Create${E_RESET} label ${E_CYAN_FG}:a${E_RESET}
2) ${E_WHITE_FG}Append${E_RESET} the current and next line to the pattern space via ${E_CYAN_FG}N${E_RESET}
3) If we are ${E_WHITE_FG}NOT LAST LINE${E_RESET} ${E_CYAN_FG}\$!${E_RESET}, branch to the created label ${E_CYAN_FG}ba${E_RESET}
4) Finally, the substitution ${E_WHITE_FG}replaces every newline with a space${E_RESET} on the pattern space
tip_sed_EOF

local RESPONSE

echo -n "\n${E_WHITE_FG}Further in-depth reading${E_RESET}"
echo -n "\n${E_MAGENTA_FG}---------------------------------------------${E_RESET}"
echo -n "\nPress (${E_WHITE_FG}a${E_RESET}) to read sed basic commands tutorial"
echo -n "\nPress (${E_WHITE_FG}b${E_RESET}) to read sed advanced tutorial"
echo -n "\nEnter (a/b):"
read -k1 RESPONSE
if [[ ${RESPONSE} == 'a' ]];then
	(
	okular --page 1 "/usr/local/etc/StreamEditor-BasicCommands.pdf" &
	win_max okular
	) 2>/dev/null &
fi
if [[ ${RESPONSE} == 'b' ]];then
	(
	okular --page 1 "/usr/local/etc/sed.pdf"
	win_max okular
	) 2>/dev/null &
fi
}

tip_tput () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << "tip_tput_EOF"

tput - list of tput capabilities
--------------------------------------------------------------------

		tput Colour Capabilities
		------------------------		
		tput setab [1-7]
		Set a background colour using ANSI escape
		
		tput setb [1-7]
		Set a background colour
		
		tput setaf [1-7]
		Set a foreground colour using ANSI escape
		
		tput setf [1-7]
		Set a foreground colour

		
		tput Text Mode Capabilities
		------------------------		
		
		tput bold
		Set bold mode
		
		tput dim
		turn on half-bright mode
		
		tput smul
		begin underline mode
		
		tput rmul
		exit underline mode
		
		tput rev
		Turn on reverse mode
		
		tput smso
		Enter standout mode (bold on rxvt)
		
		tput rmso
		Exit standout mode
		
		tput sgr0
		Turn off all attributes (doesn't work quite as expected)

		
		tput Cursor hiding
		---------------------------------		
		tput civis
		Hide the cursor

		tput cnorm
		Reveal the cursor


		tput Terminal save & restore
		---------------------------------		
		tput smcup
		Save and clear the terminal

		tput rmcup
		Restore the saved terminal contents


		tput Cursor Movement Capabilities
		---------------------------------		
		tput cup ROW COL
		Move cursor to screen location X,Y (top left is 0,0)
		
		tput sc
		Save the cursor position
		
		tput rc
		Restore the cursor position
		
		tput lines
		Output the number of lines of the terminal
		
		tput cols
		Output the number of columns of the terminal
		
		tput cub N
		Move N characters left
		
		tput cuf N
		Move N characters right
		
		tput cub1
		move left one space
		
		tput cuf1
		non-destructive space (move right one space)
		
		tput ll
		last line, first column (if no cup)
		
		tput cuu1
		up one line
		

		tput Clear and Insert Capabilities
		----------------------------------		
		
		tput ech N
		Erase N characters
		
		tput clear
		clear screen and home cursor
		
		tput el1
		Clear to beginning of line
		
		tput el
		clear to end of line
		
		tput ed
		clear to end of screen
		
		tput ich N
		insert N characters (moves rest of line forward!)
		
		tput il N
		insert N lines



		------------
		Examples
		------------
		# Yet Another Large Screen Clock
		# pulsed terminal clock
		clear;
		while true; do
			sleep 1;
			for ((a=1; a<=$(tput cols)/3; a++)); do 
				tput cup 0 ${a};
				echo " " $(date);
			done;
			sleep 1;
			for ((a; a>=1; a--)); do
				tput cup 0 ${a};
				echo $(date) " ";
			done;
		done
		
		# toggle line wrapping in your terminal
		# will disable line wrapping so that long lines are truncated to width of the terminal (${COLUMNS}).
		tput rmam
		# will re-enable wrapping.
		tput smam
		
		
		## countdown from 10 ...
		clear;
		tput cup 8 8;
		
		for i in $(seq 1 10);do
			echo -n "$((11-${i})) ";
			sleep 1;
		done;
		
		tput cup 10 8;
		echo -e "DONE\n\n"
		
		(X='tput op' y='printf %$((${COLUMNS}-6))s';
			for i in {0..10};do
				o=00${i};
				echo -e ${o:${# o}-3:3} 'tput setaf ${i}; tput setab ${i}'${y// /=}${X};
			done;
		)
		
		
		# HourGlass
		hourglass() { 
			s=$((${SECONDS} +${1:-10}))
			(
			tput civis
			while [[ ${SECONDS} -lt ${s} ]];do 
				for f in '/' '*' '\' '*'; do 
					echo -n ${f}
					sleep .2s
					tput cub1
				done
			done
			)
			tput cnorm
		}
		echo -n "Searching..."
		hourglass 30
		
		# Displays the number of unread messages on your gmail at the top right corner of your terminal
		# Checks your gmail account every 30 seconds and display the number of new messages in the top right corner 
		# of the terminal.  # A kind of CLI "Gmail notifier" if you will. :-)
		# This is a mashup of http://www.commandlinefu.com/commands/view/7916/put-a-console-clock-in-top-right-corner 
		# and http://www.commandlinefu.com/commands/view/3386/check-your-unread-gmail-from-the-command-line
		while sleep 30;do
			tput sc;
			tput cup 0 $(($(tput cols)-15));
			echo -n " New Emails: $(curl -u username:password \
				--silent https://mail.google.com/mail/feed/atom \
				| grep 'fullcount' | grep -o '[0-9]\+')";
			tput rc;
		done &
		
		
		# There's been a similar Futurama thing around for a while, 
		# which grabs a quote from the /. headers [curl -Ism3 slashdot.org | 
		# egrep "^X-(F|B|L)" | cut -d \- -f 2- | fmt -w $(tput cols)]. 
		# Same deal, but more likely to stop working when someone forgets 
		# to pay the bill on the domain. Until then: Cave Johnson!
		curl -s http://www.cavejohnsonhere.com/random/ | grep quote_main | cut -d \> -f 2- | fmt -w $(tput cols)
		
		while true;do 
			tput sc;
			tput cup 0 $(($(tput cols)-74));
			w | grep load;
			tput rc;
			sleep 10;
		done &
		
		# Put a console clock in top right corner
		# Gives not only date but also some interesting status about the System
		p() { 
			c=$(($(tput cols)-3));
			j=$((${1}*c/100));
			tput sc;
			printf "[$(
			for((k=0; k<j; k++)); do
				printf "=";
			done;)>";
			tput cuf $((c-j));
			printf "]";
			tput rc;
		};
		for((i=0; i<=100; i++));do
			p i;
		done;
		echo
		
		# create a progress bar...
		# A simple way yo do a progress bar like wget.
		while sleep 1;do
			tput sc;
			tput cup 0 $(($(tput cols)-29));
			date;
			tput rc;
		done &
		
		# Put a console clock in top right corner
		# A nice way to use the console in full screen without forget the current time.
		# you can too add other infos like cpu and mem use.
		while :;do
			ping -W1 -c1 -n 8.8.8.8 > /dev/null || tput bel > /dev/console;
			sleep 1;
		done
		
		# Make a server's console beep when the network is down
		# This is like ping -a, but it does the opposite. It alerts you if the network is down, not up. Note that the beep 
		# will be from the speaker on the server, not from your terminal.  Once a second, this script checks if the Internet 
		# is accessible and beeps if it is not. I define the Net as being "UP", if I can ping Google's public DNS 
		# server (8.8.8.8), but of course you could pick a different static IP address. I redirect the beep to /dev/console 
		# so that I can run this in the background from /etc/rc.local. Of course, doing that requires that the script is run 
		# by a UID or GID that has write permissions to /dev/console (usually only root).
		# Question: I am not sure if the -W1 flag works under BSD. I have only tested this under GNU/Linux using ping 
		# from iputils. If anybody knows how portable -W is, please post a comment.
		 
		while [ 1 -lt 2 ];do
			i=0;
			COL=$((RANDOM%$(tput cols)));
			ROW=$((RANDOM%$(tput cols)));
			while [ ${i} -lt ${COL} ];do
				tput cup ${i} ${ROW};
				echo -e "\033[1; 34m" 
				$(cat /dev/urandom | head -1 | cut -c1-1) 2>/dev/null ; i=$(expr ${i} + 1);
			done;
		done
		
		# Same as original, but works in bash
		while :;do
			integer i=0;
			COL=$((RANDOM%$(tput cols)));
			ROW=$((RANDOM%$(tput cols)));
			while (( i <= COL)) do
				tput cup ${i} ${ROW};
				echo "\033[1; 34m" 
				$(cat /dev/urandom | head -1 | cut -c1-1) 2>/dev/null;
				i=$(expr ${i} + 1);
			done
		done
		
		# Print a row of characters across the terminal
		seq -s'#' 0 $(tput cols) | tr -d '[:digit:]'
		
		# Print a row of characters across the terminal. Uses tput to establish the current terminal width, 
		# and generates a line of characters just long enough to cross it. In the example '#' is used.
		# It's possible to use a repeating sequence by dividing the columns by the number of characters 
		# in the sequence like this:
		seq -s'~-' 0 $(( $(tput cols) /2 )) | tr -d '[:digit:]'
		# or
		seq -s'-~?' 0 $(( $(tput cols) /3 )) | tr -d '[:digit:]'
		# You will lose chararacters at the end if the length isn't cleanly divisible.
		 
		# Terminal Escape Code Zen - Strace and Tput
		termtrace() {
			( strace -s 1000 -e write tput ${@} 2>&2 2>&1 ) | grep -o '"[^"]*"';
		}
		
		# Depending on the TERM, the terminfo version, ncurses version, etc.. you may be using a varied assortment of terminal 
		# escape codes.  # With this command you can easily find out exactly what is going on.. This is terminal escape zen!
		( 2>&2 strace -f -F -e write -s 1000 \
			sh -c 'echo -e "initc\nis2\ncnorm\nrmso\nsgr0" \
			| tput -S' 2>&1 
		) | grep -o '"\\[^"]*"' --color=always "\33]4; %p1%d; \ 
		rgb:%p2%{255}%*%{1000}%/%2.2X/%p3%{255}%*%{1000}%/%2.2X/%p4%{255}%*%{1000}%/%2.2X\33\\\33[!p\33[?3;
		4l\33[4l\33>\33[?12l\33[?25h\33[27m\33(B\33[m"
		
		# Lets say you want to find out what you need to echo in order to get the text to blink..
		echo -e "'tput blink'This will blink'tput sgr0' This wont"
		# Now you can use this function instead of calling tput 
		#(tput is much smarter for portable code because it works differently depending on the current TERM, 
		# and tput -T anyterm works too.) to turn that echo into a much faster executing code. 
		# tput queries files, opens files, etc.. but echo is very strait and narrow.
		# So now you can do this:
		echo -e "\33[5mThis will blink\33(B\33[m This wont"
		# More at http://www.askapache.com/linux-unix/bash_profile-functions-advanced-shell.html
		 
		# Another Matrix Style Implementation
		COL=$(( $(tput cols) / 2 ));
		clear;
		tput setaf 2;
		while :;do 
			tput cup $((RANDOM%COL)) $((RANDOM%COL));
			printf "%$((RANDOM%COL))s" $((RANDOM%2));
		done
		
		# For vi(m) users :
		# Add it in your ~/.bashrc
		# Add an "exit" @ the end if you are masochist ;
		# Know when you will type :q in your term instead of vi(m), the alias will chewed you out.
		alias :q='tput setaf 1; echo >&2 "this is NOT vi(m) :/"; tput sgr0'
		
		
		# Using tput to save, clear and restore the terminal contents
		# Very useful for interactive scripts where you would like to return the terminal contents 
		# to its original state before the script was run. This would be similar to how vi exits 
		# and returns you to your original terminal screen.
		tput smcup;
		echo "Doing some things...";
		sleep 2;
		tput rmcup
		
		# Save and clear the terminal contents with:
		tput smcup
		# Execute some commands, then restore the saved terminal contents with:
		tput rmcup
		
		
		# prints message in given argument on on center of screen
		# echox prints given argument on bottom line center screen in terminal
		# you can easily use these functions by placing them in your .bashrc file, make sure to source your 
		# .bashrc once you do:
		function echox { 
			echo 'tput cup $(($(tput lines))) $(( ($(tput cols) - $(echo "${#1}"))/2 )) \
			'"${1}"'tput cup $(tput lines) $(( $(tput cols)-1 ))';
		}
		
		# exhoxy prints given argument center screen
		function echoxy { 
			echo 'tput cup $(($(tput lines)/2)) $(( ($(tput cols) - $(echo "${#1}"))/2))'"${1}"' \
			tput cup $(tput lines) $(( $(tput cols)-1 ))';
		}
		
		# echos prints date and time on second from last line (used as status message)
		function echos { 
			echo 'tput cup $(($(tput lines)-2)) $(($(tput cols)-$(echo ${#1}))) && \
				  tput sc'"${1}"'tput cup $(($(tput lines)-2)) 0 && tput rc';
		} 

		while [ 1 ]; do 
			echos "'date'";
		done
		
		# reset a hanging terminal session
		# when your terminal session seems unrensponsive (this normally happen after outputting 
		# some binary data directly on your standard output) it may me saned by hitting:
		# Note: don't press the Enter key, just ctrl+j
		# CTRL+J tput sgr0 CTRL+J
		^J tput sgr0 ^J

tip_tput_EOF
}

tip_vim () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_vim_EOF

                                                                            
                           Readline VI Editing Mode                         
                      Default Keyboard Shortcuts for Bash                   
                                Cheat Sheet                                 
                                                                            

 ======================== Keyboard Shortcut Summary ========================

.--------------.------------------------------------------------------------.
|              |                                                            |
| Shortcut     | Description                                                |
|              |                                                            |
'--------------'------------------------------------------------------------'
| Switching to COMMAND Mode:                                                |
'--------------.------------------------------------------------------------'
| ESC          | Switch to command mode.                                    |
'--------------'------------------------------------------------------------'
| Commands for Entering INPUT Mode:                                         |
'--------------.------------------------------------------------------------'
| i            | Insert before cursor.                                      |
'--------------+------------------------------------------------------------'
| a            | Insert after cursor.                                       |
'--------------+------------------------------------------------------------'
| I            | Insert at the beginning of line.                           |
'--------------+------------------------------------------------------------'
| A            | Insert at the end of line.                                 |
'--------------+------------------------------------------------------------'
| c<mov. comm> | Change text of a movement command <mov. comm> (see below). |
'--------------+------------------------------------------------------------'
| C            | Change text to the end of line (equivalent to c\$).         |
'--------------+------------------------------------------------------------'
| cc or S      | Change current line (equivalent to 0c\$).                   |
'--------------+------------------------------------------------------------'
| s            | Delete a single character under the cursor and enter input |
|              | mode (equivalent to c[SPACE]).                             |
'--------------+------------------------------------------------------------'
| r            | Replaces a single character under the cursor (without      |
|              | leaving command mode).                                     |
'--------------+------------------------------------------------------------'
| R            | Replaces characters under cursor.                          |
'--------------+------------------------------------------------------------'
| v            | Edit (and execute) the current command in the text editor. |
|              | (an editor defined in \${VISUAL} or \${EDITOR} variables, or vi  |
'--------------'------------------------------------------------------------'
| Basic Movement Commands (in command mode):                                |
'--------------.------------------------------------------------------------'
| h            | Move one character right.                                  |
'--------------+------------------------------------------------------------'
| l            | Move one character left.                                   |
'--------------+------------------------------------------------------------'
| w            | Move one word or token right.                              |
'--------------+------------------------------------------------------------'
| b            | Move one word or token left.                               |
'--------------+------------------------------------------------------------'
| W            | Move one non-blank word right.                             |
'--------------+------------------------------------------------------------'
| B            | Move one non-blank word left.                              |
'--------------+------------------------------------------------------------'
| e            | Move to the end of the current word.                       |
'--------------+------------------------------------------------------------'
| E            | Move to the end of the current non-blank word.             |
'--------------+------------------------------------------------------------'
| 0            | Move to the beginning of line                              |
'--------------+------------------------------------------------------------'
| ^            | Move to the first non-blank character of line.             |
'--------------+------------------------------------------------------------'
| \$            | Move to the end of line.                                   |
'--------------+------------------------------------------------------------'
| %            | Move to the corresponding opening/closing bracket.         |
'--------------'------------------------------------------------------------'
| Character Finding Commands (these are also Movement Commands):            |
'--------------.------------------------------------------------------------'
| fc           | Move right to the next occurance of char c.                |
'--------------+------------------------------------------------------------'
| Fc           | Move left to the previous occurance of c.                  |
'--------------+------------------------------------------------------------'
| tc           | Move right to the next occurance of c, then one char       |
|              | backward.                                                  |
'--------------+------------------------------------------------------------'
| Tc           | Move left to the previous occurance of c, then one char    |
|              | forward.                                                   |
'--------------+------------------------------------------------------------'
| ;            | Redo the last character finding command.                   |
'--------------+------------------------------------------------------------'
| ,            | Redo the last character finding command in opposite        |
|              | direction.                                                 |
'--------------+------------------------------------------------------------'
| |            | Move to the n-th column (you may specify the argument n by |
|              | typing it on number keys, for example, 20|)                |
'--------------'------------------------------------------------------------'
| Deletion Commands:                                                        |
'--------------.------------------------------------------------------------'
| x            | Delete a single character under the cursor.                |
'--------------+------------------------------------------------------------'
| X            | Delete a character before the cursor.                      |
'--------------+------------------------------------------------------------'
| d<mov. comm> | Delete text of a movement command <mov. comm> (see above). |
'--------------+------------------------------------------------------------'
| D            | Delete to the end of the line (equivalent to d\$).          |
'--------------+------------------------------------------------------------'
| dd           | Delete current line (equivalent to 0d\$).                   |
'--------------+------------------------------------------------------------'
| CTRL-w       | Delete the previous word.                                  |
'--------------+------------------------------------------------------------'
| CTRL-u       | Delete from the cursor to the beginning of line.           |
'--------------'------------------------------------------------------------'
| Undo, Redo and Copy/Paste Commands:                                       |
'--------------.------------------------------------------------------------'
| u            | Undo previous text modification.                           |
'--------------+------------------------------------------------------------'
| U            | Undo all previous text modifications.                      |
'--------------+------------------------------------------------------------'
| .            | Redo the last text modification.                           |
'--------------+------------------------------------------------------------'
| y<mov. comm> | Yank a movement into buffer (copy).                        |
'--------------+------------------------------------------------------------'
| yy           | Yank the whole line.                                       |
'--------------+------------------------------------------------------------'
| p            | Insert the yanked text at the cursor.                      |
'--------------+------------------------------------------------------------'
| P            | Insert the yanked text before the cursor.                  |
'--------------'------------------------------------------------------------'
| Commands for Command History:                                             |
'--------------.------------------------------------------------------------'
| k            | Insert the yanked text before the cursor.                  |
'--------------+------------------------------------------------------------'
| j            | Insert the yanked text before the cursor.                  |
'--------------+------------------------------------------------------------'
| G            | Insert the yanked text before the cursor.                  |
'--------------+------------------------------------------------------------'
| /string or   | Search history backward for a command matching string.     |
| CTRL-r       |                                                            |
'--------------+------------------------------------------------------------'
| ?string or   | Search history forward for a command matching string.      |
| CTRL-s       | (Note that on most machines Ctrl-s STOPS the terminal      |
|              | output, change it with 'stty' (Ctrl-q to resume)).         |
'--------------+------------------------------------------------------------'
| n            | Repeat search in the same direction as previous.           |
'--------------+------------------------------------------------------------'
| N            | Repeat search in the opposite direction as previous.       |
'--------------'------------------------------------------------------------'
| Completion commands:                                                      |
'--------------.------------------------------------------------------------'
| TAB or = or  | List all possible completions.                             |
| CTRL-i       |                                                            |
'--------------+------------------------------------------------------------'
| *            | Insert all possible completions.                           |
'--------------'------------------------------------------------------------'
| Miscellaneous commands:                                                   |
'--------------.------------------------------------------------------------'
| ~            | Invert case of the character under cursor and move a       |
|              | character right.                                           |
'--------------+------------------------------------------------------------'
| #            | Prepend '#' (comment character) to the line and send it to |
|              | the history.                                               |
'--------------+------------------------------------------------------------'
| _            | Inserts the n-th word of the previous command in the       |
|              | current line.                                              |
'--------------+------------------------------------------------------------'
| 0, 1, 2, ... | Sets the numeric argument.                                 |
'--------------+------------------------------------------------------------'
| CTRL-v       | Insert a character literally (quoted insert).              |
'--------------+------------------------------------------------------------'
| CTRL-r       | Transpose (exchange) two characters.                       |
'--------------'------------------------------------------------------------'


${E_WHITE_FG}Key Mapping${E_RESET}

Check that the key is effectively mapped to what it should do

   Vim provides a command :${E_WHITE_FG}map${E_RESET}. By default (when no argument is given) the command will show all the mappings currently created.
   Here is an example of the result of the command:

   result of <code>:${E_WHITE_FG}map${E_RESET}</code>

   As always the doc is your friend: :h ${E_WHITE_FG}map${E_RESET}-listing

   You can see in the first column the mode of the mapping (n for normal mode, v for visual mode, etc), the second column shows the
   keys mapped and the last column what the keys are mapped to. Note that before the mapped actions some additional characters may
   appear, it is important to understand them:
     * * indicates that it is not remappable (i.e. it is not a recursive mapping, see know when to use nore later in this answer)
     * & indicates that only script-local mappings are remappable
     * @ indicates a buffer-local mapping

   When asking for help about a mapping it is a good thing to add this information since it can help other people to understand the
   behavior of your mapping.

   It is possible to restrict the prompt to a particular mode with the sister-commands of :${E_WHITE_FG}map${E_RESET}, like :${E_WHITE_FG}vmap${E_RESET}, :${E_WHITE_FG}nmap${E_RESET}, :${E_WHITE_FG}omap${E_RESET}, etc.

   Now to restrict your search to the problematic mapping you can pass the key sequence you're debugging as parameter of the
   commands, like this:
:${E_WHITE_FG}map${E_RESET} j
:${E_WHITE_FG}map${E_RESET} <Leader>m
:${E_WHITE_FG}map${E_RESET} <F5>

   Note that the <Leader> key will be replaced by its actual value in the list.

   If the result of the command shows that your keys are correctly mapped, it probably means that the problem doesn't come from Vim
   but from your terminal or your desktop environment. See the part Check if your mapping is actually intercepted by Vim

   If the result of the command show that your keys are not correctly mapped see the following part.

Check what overrode your mapping

   Another convenient use of the :${E_WHITE_FG}map${E_RESET} command is to combine it with verbose: This will prompt the last file which modified your
   mapping.

   For example see these two screen-shots: the first one is a mapping modified by my .vimrc and the second a mapping created by a
   plugin:

   Mapping set from vimrc

   Mapping set from a plugin

   Now if you see that another script modified your mapping you'll have to see if you can remove it or modify its behavior. (Note
   that some plugins provides variable to enable/disable their mappings, unfortunately not all of the plugins do that)

   If the last file which changed your mapping is your .vimrc, make sure there is no other line that also defines a mapping for the
   same key. The .vimrc file will happily override any mappings with the last one of its kind in the file.

Check if your mapping is actually intercepted by Vim

   Several situations may indicate that Vim doesn't intercept your key:
     * The command :${E_WHITE_FG}map${E_RESET} show that your key is correctly mapped but pressing it does nothing.
     * Your mapping works on gVim (GUI) but does nothing in terminal Vim
     * Your mapping works on a defined terminal emulator but not on another
     * Your mapping works on a defined OS but not another one.

   It is probably caused by one of the two following things:

     * Something intercepts the key before Vim: It can be different applications: your OS, your desktop environment, your terminal
       emulator, Tmux (if you use it)....
       To troubleshoot that, you should:
          + Try to temporary remove your .tmux.conf if you use tmux
          + Refer to the doc of your terminal or of your desktop environment.
       You could also refer to sister-sites like super-user, Unix and Linux, askUbuntu, etc...
       If this is the problem, you then have two solutions: either you spend (a lot of) time to change the behavior of the
       application which causes the problem or you find another key combination to ${E_WHITE_FG}map${E_RESET} which isn't intercepted by another
       application.

     * Your terminal emulator can't handle the key combination you're trying to ${E_WHITE_FG}map${E_RESET}: Terminal emulators are implemented differently
       and some of them are not able to handle some particular key combination. (The reason why they can't is out of the scope of
       this question, see their doc or the sister-sites mentioned before for more details).
       In this case you don't have a lot of solutions: either you change your key for another one which is handled properly by your
       terminal or you change your terminal emulator.

Check for the common pitfalls

   Some problems in mappings are pretty recurrent and mostly related to the vimscript syntax. If your mapping has an unexpected
   behavior remember to check the following points:
     * Do not put a comment on the same line as your mapping, instead put the comment on the line above. 
	 
	 Example:
       Don't do: ${E_WHITE_FG}inoremap${E_RESET} ii <esc>    " ii to go back into normal mode

       Vim will consider the whitespaces, the " and the comment as a part of the mapping which will result in an unexpected behavior.
       Instead do: 
		" ii to go back into normal mode
		${E_WHITE_FG}inoremap${E_RESET} ii <esc>

       This is easier to read and won't mess your mapping.

     * Do not pipe your commands with |. 
	 Example:
       Don't do: ${E_WHITE_FG}nnoremap${E_RESET} <Leader>x :w | !% python -m json.tools

       Vim will consider the pipe | as a command termination: When you source your .vimrc the mapping ${E_WHITE_FG}nnoremap${E_RESET} <Leader>x :w will be
       created then the external command !% python -m json.tools will be executed.

       Instead do: ${E_WHITE_FG}nnoremap${E_RESET} <Leader>x :w <bar> !% python -m json.tools

       See an explanation about <bar>.

     * Know when to use nore: always.

       LearnVimscriptTheHardWay explains it pretty clearly: never use ${E_WHITE_FG}map${E_RESET}, ${E_WHITE_FG}nmap${E_RESET}, ${E_WHITE_FG}vmap${E_RESET}, etc... Always prefer the nore version:
       ${E_WHITE_FG}noremap${E_RESET}, ${E_WHITE_FG}nnoremap${E_RESET}, ${E_WHITE_FG}${E_WHITE_FG}vnoremap${E_RESET}${E_RESET}, etc... Why? nore stands for non recursive mapping it means that the right hand side of the
       mapping will be considered as the built in feature even if you remmaped it. 

	   Example:
       Let's say you want to ${E_WHITE_FG}map${E_RESET} > to delete a line and - to increment the indent of a line. If you don't use non recursive
       mappings you'll do that: (Do not do it; it's only for the example)

${E_WHITE_FG}nmap${E_RESET} > dd
${E_WHITE_FG}nmap${E_RESET} - >

       When you'll hit > your line will be deleted, that's good. But when you'll hit - your line will also be deleted instead of
       being indented. Why? Because Vim understood "I received a hit on - which I should translate to > which I should in turn
       translate to dd".

       Instead do:
${E_WHITE_FG}nnoremap${E_RESET} > dd
${E_WHITE_FG}nnoremap${E_RESET} - >

       This way Vim will translate - as > and will not try to do any other translation because of the nore.
       Edit note "Always" may be an exaggerated answer in some cases you'll need to use the recursive mapping form but it is not
       really common. 
	   
	   To clarify, I'll quote @romainl from this answer:

     Use a recursive mapping only if you intend to use any other mapping in your mapping. Use non-recursive mappings if you don't.

     * Remember that some key combinations are equivalent: Because of the hexadecimal codes that are produced some key combinations
       will be interpreted by Vim as another key. For example
          + <C-h> is equivalent to <backspace>
          + <C-j> as <enter>
          + On French keyboards <M-a> is the same as á and the same goes with all the <m- mappings. As @LucHermitte pointed out in
            the comment that is a problem with plugins using this type of mappings like vim-latex.
          + <C-S-a> is equivalent to <C-a>. Mapping Ctrl+upper case letter separately from Ctrl+lower case letter is not possible
            cause of the way the terminals send ASCII codes.
       When your mapping seems to affect another key try to use another lhs combination, if that solves the problem inspect which
       hexadecimal codes are sent to Vim.

     * Check that your leader is correctly defined: If your mappings involving <leader> doesn't work and you changed your leader
       with the command mapleader, check that the definition of your leader is done before the definition of the mappings.
       Otherwise, Vim will try to create mappings with a key which is not the one you think. Also if you want to use the space bar
       as your leader (which is pretty current) make sure that you used the correct notation: let mapleader = "\<Space>"

Your mapping still doesn't work?

   If you went through all the steps of this answer and your mapping still doesn't work like you want, you'll probably want to ask
   for help on this site.

   To help people to help you remember to provide some crucial information like:
     * The command you used to define your mapping.
     * What you are expecting your mapping to do.
     * A precise description of the problem:
       "It doesn't work" won't be really helpful to people who will try to help you. You should precise if the mapping doesn't do
       anything or how it behaves differently than what you was expecting.
     * Also indicate that you actually followed the steps described here and the results you get with :${E_WHITE_FG}map${E_RESET} and :verbose ${E_WHITE_FG}map${E_RESET}

   All of this will save you and the users of the site a lot of time.
   ___________________________________________________________________________________________________________________________

A useful command: :${E_WHITE_FG}unmap${E_RESET}

   Sometimes it can be useful to reset a mapping without quitting Vim to help debugging its behavior.

   To do so you can use the command :${E_WHITE_FG}unmap${E_RESET} <key> which will remove the mapping assigned to <key> for Normal, Visual and
   Operating-pending modes. :iunmap will remove mappings for Insert mode. For other modes see :help :${E_WHITE_FG}unmap${E_RESET}.
   ___________________________________________________________________________________________________________________________

${E_WHITE_FG}Common Settings${E_RESET}

Indention Options

  • set autoindent: New lines inherit the indentation of previous lines.
  • set expandtab: Convert tabs to spaces.
  • set filetype indent on: Enable indentation rules that are file-type specific.
  • set shiftround: When shifting lines, round the indentation to the nearest multiple of “shiftwidth.”
  • set shiftwidth=4: When shifting, indent using four spaces.
  • set smarttab: Insert “tabstop” number of spaces when the “tab” key is pressed.
  • set tabstop=4: Indent using four spaces.

Search Options

  • set hlsearch: Enable search highlighting.
  • set ignorecase: Ignore case when searching.
  • set incsearch: Incremental search that shows partial matches.
  • set smartcase: Automatically switch search to case-sensitive when search query contains an uppercase letter.

Performance Options

  • set complete-=i: Limit the files searched for auto-completes.
  • set lazyredraw: Don’t update screen during macro and script execution.

Text Rendering Options

  • set display+=lastline: Always try to show a paragraph’s last line.
  • set encoding=utf-8: Use an encoding that supports unicode.
  • set linebreak: Avoid wrapping a line in the middle of a word.
  • set scrolloff=1: The number of screen lines to keep above and below the cursor.
  • set sidescrolloff=5: The number of screen columns to keep to the left and right of the cursor.
  • syntax enable: Enable syntax highlighting.
  • set wrap: Enable line wrapping.

User Interface Options

  • set laststatus=2: Always display the status bar.
  • set ruler: Always show cursor position.
  • set wildmenu: Display command line’s tab complete options as a menu.
  • set tabpagemax=50: Maximum number of tab pages that can be opened from the command line.
  • set colorscheme wombat256mod: Change color scheme.
  • set cursorline: Highlight the line currently under cursor.
  • set number: Show line numbers on the sidebar.
  • set relativenumber: Show line number on the current line and relative numbers on all other lines.
  • set noerrorbells: Disable beep on errors.
  • set visualbell: Flash the screen instead of beeping on errors.
  • set mouse=a: Enable mouse for scrolling and resizing.
  • set title: Set the window’s title, reflecting the file currently being edited.
  • set background=dark: Use colors that suit a dark background.

Code Folding Options

  • set foldmethod=indent: Fold based on indention levels.
  • set foldnestmax=3: Only fold up to three nested levels.
  • set nofoldenable: Disable folding by default.

Miscellaneous Options

  • set autoread: Automatically re-read files if unmodified inside Vim.
  • set backspace=indent,eol,start: Allow backspacing over indention, line breaks and insertion start.
  • set backupdir=~/.cache/vim: Directory to store backup files.
  • set confirm: Display a confirmation dialog when closing an unsaved file.
  • set dir=~/.cache/vim: Directory to store swap files.
  • set formatoptions+=j: Delete comment characters when joining lines.
  • set hidden: Hide files in the background instead of closing them.
  • set history=1000: Increase the undo limit.
  • set nomodeline: Ignore file’s mode lines; use vimrc configurations instead.
  • set noswapfile: Disable swap files.
  • set nrformats-=octal: Interpret octal as decimal when incrementing numbers.
  • set shell: The shell used to execute commands.
  • set spell: Enable spellchecking.
  • set wildignore+=.pyc,.swp: Ignore files matching these patterns when opening files based on a glob pattern.

${E_WHITE_FG}Advanced Regex${E_RESET}

${E_WHITE_FG}look-behind${E_RESET} and ${E_WHITE_FG}look-ahead${E_RESET} Regex in Vim

Here's a nifty little vim tip for you.

I recently had to switch a few variables in PHP from ${E_WHITE_FG}\${varname}${E_RESET} to ${E_WHITE_FG}\${somearray}['varname']${E_RESET}. 
Since there were quite a few of these replacements to be done, 
I found it convenient to use vim's search/replace regex feature. 
In this case, I have to use ${E_WHITE_FG}look-behind${E_RESET}, since the matching string is simply varname, and 
I'm not interested in catching the ${E_WHITE_FG}\$${E_RESET} at the beginning. I just want the regex to match 
anything starting with the ${E_WHITE_FG}\$${E_RESET}, without having the ${E_WHITE_FG}\$${E_RESET} as part of the matching string itself.

So, let’s try to replace the following line:

${E_WHITE_FG}authenticate(\${key}, \${secret}, \${uri});${E_RESET}

with this one:

${E_WHITE_FG}authenticate(\${somearray}['key'], \${somearray}['secret'], \${somearray}['uri']);${E_RESET}

We’ll want to construct a ${E_WHITE_FG}look-behind${E_RESET} for the ${E_WHITE_FG}\$${E_RESET}, with some string in front. 
Then, we’ll replace it with ${E_WHITE_FG}\${somearray}[‘matching_string‘]${E_RESET}. 
In vim, ${E_WHITE_FG}look-behind${E_RESET} uses the special ${E_WHITE_FG}@${E_RESET} symbol, rather than the perl (?<=somestring) syntax. 

This will do the trick:

${E_WHITE_FG}1,\${s}/\\$\@<=[a-z]\+/\${somearray}['&']/g${E_RESET}

As you can see, the ${E_WHITE_FG}'\$'${E_RESET}, ${E_WHITE_FG}'@'${E_RESET}, and ${E_WHITE_FG}'+'${E_RESET} must all be escaped. 
The ${E_WHITE_FG}look-behind${E_RESET} positive search chars: ${E_WHITE_FG}@<=${E_RESET} can be replaced with: ${E_WHITE_FG}@<!${E_RESET} if a negative search is desired. 

${E_WHITE_FG}look-ahead${E_RESET} is similar to ${E_WHITE_FG}look-behind${E_RESET} syntax, but uses ${E_WHITE_FG}@=${E_RESET} and ${E_WHITE_FG}@!${E_RESET} instead. 

The special ${E_WHITE_FG}'&'${E_RESET} character in the replace string designates a matching token, which you can use to 
place the matching string in your replacement.

So for reference:

${E_WHITE_FG}LOOKBEHIND${E_RESET}
--------------------------
${E_WHITE_FG}s/\(some\)\\${E_GREEN_FG}@<=${E_RESET}thing/one/g${E_RESET}
-------------------------
searches for all strings ${E_WHITE_FG}starting with 'some'${E_RESET}, then matching 'thing'; changes 'thing' into 'one'
-> ${E_WHITE_FG}end result${E_RESET}: 'something' becomes 'someone'

--------------------------
${E_WHITE_FG}s/\(some\)\\${E_GREEN_FG}@<${E_RESET}${E_RED_FG}!${E_RESET}thing/one/g${E_RESET}
--------------------------
searches for all strings ${E_RED_FG}not${E_WHITE_FG} starting with 'some'${E_RESET}, then matching 'thing'; changes 'thing' into 'one'
-> ${E_WHITE_FG}end result${E_RESET}: 'something' is not changed, 'everything' changes to 'everyone'

${E_WHITE_FG}LOOKAHEAD${E_RESET}
--------------------------
${E_WHITE_FG}s/some\(thing\)\\${E_GREEN_FG}@=${E_RESET}/every/g${E_RESET}
--------------------------
searches for all strings ${E_WHITE_FG}ending with 'thing'${E_RESET}, then matching 'some'; changes 'some' into 'every'
-> ${E_WHITE_FG}end result${E_RESET}: 'something' becomes 'everything'

--------------------------
${E_WHITE_FG}s/some\(thing\)\\${E_GREEN_FG}@${E_RESET}${E_RED_FG}!${E_RESET}/every/g${E_RESET}
--------------------------
searches for all strings ${E_RED_FG}not${E_WHITE_FG} ending with 'thing'${E_RESET}, then matching 'some'; changes 'some' into 'every'
-> ${E_WHITE_FG}end result${E_RESET}: 'something' is not changed, but 'someone' becomes 'everyone'

${E_WHITE_FG}============================ P A T T E R N S =============================${E_RESET}

An atom can be followed by an indication of how many times the atom can be
matched and in what way.  This is called a multi.  See |/multi| for an
overview.

							*/star* */\star*
*	(use \* when 'magic' is not set)
	Matches 0 or more of the preceding atom, as many as possible.

	${E_WHITE_FG}Example${E_RESET}  'nomagic'	${E_GREEN_FG}Matches${E_RESET}
	a*	   a\*		"", "a", "aa", "aaa", etc.
	.*	   \.\*		anything, also an empty string, no end-of-line
	\_.*	   \_.\*	everything up to the end of the buffer
	\_.*END	   \_.\*END	everything up to and including the last "END" in the buffer

	Exception: When "*" is used at the start of the pattern or just after
	"^" it matches the star character.

	Be aware that repeating "\_." can match a lot of text and take a long
	time.  For example, "\_.*END" matches all text from the current
	position to the last occurrence of "END" in the file.  Since the "*"
	will match as many as possible, this first skips over all lines until
	the end of the file and then tries matching "END", backing up one
	character at a time.

							*/\+*
\+	Matches 1 or more of the preceding atom, as many as possible. {not in
	Vi}

	${E_WHITE_FG}Example${E_RESET}		${E_GREEN_FG}Matches${E_RESET}
	^.\+$		any non-empty line
	\s\+		white space of at least one character

							*/\=*
\=	Matches 0 or 1 of the preceding atom, as many as possible. {not in Vi}

	${E_WHITE_FG}Example${E_RESET}		${E_GREEN_FG}Matches${E_RESET}
	foo\=		"fo" and "foo"

							*/\?*
\?	Just like \=.  Cannot be used when searching backwards with the "?"
	command. {not in Vi}

					*/\{* *E60* *E554* *E870*
\{n,m}	Matches n to m of the preceding atom, as many as possible
\{n}	Matches n of the preceding atom
\{n,}	Matches at least n of the preceding atom, as many as possible
\{,m}	Matches 0 to m of the preceding atom, as many as possible
\{}	Matches 0 or more of the preceding atom, as many as possible (like *)
							*/\{-*
\{-n,m}	matches n to m of the preceding atom, as few as possible
\{-n}	matches n of the preceding atom
\{-n,}	matches at least n of the preceding atom, as few as possible
\{-,m}	matches 0 to m of the preceding atom, as few as possible
\{-}	matches 0 or more of the preceding atom, as few as possible
	{Vi does not have any of these}

	n and m are positive decimal numbers or zero
								*non-greedy*
	If a "-" appears immediately after the "{", then a shortest match
	first algorithm is used (see example below).  In particular, "\{-}" is
	the same as "*" but uses the shortest match first algorithm.  BUT: A
	match that starts earlier is preferred over a shorter match: "a\{-}b"
	matches "aaab" in "xaaab".

	${E_WHITE_FG}Example${E_RESET}			${E_GREEN_FG}Matches${E_RESET}
	ab\{2,3}c		"abbc" or "abbbc"
	a\{5}			"aaaaa"
	ab\{2,}c		"abbc", "abbbc", "abbbbc", etc.
	ab\{,3}c		"ac", "abc", "abbc" or "abbbc"
	a[bc]\{3}d		"abbbd", "abbcd", "acbcd", "acccd", etc.
	a\(bc\)\{1,2}d		"abcd" or "abcbcd"
	a[bc]\{-}[cd]		"abc" in "abcd"
	a[bc]*[cd]		"abcd" in "abcd"

	The } may optionally be preceded with a backslash: \{n,m\}.

							*/\@=*
\@=	Matches the preceding atom with zero width. {not in Vi}

	${E_WHITE_FG}Like "(?=pattern)" in Perl.${E_RESET}

	${E_WHITE_FG}Example${E_RESET}			${E_GREEN_FG}Matches${E_RESET}
	foo\(bar\)\@=		"foo" in "foobar"
	foo\(bar\)\@=foo	nothing
							*/zero-width*
	When using "\@=" (or "^", "$", "\<", "\>") no characters are included
	in the match.  These items are only used to check if a match can be
	made.  This can be tricky, because a match with following items will
	be done in the same position.  The last example above will not match
	"foobarfoo", because it tries match "foo" in the same position where
	"bar" matched.

	Note that using "\&" works the same as using "\@=": "foo\&.." is the
	same as "\(foo\)\@=..".  But using "\&" is easier, you don't need the
	braces.


							*/\@!*
\@!	Matches with zero width if the preceding atom does NOT match at the
	current position. |/zero-width| {not in Vi}

	${E_WHITE_FG}Like "(?!pattern)" in Perl.${E_RESET}

	${E_WHITE_FG}Example${E_RESET}			${E_GREEN_FG}Matches${E_RESET}
	foo\(bar\)\@!		any "foo" not followed by "bar"
	a.\{-}p\@!		"a", "ap", "app", "appp", etc. not immediately
				followed by a "p"
	if \(\(then\)\@!.\)*$	"if " not followed by "then"

	Using "\@!" is tricky, because there are many places where a pattern
	does not match.  "a.*p\@!" will match from an "a" to the end of the
	line, because ".*" can match all characters in the line and the "p"
	doesn't match at the end of the line.  "a.\{-}p\@!" will match any
	"a", "ap", "app", etc. that isn't followed by a "p", because the "."
	can match a "p" and "p\@!" doesn't match after that.

	You can't use "\@!" to look for a non-match before the matching
	position: "\(foo\)\@!bar" will match "bar" in "foobar", because at the
	position where "bar" matches, "foo" does not match.  To avoid matching
	"foobar" you could use "\(foo\)\@!...bar", but that doesn't match a
	bar at the start of a line.  Use "\(foo\)\@<!bar".

	Useful example: to find "foo" in a line that does not contain "bar": >
		/^\%(.*bar\)\@!.*\zsfoo
<	This pattern first checks that there is not a single position in the
	line where "bar" matches.  If ".*bar" matches somewhere the \@! will
	reject the pattern.  When there is no match any "foo" will be found.
	The "\zs" is to have the match start just before "foo".

							*/\@<=*
\@<=	Matches with zero width if the preceding atom matches just before what
	follows. |/zero-width| {not in Vi}

	${E_WHITE_FG}Like "(?<=pattern)" in Perl, but Vim allows non-fixed-width patterns.${E_RESET}

	${E_WHITE_FG}Example${E_RESET}			${E_GREEN_FG}Matches${E_RESET}
	\(an\_s\+\)\@<=file	"file" after "an" and white space or an
				end-of-line
	For speed it's often much better to avoid this multi.  Try using "\zs"
	instead |/\zs|.  To match the same as the above example:
		an\_s\+\zsfile
	At least set a limit for the look-behind, see below.

	"\@<=" and "\@<!" check for matches just before what follows.
	Theoretically these matches could start anywhere before this position.
	But to limit the time needed, only the line where what follows matches
	is searched, and one line before that (if there is one).  This should
	be sufficient to match most things and not be too slow.

	In the old regexp engine the part of the pattern after "\@<=" and
	"\@<!" are checked for a match first, thus things like "\1" don't work
	to reference \(\) inside the preceding atom.  It does work the other
	way around:
	${E_RED_FG}Bad example${E_RESET}			${E_GREEN_FG}Matches${E_RESET}
	\%#=1\1\@<=,\([a-z]\+\)		",abc" in "abc,abc"

	However, the new regexp engine works differently, it is better to not
	rely on this behavior, do not use \@<= if it can be avoided:

	${E_WHITE_FG}Example${E_RESET}				${E_GREEN_FG}Matches${E_RESET}
	\([a-z]\+\)\zs,\1		",abc" in "abc,abc"

\@123<=
	Like "\@<=" but only look back 123 bytes. This avoids trying lots
	of matches that are known to fail and make executing the pattern very
	slow.  

	${E_WHITE_FG}Example${E_RESET} check if there is a "<" just before "span": /<\@1<=span

	This will try matching "<" only one byte before "span", which is the
	only place that works anyway.
	After crossing a line boundary, the limit is relative to the end of
	the line.  Thus the characters at the start of the line with the match
	are not counted (this is just to keep it simple).
	The number zero is the same as no limit.

							*/\@<!*
\@<!	Matches with zero width if the preceding atom does NOT match just
	before what follows.  Thus this matches if there is no position in the
	current or previous line where the atom matches such that it ends just
	before what follows.  |/zero-width| {not in Vi}

	${E_WHITE_FG}Like "(?<!pattern)" in Perl, but Vim allows non-fixed-width patterns.${E_RESET}

	The match with the preceding atom is made to end just before the match
	with what follows, thus an atom that ends in ".*" will work.
	Warning: This can be slow (because many positions need to be checked
	for a match).  Use a limit if you can, see below.

	${E_WHITE_FG}Example${E_RESET}			${E_GREEN_FG}Matches${E_RESET}
	\(foo\)\@<!bar		any "bar" that's not in "foobar"
	\(\/\/.*\)\@<!in	"in" which is not after "//"

\@123<!
	Like "\@<!" but only look back 123 bytes. This avoids trying lots of
	matches that are known to fail and make executing the pattern very
	slow.

							*/\@>*
\@>	Matches the preceding atom like matching a whole pattern. {not in Vi}

	${E_WHITE_FG}Like "(?>pattern)" in Perl.${E_RESET}

	${E_WHITE_FG}Example${E_RESET}		${E_GREEN_FG}Matches${E_RESET}
	\(a*\)\@>a	nothing (the "a*" takes all the "a"'s, there can't be
			another one following)

	This matches the preceding atom as if it was a pattern by itself.  If
	it doesn't match, there is no retry with shorter sub-matches or
	anything.  Observe this difference: "a*b" and "a*ab" both match
	"aaab", but in the second case the "a*" matches only the first two
	"a"s.  "\(a*\)\@>ab" will not match "aaab", because the "a*" matches
	the "aaa" (as many "a"s as possible), thus the "ab" can't match.


${E_WHITE_FG}=========================================================================${E_RESET}
tip_vim_EOF
}

tip_vimcolors () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_vimcolors_EOF

${E_WHITE_FG}Hints for writing a color scheme file:${E_RESET}

There are two basic ways to define a color scheme:

1. ${E_CYAN_FG}Define a new Normal color and set the 'background' option accordingly.${E_RESET}

	set background={light or dark}
	highlight clear
	highlight Normal ...
	...

2. ${E_CYAN_FG}Use the default Normal color and automatically adjust to the value of 'background'.${E_RESET}

	highlight clear Normal
	set background&
	highlight clear
	if &background == "light"
	  highlight Error ...
	  ...
	else
	  highlight Error ...
	  ...
	endif

	You can use :highlight clear to reset everything to the defaults, and then change the groups 
	that you want differently.  This will also work for groups that are added in later versions of Vim.
	Note that :highlight clear uses the value of 'background', thus set it before this command.
	Some attributes (e.g., bold) might be set in the defaults that you want removed in your color scheme.  
	Use something like "gui=NONE" to remove the attributes.

${E_CYAN_FG}In case you want to set 'background' depending on the colorscheme selected, this autocmd might be useful:${E_RESET} 

	autocmd SourcePre */colors/blue_sky.vim set background=dark

	Replace "blue_sky" with the name of the colorscheme.

${E_CYAN_FG}In case you want to tweak a colorscheme after it was loaded, check out the ColorScheme autocommand event.${E_RESET}

	To clean up just before loading another colorscheme, use the ColorSchemePre autocommand event.  
	For example:

	let g:term_ansi_colors = ...
	augroup MyColorscheme
	  au!
	  au ColorSchemePre * unlet g:term_ansi_colors
	  au ColorSchemePre * au! MyColorscheme
	augroup END

${E_CYAN_FG}To customize a colorscheme use another name, e.g.  "~/.vim/colors/mine.vim", and use ":runtime"${E_RESET}
${E_CYAN_FG}to load the original colorscheme:${E_RESET}

	" load the "evening" colorscheme
	runtime colors/evening.vim
	" change the color of statements
	hi Statement ctermfg=Blue guifg=Blue

${E_CYAN_FG}To see which highlight group is used where, see:${E_RESET} 
	${E_WHITE_FG}:help highlight-groups and :help group-name.${E_RESET}

	You can use ":highlight" to find out the current colors.  Exception: the
	ctermfg and ctermbg values are numbers, which are only valid for the current
	terminal.  Use the color names instead for better portability.  See ${E_WHITE_FG}:help cterm-colors${E_RESET}

${E_CYAN_FG}The default color settings can be found in the source file:${E_WHITE_FG}src/syntax.c.${E_RESET}
	Search for "highlight_init".

${E_MAGENTA_FG}If you think you have a color scheme that is good enough to be used by others,${E_RESET}
${E_MAGENTA_FG}please check the following items:${E_RESET}

	- Source the \${VIMRUNTIME}/colors/tools/check_colors.vim script to check for common mistakes.

	- Does it work in a color terminal as well as in the GUI? Is it consistent?

	- Is "g:colors_name" set to a meaningful value?  In case of doubt you can do it this way: >

		let g:colors_name = expand('<sfile>:t:r')

	- Is 'background' either used or appropriately set to "light" or "dark"?

	- Try setting 'hlsearch' and searching for a pattern, is the match easy to spot?

	- Split a window with ":split" and ":vsplit".  Are the status lines and vertical separators clearly visible?

	- In the GUI, is it easy to find the cursor, also in a file with lots of syntax highlighting?

	- In general, test your color scheme against as many filetypes, Vim features, environments, etc. as possible.

	- Do not use hard coded escape sequences, these will not work in other terminals.  Always use #RRGGBB for the GUI.

	- When targetting 8-16 colors terminals, don't count on "darkblue" to be blue and dark, or on "2" to be even 
	  vaguely reddish.  Names are more portable than numbers, though.

	- When targetting 256 colors terminals, prefer colors 16-255 to colors 0-15 for the same reason.

	- Typographic attributes (bold, italic, underline, reverse, etc.) are not universally supported.  
	  Don't count on any of them.

	- Is "g:terminal_ansi_colors" set to a list of 16 #RRGGBB values?

	- Try to keep your color scheme simple by avoiding unnecessary logic and refraining from adding options.  
	  The best color scheme is one that only requires: >

		colorscheme foobar

${E_WHITE_FG}The color schemes distributed with Vim are built with lifepillar/colortemplate${E_RESET}
${E_WHITE_FG}(https://github.com/lifepillar/vim-colortemplate).  It is therefore highly recommended.${E_RESET}

If you would like your color scheme to be distributed with Vim, make sure that:

	- it satisfies the guidelines above,
	- it was made with colortemplate,

	and join us at vim/colorschemes: (https://github.com/vim/colorschemes).

==============================================================================
${E_WHITE_FG}Highlight command			*:highlight* *:hi* *E28* *E411* *E415*${E_RESET}

There are three types of highlight groups:

	- The ones used for specific languages.  For these the name starts with the
	  name of the language.  Many of these don't have any attributes, but are
	  linked to a group of the second type.

	- The ones used for all syntax languages.

	- The ones used for the 'highlight' option.

${E_WHITE_FG}*hitest.vim*${E_RESET}

${E_CYAN_FG}You can see all the groups currently active with this command:${E_RESET}

    :so \${VIMRUNTIME}/syntax/hitest.vim

${E_CYAN_FG}This will open a new window containing all highlight group names, displayed in their own color.${E_RESET}

	*:colo* *:colorscheme* *E185*

${E_WHITE_FG}:colo[rscheme]	Output the name of the currently active color scheme.${E_RESET}

	This is basically the same as
		:echo g:colors_name

	In case g:colors_name has not been defined :colo will
	output "default".  When compiled without the |+eval|
	feature it will output "unknown".

${E_WHITE_FG}:colo[rscheme] {name}	Load color scheme {name}.${E_RESET}

	This searches 'runtimepath' for the file "colors/{name}.vim.
	The first one that is found is loaded.

	To see the name of the currently active color scheme:
		:colo

	The name is also stored in the g:colors_name variable.

	Doesn't work recursively, thus you can't use ":colorscheme" in a color scheme script.

	After the color scheme has been loaded the |ColorScheme| autocommand event is triggered.
	For info about writing a colorscheme file:

		:edit \${VIMRUNTIME}/colors/README.txt

${E_WHITE_FG}:hi[ghlight]		List all the current highlight groups that have attributes set.${E_RESET}

${E_WHITE_FG}:hi[ghlight] {group-name} List one highlight group.${E_RESET}

${E_WHITE_FG}:hi[ghlight] clear${E_RESET}

	Reset all highlighting to the defaults.  Removes all highlighting for groups added by the user!
	Uses the current value of 'background' to decide which default colors to use.

${E_WHITE_FG}:hi[ghlight] clear {group-name}${E_RESET}

${E_WHITE_FG}:hi[ghlight] {group-name} NONE${E_RESET}

	Disable the highlighting for one highlight group.  It is _not_ set back to the default colors.

${E_WHITE_FG}:hi[ghlight] [default] {group-name} {key}={arg}${E_RESET}

	Add a highlight group, or change the highlighting for an existing group.
	See |highlight-args| for the {key}={arg} arguments.
	See |:highlight-default| for the optional [default] argument.

	Normally a highlight group is added once when starting up.  This sets the
	default values for the highlighting.  After that, you can use additional
	highlight commands to change the arguments that you want to set to non-default
	values.  The value "NONE" can be used to switch the value off or go back to
	the default value.

	A simple way to change colors is with the |:colorscheme| command.  This loads
	a file with ":highlight" commands such as this:

${E_WHITE_FG}:hi Comment	gui=bold${E_RESET}

	Note that all settings that are not included remain the same, only the
	specified field is used, and settings are merged with previous ones.  So, the
	result is like this single command has been used:

${E_WHITE_FG}:hi Comment	term=bold ctermfg=Cyan guifg=#80a0ff gui=bold${E_RESET}
 
${E_WHITE_FG}*:highlight-verbose*${E_RESET}

	When listing a highlight group and 'verbose' is non-zero, the listing will also tell where it was last set.  

	Example:

	:verbose hi Comment
 	Comment        xxx term=bold ctermfg=4 guifg=Blue 
	   Last set from /home/mool/vim/vim7/runtime/syntax/syncolor.vim 

	When ":hi clear" is used then the script where this command is used will be
	mentioned for the default values. See |:verbose-cmd| for more information.

${E_WHITE_FG}*highlight-args* *E416* *E417* *E423*${E_RESET}

	There are three types of terminals for highlighting: 

	 term - a normal terminal (vt100, xterm)
	cterm - a color terminal (MS-DOS console, color-xterm, these have the "Co" termcap entry)
	  gui - the GUI

	For each type the highlighting can be given.  This makes it possible to use
	the same syntax file on all terminals, and use the optimal highlighting.

${E_GREEN_FG}1. highlight arguments for normal terminals${E_RESET}

	*bold* *underline* *undercurl*

	*inverse* *italic* *standout*

${E_WHITE_FG}term={attr-list}			*attr-list* *highlight-term* *E418*${E_RESET}

	attr-list is a comma separated list (without spaces) of the
	following items (in any order):
		bold
		underline
		undercurl	not always available
		reverse
		inverse		same as reverse
		italic
		standout
		NONE		no attributes used (used to reset it)

	Note that "bold" can be used here and by using a bold font.  They
	have the same effect.
	"undercurl" is a curly underline.  When "undercurl" is not possible
	then "underline" is used.  In general "undercurl" is only available in
	the GUI.  The color is set with |highlight-guisp|.


${E_WHITE_FG}start={term-list}				*highlight-start* *E422*${E_RESET}

${E_WHITE_FG}stop={term-list}				*term-list* *highlight-stop*${E_RESET}

	These lists of terminal codes can be used to get
	non-standard attributes on a terminal.

	The escape sequence specified with the "start" argument
	is written before the characters in the highlighted
	area.  It can be anything that you want to send to the
	terminal to highlight this area.  The escape sequence
	specified with the "stop" argument is written after the
	highlighted area.  This should undo the "start" argument.
	Otherwise the screen will look messed up.

	The {term-list} can have two forms:

	1. A string with escape sequences.
	   This is any string of characters, except that it can't start with
	   "t_" and blanks are not allowed.  The <> notation is recognized
	   here, so you can use things like "<Esc>" and "<Space>".  Example:
		start=<Esc>[27h;<Esc>[<Space>r;

	2. A list of terminal codes.
	   Each terminal code has the form "t_xx", where "xx" is the name of
	   the termcap entry.  The codes have to be separated with commas.
	   White space is not allowed.	Example:
		start=t_C1,t_BL
	   The terminal codes must exist for this to work.


${E_GREEN_FG}2. highlight arguments for color terminals${E_RESET}


${E_WHITE_FG}cterm={attr-list}					*highlight-cterm*${E_RESET}

	See above for the description of {attr-list} |attr-list|.
	The "cterm" argument is likely to be different from "term", when
	colors are used.  For example, in a normal terminal comments could
	be underlined, in a color terminal they can be made Blue.
	Note: Many terminals (e.g., DOS console) can't mix these attributes
	with coloring.	Use only one of "cterm=" OR "ctermfg=" OR "ctermbg=".


${E_WHITE_FG}ctermfg={color-nr}				*highlight-ctermfg* *E421*${E_RESET}

${E_WHITE_FG}ctermbg={color-nr}				*highlight-ctermbg*${E_RESET}

	The {color-nr} argument is a color number.  Its range is zero to
	(not including) the number given by the termcap entry "Co".
	The actual color with this number depends on the type of terminal
	and its settings.  Sometimes the color also depends on the settings of
	"cterm".  For example, on some systems "cterm=bold ctermfg=3" gives
	another color, on others you just get color 3.

	For an xterm this depends on your resources, and is a bit
	unpredictable.	See your xterm documentation for the defaults.	The
	colors for a color-xterm can be changed from the .Xdefaults file.
	Unfortunately this means that it's not possible to get the same colors
	for each user.	See |xterm-color| for info about color xterms.

	The MSDOS standard colors are fixed (in a console window), so these
	have been used for the names.  But the meaning of color names in X11
	are fixed, so these color settings have been used, to make the
	highlighting settings portable (complicated, isn't it?).  The
	following names are recognized, with the color number used:


${E_WHITE_FG}*cterm-colors*${E_RESET}

	    NR-16   NR-8    COLOR NAME 
	    0	    0	    Black
	    1	    4	    DarkBlue
	    2	    2	    DarkGreen
	    3	    6	    DarkCyan
	    4	    1	    DarkRed
	    5	    5	    DarkMagenta
	    6	    3	    Brown, DarkYellow
	    7	    7	    LightGray, LightGrey, Gray, Grey
	    8	    0*	    DarkGray, DarkGrey
	    9	    4*	    Blue, LightBlue
	    10	    2*	    Green, LightGreen
	    11	    6*	    Cyan, LightCyan
	    12	    1*	    Red, LightRed
	    13	    5*	    Magenta, LightMagenta
	    14	    3*	    Yellow, LightYellow
	    15	    7*	    White

	The number under "NR-16" is used for 16-color terminals ('t_Co'
	greater than or equal to 16).  The number under "NR-8" is used for
	8-color terminals ('t_Co' less than 16).  The '*' indicates that the
	bold attribute is set for ctermfg.  In many 8-color terminals (e.g.,
	"linux"), this causes the bright colors to appear.  This doesn't work
	for background colors!	Without the '*' the bold attribute is removed.
	If you want to set the bold attribute in a different way, put a
	"cterm=" argument AFTER the "ctermfg=" or "ctermbg=" argument.	Or use
	a number instead of a color name.

	The case of the color names is ignored.
	Note that for 16 color ansi style terminals (including xterms), the
	numbers in the NR-8 column is used.  Here '*' means 'add 8' so that Blue
	is 12, DarkGray is 8 etc.

	Note that for some color terminals these names may result in the wrong
	colors!

   *:hi-normal-cterm*

	When setting the "ctermfg" or "ctermbg" colors for the Normal group,
	these will become the colors used for the non-highlighted text.
	Example:
		:highlight Normal ctermfg=grey ctermbg=darkblue
 	When setting the "ctermbg" color for the Normal group, the
	'background' option will be adjusted automatically.  This causes the
	highlight groups that depend on 'background' to change!  This means
	you should set the colors for Normal first, before setting other
	colors.
	When a colorscheme is being used, changing 'background' causes it to
	be reloaded, which may reset all colors (including Normal).  First
	delete the "g:colors_name" variable when you don't want this.

	When you have set "ctermfg" or "ctermbg" for the Normal group, Vim
	needs to reset the color when exiting.	This is done with the "op"
	termcap entry |t_op|.  If this doesn't work correctly, try setting the
	't_op' option in your .vimrc.

							*E419* *E420*

	When Vim knows the normal foreground and background colors, "fg" and
	"bg" can be used as color names.  This only works after setting the
	colors for the Normal group and for the MS-DOS console.  Example, for
	reverse video:
	    :highlight Visual ctermfg=bg ctermbg=fg
 	Note that the colors are used that are valid at the moment this
	command are given.  If the Normal group colors are changed later, the
	"fg" and "bg" colors will not be adjusted.


${E_GREEN_FG}3. highlight arguments for the GUI${E_RESET}


${E_WHITE_FG}gui={attr-list}						*highlight-gui*${E_RESET}

	These give the attributes to use in the GUI mode.
	See |attr-list| for a description.
	Note that "bold" can be used here and by using a bold font.  They
	have the same effect.
	Note that the attributes are ignored for the "Normal" group.


${E_WHITE_FG}font={font-name}					*highlight-font*${E_RESET}

	font-name is the name of a font, as it is used on the system Vim
	runs on.  For X11 this is a complicated name, for example:
   font=-misc-fixed-bold-r-normal--14-130-75-75-c-70-iso8859-1
 
	The font-name "NONE" can be used to revert to the default font.
	When setting the font for the "Normal" group, this becomes the default
	font (until the 'guifont' option is changed; the last one set is
	used).
	The following only works with Motif and Athena, not with other GUIs:
	When setting the font for the "Menu" group, the menus will be changed.
	When setting the font for the "Tooltip" group, the tooltips will be
	changed.
	All fonts used, except for Menu and Tooltip, should be of the same
	character size as the default font!  Otherwise redrawing problems will
	occur.


${E_WHITE_FG}guifg={color-name}					*highlight-guifg*${E_RESET}

${E_WHITE_FG}guibg={color-name}					*highlight-guibg*${E_RESET}

${E_WHITE_FG}guisp={color-name}					*highlight-guisp*${E_RESET}

	These give the foreground (guifg), background (guibg) and special
	(guisp) color to use in the GUI.  "guisp" is used for undercurl.
	There are a few special names:
		NONE		no color (transparent)
		bg		use normal background color
		background	use normal background color
		fg		use normal foreground color
		foreground	use normal foreground color
	To use a color name with an embedded space or other special character,
	put it in single quotes.  The single quote cannot be used then.
	Example:
	    :hi comment guifg='salmon pink'
 
   *gui-colors*

	Suggested color names (these are available on most systems):
	    Red		LightRed	DarkRed
	    Green	LightGreen	DarkGreen	SeaGreen
	    Blue	LightBlue	DarkBlue	SlateBlue
	    Cyan	LightCyan	DarkCyan
	    Magenta	LightMagenta	DarkMagenta
	    Yellow	LightYellow	Brown		DarkYellow
	    Gray	LightGray	DarkGray
	    Black	White
	    Orange	Purple		Violet

	In the Win32 GUI version, additional system colors are available.  See
	|win32-colors|.

	You can also specify a color by its Red, Green and Blue values.
	The format is "#rrggbb", where
		"rr"	is the Red value
		"gg"	is the Green value
		"bb"	is the Blue value
	All values are hexadecimal, range from "00" to "ff".  Examples:
  :highlight Comment guifg=#11f0c3 guibg=#ff00ff
 
${E_WHITE_FG}*highlight-groups* *highlight-default*${E_RESET}

	These are the default highlighting groups.  These groups are used by the
	'highlight' option default.  Note that the highlighting depends on the value
	of 'background'.  You can see the current settings with the ":highlight"
	command.

${E_WHITE_FG}*hl-ColorColumn* ColorColumn	used for the columns set with 'colorcolumn'${E_RESET}

${E_WHITE_FG}*hl-Conceal*${E_RESET}

	Conceal placeholder characters substituted for concealed text (see 'conceallevel')

${E_WHITE_FG}*hl-Cursor*${E_RESET}

	Cursor the character under the cursor

${E_WHITE_FG}*hl-CursorIM* CursorIM like Cursor, but used when in IME mode |CursorIM|${E_RESET}

${E_WHITE_FG}*hl-CursorColumn* CursorColumn the screen column that the cursor is in when 'cursorcolumn' is set${E_RESET}

${E_WHITE_FG}*hl-CursorLine* CursorLine	the screen line that the cursor is in when 'cursorline' is set${E_RESET}

${E_WHITE_FG}*hl-Directory* Directory directory names (and other special names in listings)${E_RESET}

${E_WHITE_FG}*hl-DiffAdd* DiffAdd diff mode: Added line |diff.txt|${E_RESET}

${E_WHITE_FG}*hl-DiffChange* DiffChange	diff mode: Changed line |diff.txt|${E_RESET}

${E_WHITE_FG}*hl-DiffDelete* DiffDelete	diff mode: Deleted line |diff.txt|${E_RESET}

${E_WHITE_FG}*hl-DiffText* DiffText	diff mode: Changed text within a changed line |diff.txt|${E_RESET}

${E_WHITE_FG}*hl-ErrorMsg* ErrorMsg	error messages on the command line${E_RESET}

${E_WHITE_FG}*hl-VertSplit* VertSplit	the column separating vertically split windows${E_RESET}

${E_WHITE_FG}*hl-Folded* Folded line used for closed folds${E_RESET}

${E_WHITE_FG}*hl-FoldColumn* FoldColumn	'foldcolumn'${E_RESET}

${E_WHITE_FG}*hl-SignColumn* SignColumn	column where |signs| are displayed${E_RESET}

${E_WHITE_FG}*hl-IncSearch* IncSearch 'incsearch' highlighting; also used for the text replaced with ":s///c"${E_RESET}

${E_WHITE_FG}*hl-LineNr* LineNr Line number for ":number" and ":#" commands, and when 'number' or 'relativenumber' option is set.${E_RESET}

${E_WHITE_FG}*hl-MatchParen* MatchParen${E_RESET}

		The character under the cursor or just before it, if it is a paired bracket, and its match. |pi_paren.txt|

${E_WHITE_FG}*hl-ModeMsg* ModeMsg	'showmode' message (e.g., "-- INSERT --"${E_RESET}

${E_WHITE_FG}*hl-MoreMsg* MoreMsg		|more-prompt${E_RESET}

${E_WHITE_FG}*hl-NonText* NonText	${E_RESET}

      '~' and '@' at the end of the window, characters from
		'showbreak' and other characters that do not really exist in
		the text (e.g., ">" displayed when a double-wide character
		doesn't fit at the end of the line).

${E_WHITE_FG}*hl-Normal* Normal		normal tex${E_RESET}

${E_WHITE_FG}*hl-Pmenu* Pmenu		Popup menu: normal item${E_RESET}

${E_WHITE_FG}*hl-PmenuSel* PmenuSel	Popup menu: selected item${E_RESET}

${E_WHITE_FG}*hl-PmenuSbar* PmenuSbar	Popup menu: scrollbar${E_RESET}

${E_WHITE_FG}*hl-PmenuThumb* PmenuThumb	Popup menu: Thumb of the scrollbar${E_RESET}

${E_WHITE_FG}*hl-Question* Question	|hit-enter| prompt and yes/no question${E_RESET}

${E_WHITE_FG}*hl-Search* Search${E_RESET}

      Last search pattern highlighting (see 'hlsearch').
		Also used for highlighting the current line in the quickfix
		window and similar items that need to stand out.

${E_WHITE_FG}*hl-SpecialKey*${E_RESET}

	SpecialKey	Meta and special keys listed with ":map", also for text used
	to show unprintable characters in the text, 'listchars'.
	Generally: text that is displayed differently from what it
	really is.

${E_WHITE_FG}*hl-SpellBad*${E_RESET}

	SpellBad	Word that is not recognized by the spellchecker. |spell|
	This will be combined with the highlighting used otherwise.

${E_WHITE_FG}*hl-SpellCap*${E_RESET}

	SpellCap	Word that should start with a capital. |spell|
	This will be combined with the highlighting used otherwise.

${E_WHITE_FG}*hl-SpellLocal*${E_RESET}

	SpellLocal	Word that is recognized by the spellchecker as one that is
	used in another region. |spell|
	This will be combined with the highlighting used otherwise.

${E_WHITE_FG}*hl-SpellRare*${E_RESET}

	SpellRare	Word that is recognized by the spellchecker as one that is
	hardly ever used. |spell|
	This will be combined with the highlighting used otherwise.

${E_WHITE_FG}*hl-StatusLine*${E_RESET}

	StatusLine	status line of current window

${E_WHITE_FG}*hl-StatusLineNC*${E_RESET}

	StatusLineNC	status lines of not-current windows
	Note: if this is equal to "StatusLine" Vim will use "^^^" in
	the status line of the current window.

${E_WHITE_FG}*hl-TabLine*${E_RESET}

	TabLine		tab pages line, not active tab page label

${E_WHITE_FG}*hl-TabLineFill*${E_RESET}

	TabLineFill	tab pages line, where there are no labels

${E_WHITE_FG}*hl-TabLineSel*${E_RESET}

	TabLineSel	tab pages line, active tab page label

${E_WHITE_FG}*hl-Title*${E_RESET}

	Title		titles for output from ":set all", ":autocmd" etc.

${E_WHITE_FG}*hl-Visual*${E_RESET}

	Visual		Visual mode selection

${E_WHITE_FG}*hl-VisualNOS*${E_RESET}

	VisualNOS	Visual mode selection when vim is "Not Owning the Selection".
	Only X11 Gui's |gui-x11| and |xterm-clipboard| supports this.

${E_WHITE_FG}*hl-WarningMsg*${E_RESET}

	WarningMsg	warning messages

${E_WHITE_FG}*hl-WildMenu*${E_RESET}

	WildMenu	current match in 'wildmenu' completion

${E_WHITE_FG}*hl-User1* *hl-User1..9* *hl-User9*${E_RESET}

	The 'statusline' syntax allows the use of 9 different highlights in the
	statusline and ruler (via 'rulerformat').  The names are User1 to User9.

	For the GUI you can use the following groups to set the colors for the menu,
	scrollbars and tooltips.  They don't have defaults.  This doesn't work for the
	Win32 GUI.  Only three highlight arguments have any effect here: font, guibg,
	and guifg.


${E_WHITE_FG}*hl-Menu*${E_RESET}

	Menu		Current font, background and foreground colors of the menus.
	Also used for the toolbar.
	Applicable highlight arguments: font, guibg, guifg.

	NOTE: For Motif and Athena the font argument actually
	specifies a fontset at all times, no matter if 'guifontset' is
	empty, and as such it is tied to the current |:language| when set.


${E_WHITE_FG}*hl-Scrollbar*${E_RESET}

	Scrollbar	Current background and foreground of the main window's scrollbars.
	Applicable highlight arguments: guibg, guifg.


${E_WHITE_FG}*hl-Tooltip*${E_RESET}

	Tooltip		Current font, background and foreground of the tooltips.
	Applicable highlight arguments: font, guibg, guifg.

	NOTE: For Motif and Athena the font argument actually
	specifies a fontset at all times, no matter if 'guifontset' is
	empty, and as such it is tied to the current |:language| when
	set.

==============================================================================
${E_MAGENTA_FG}Linking groups${E_RESET}

${E_WHITE_FG}*:hi-link* *:highlight-link* *E412* *E413*${E_RESET}

	When you want to use the same highlighting for several syntax groups, you
	can do this more easily by linking the groups into one common highlight
	group, and give the color attributes only for that group.

To set a link:

${E_WHITE_FG}:hi[ghlight][!] [default] link {from-group} {to-group}${E_RESET}

To remove a link:

${E_WHITE_FG}:hi[ghlight][!] [default] link {from-group} NONE${E_RESET}


	Notes:							*E414*
	- If the {from-group} and/or {to-group} doesn't exist, it is created.  You
	  don't get an error message for a non-existing group.
	- As soon as you use a ":highlight" command for a linked group, the link is
	  removed.
	- If there are already highlight settings for the {from-group}, the link is
	  not made, unless the '!' is given.  For a ":highlight link" command in a
	  sourced file, you don't get an error message.  This can be used to skip
	  links for groups that already have settings.


${E_WHITE_FG}*:hi-default* *:highlight-default*${E_RESET}

	The [default] argument is used for setting the default highlighting for a
	group.	If highlighting has already been specified for the group the command
	will be ignored.  Also when there is an existing link.

	Using [default] is especially useful to overrule the highlighting of a
	specific syntax file.  For example, the C syntax file contains:

${E_WHITE_FG}:highlight default link cComment Comment${E_RESET}

If you like Question highlighting for C comments, put this in your vimrc file:

	:highlight link cComment Question

	Without the "default" in the C syntax file, the highlighting would be
	overruled when the syntax file is loaded.

==============================================================================
${E_MAGENTA_FG}Cleaning up${E_RESET}

${E_WHITE_FG}*:syn-clear* *E391*${E_RESET}

If you want to clear the syntax stuff for the current buffer, you can use this command:

${E_WHITE_FG}:syntax clear${E_RESET}

	This command should be used when you want to switch off syntax highlighting,
	or when you want to switch to using another syntax.  It's normally not needed
	in a syntax file itself, because syntax is cleared by the autocommands that
	load the syntax file.

	The command also deletes the "b:current_syntax" variable, since no syntax is
	loaded after this command.

	If you want to disable syntax highlighting for all buffers, you need to remove
	the autocommands that load the syntax files:

${E_WHITE_FG}:syntax off${E_RESET}

	What this command actually does, is executing the command

${E_WHITE_FG}:source \${VIMRUNTIME}/syntax/nosyntax.vim${E_RESET}

	See the "nosyntax.vim" file for details.  Note that for this to work
	\${VIMRUNTIME} must be valid.  See |\${VIMRUNTIME}|.

To clean up specific syntax groups for the current buffer:

${E_WHITE_FG}:syntax clear {group-name} ..${E_RESET}

This removes all patterns and keywords for {group-name}.

To clean up specific syntax group lists for the current buffer:

${E_WHITE_FG}:syntax clear @{grouplist-name} ..${E_RESET}

This sets {grouplist-name}'s contents to an empty list.

${E_WHITE_FG}*:syntax-reset* *:syn-reset*${E_RESET}

	If you have changed the colors and messed them up, use this command to get the
	defaults back:

${E_WHITE_FG}:syntax reset${E_RESET}

	This doesn't change the colors for the 'highlight' option.

	Note that the syntax colors that you set in your vimrc file will also be reset
	back to their Vim default.
	Note that if you are using a color scheme, the colors defined by the color
	scheme for syntax highlighting will be lost.

	What this actually does is:

	let g:syntax_cmd = "reset"
	runtime! syntax/syncolor.vim

	Note that this uses the 'runtimepath' option.


${E_WHITE_FG}*syncolor*${E_RESET}

	If you want to use different colors for syntax highlighting, you can add a Vim
	script file to set these colors.  Put this file in a directory in
	'runtimepath' which comes after ${VIMRUNTIME}, so that your settings overrule
	the default colors.  This way these colors will be used after the ":syntax
	reset" command.

	For Unix you can use the file ~/.vim/after/syntax/syncolor.vim.  Example:

		if &background == "light"
		  highlight comment ctermfg=darkgreen guifg=darkgreen
		else
		  highlight comment ctermfg=green guifg=green
		endif

									*E679*
	Do make sure this syncolor.vim script does not use a "syntax on", set the
	'background' option or uses a "colorscheme" command, because it results in an
	endless loop.

	Note that when a color scheme is used, there might be some confusion whether
	your defined colors are to be used or the colors from the scheme.  This
	depends on the color scheme file.  See |:colorscheme|.


${E_WHITE_FG}*syntax_cmd*${E_RESET}

	The "syntax_cmd" variable is set to one of these values when the
	syntax/syncolor.vim files are loaded:

   "on"		":syntax on" command.  Highlight colors are overruled but
		links are kept
   "enable"	":syntax enable" command.  Only define colors for groups that
		don't have highlighting yet.  Use ":syntax default".
   "reset"	":syntax reset" command or loading a color scheme.  Define all
		the colors.
   "skip"	Don't define colors.  Used to skip the default settings when a
		syncolor.vim file earlier in 'runtimepath' has already set
		them.

==============================================================================
${E_MAGENTA_FG}Highlighting tags					*tag-highlight*${E_RESET}

If you want to highlight all the tags in your file, you can use the following
mappings.

	<F11>	-- Generate tags.vim file, and highlight tags.
	<F12>	-- Just highlight tags based on existing tags.vim file.

  :map <F11>  :sp tags<CR>:%s/^\([^	:]*:\)\=\([^	]*\).*/syntax keyword Tag \2/<CR>:wq! tags.vim<CR>/^<CR><F12>
  :map <F12>  :so tags.vim<CR>

WARNING: The longer the tags file, the slower this will be, and the more
memory Vim will consume.

Only highlighting typedefs, unions and structs can be done too.  For this you
must use Exuberant ctags found at	http://ctags.sf.net.

Put these lines in your Makefile:

# Make a highlight file for types.  Requires Exuberant ctags and awk
types: types.vim
types.vim: *.[ch]
	ctags --c-kinds=gstu -o- *.[ch] YXXY\
		awk 'BEGIN{printf("syntax keyword Type\t")} {printf("%s ", $${1})}END{print ""}' > ${@}

And put these lines in your .vimrc:

   " load the types.vim highlighting file, if it exists
   autocmd BufRead,BufNewFile *.[ch] let fname = expand('<afile>:p:h') . '/types.vim'
   autocmd BufRead,BufNewFile *.[ch] if filereadable(fname)
   autocmd BufRead,BufNewFile *.[ch]   exe 'so ' . fname
   autocmd BufRead,BufNewFile *.[ch] endif

==============================================================================
${E_MAGENTA_FG}Window-local syntax				*:ownsyntax*${E_RESET}

Normally all windows on a buffer share the same syntax settings. It is
possible, however, to set a particular window on a file to have its own
private syntax setting. A possible example would be to edit LaTeX source
with conventional highlighting in one window, while seeing the same source
highlighted differently (so as to hide control sequences and indicate bold,
italic etc regions) in another. The 'scrollbind' option is useful here.

To set the current window to have the syntax "foo", separately from all other
windows on the buffer:

${E_WHITE_FG}:ownsyntax foo${E_RESET}

${E_WHITE_FG}*w:current_syntax*${E_RESET}

	This will set the "w:current_syntax" variable to "foo".  The value of
	"b:current_syntax" does not change.  This is implemented by saving and
	restoring "b:current_syntax", since the syntax files do set
	"b:current_syntax".  The value set by the syntax file is assigned to
	"w:current_syntax".

	Once a window has its own syntax, syntax commands executed from other windows
	on the same buffer (including :syntax clear) have no effect. Conversely, 
	syntax commands executed from that window do not effect other windows on the
	same buffer.

	A window with its own syntax reverts to normal behavior when another buffer
	is loaded into that window or the file is reloaded.
	When splitting the window, the new window will use the original syntax.

==============================================================================
${E_MAGENTA_FG}Color xterms				*xterm-color* *color-xterm*${E_RESET}

Most color xterms have only eight colors.  If you don't get colors with the
default setup, it should work with these lines in your .vimrc:
   :if &term =~ "xterm"
   :  if has("terminfo")
   :	set t_Co=8
   :	set t_Sf=<Esc>[3%p1%dm
   :	set t_Sb=<Esc>[4%p1%dm
   :  else
   :	set t_Co=8
   :	set t_Sf=<Esc>[3%dm
   :	set t_Sb=<Esc>[4%dm
   :  endif
   :endif
 	[<Esc> is a real escape, type CTRL-V <Esc>]

You might want to change the first "if" to match the name of your terminal,
e.g. "dtterm" instead of "xterm".

Note: Do these settings BEFORE doing ":syntax on".  Otherwise the colors may
be wrong.

${E_WHITE_FG}*xiterm* *rxvt*${E_RESET}

	The above settings have been mentioned to work for xiterm and rxvt too.
	But for using 16 colors in an rxvt these should work with terminfo:

	:set t_AB=<Esc>[%?%p1%{8}%<%t25;%p1%{40}%+%e5;%p1%{32}%+%;%dm
	:set t_AF=<Esc>[%?%p1%{8}%<%t22;%p1%{30}%+%e1;%p1%{22}%+%;%dm
 

${E_WHITE_FG}*colortest.vim*${E_RESET}

	To test your color setup, a file has been included in the Vim distribution.
	To use it, execute this command:

   :runtime syntax/colortest.vim

	Some versions of xterm (and other terminals, like the Linux console) can
	output lighter foreground colors, even though the number of colors is defined
	at 8.  Therefore Vim sets the "cterm=bold" attribute for light foreground
	colors, when 't_Co' is 8.


${E_WHITE_FG}*xfree-xterm*${E_RESET}

	To get 16 colors or more, get the newest xterm version (which should be
	included with XFree86 3.3 and later).  You can also find the latest version
	at:
		http://invisible-island.net/xterm/xterm.html
	Here is a good way to configure it.  This uses 88 colors and enables the
	termcap-query feature, which allows Vim to ask the xterm how many colors it
	supports.
		./configure --disable-bold-color --enable-88-color --enable-tcap-query
	If you only get 8 colors, check the xterm compilation settings.
	(Also see |UTF8-xterm| for using this xterm with UTF-8 character encoding).

	This xterm should work with these lines in your .vimrc (for 16 colors):
		:if has("terminfo")
		:  set t_Co=16
		:  set t_AB=<Esc>[%?%p1%{8}%<%t%p1%{40}%+%e%p1%{92}%+%;%dm
		:  set t_AF=<Esc>[%?%p1%{8}%<%t%p1%{30}%+%e%p1%{82}%+%;%dm
		:else
		:  set t_Co=16
		:  set t_Sf=<Esc>[3%dm
		:  set t_Sb=<Esc>[4%dm
		:endif
		[<Esc> is a real escape, type CTRL-V <Esc>]

	Without |+terminfo|, Vim will recognize these settings, and automatically
	translate cterm colors of 8 and above to "<Esc>[9%dm" and "<Esc>[10%dm".
	Colors above 16 are also translated automatically.

	For 256 colors this has been reported to work:

		:set t_AB=<Esc>[48;5;%dm
		:set t_AF=<Esc>[38;5;%dm

	Or just set the TERM environment variable to "xterm-color" or "xterm-16color"
	and try if that works.

	You probably want to use these X resources (in your ~/.Xdefaults file):
		XTerm*color0:			#000000
		XTerm*color1:			#c00000
		XTerm*color2:			#008000
		XTerm*color3:			#808000
		XTerm*color4:			#0000c0
		XTerm*color5:			#c000c0
		XTerm*color6:			#008080
		XTerm*color7:			#c0c0c0
		XTerm*color8:			#808080
		XTerm*color9:			#ff6060
		XTerm*color10:			#00ff00
		XTerm*color11:			#ffff00
		XTerm*color12:			#8080ff
		XTerm*color13:			#ff40ff
		XTerm*color14:			#00ffff
		XTerm*color15:			#ffffff
		Xterm*cursorColor:		Black

	[Note: The cursorColor is required to work around a bug, which changes the
	cursor color to the color of the last drawn text.  This has been fixed by a
	newer version of xterm, but not everybody is using it yet.]

	To get these right away, reload the .Xdefaults file to the X Option database Manager 
	(you only need to do this when you just changed the .Xdefaults file): xrdb -merge ~/.Xdefaults
 

${E_WHITE_FG}*xterm-blink* *xterm-blinking-cursor*${E_RESET}

	To make the cursor blink in an xterm, see tools/blink.c.  Or use Thomas
	Dickey's xterm above patchlevel 107 (see above for where to get it), with
	these resources:

	XTerm*cursorBlink:	on
	XTerm*cursorOnTime:	400
	XTerm*cursorOffTime:	250
	XTerm*cursorColor:	White


${E_WHITE_FG}*hpterm-color*${E_RESET}

	These settings work (more or less) for an hpterm, which only supports 8
	foreground colors:

   :if has("terminfo")
   :  set t_Co=8
   :  set t_Sf=<Esc>[&v%p1%dS
   :  set t_Sb=<Esc>[&v7S
   :else
   :  set t_Co=8
   :  set t_Sf=<Esc>[&v%dS
   :  set t_Sb=<Esc>[&v7S
   :endif
 	[<Esc> is a real escape, type CTRL-V <Esc>]


${E_WHITE_FG}*Eterm* *enlightened-terminal*${E_RESET}

		These settings have been reported to work for the Enlightened terminal
		emulator, or Eterm.  They might work for all xterm-like terminals that use the
		bold attribute to get bright colors.  Add an ":if" like above when needed.

       :set t_Co=16
       :set t_AF=^[[%?%p1%{8}%<%t3%p1%d%e%p1%{22}%+%d;1%;m
       :set t_AB=^[[%?%p1%{8}%<%t4%p1%d%e%p1%{32}%+%d;1%;m
 

${E_WHITE_FG}*TTpro-telnet*${E_RESET}

	These settings should work for TTpro telnet.  Tera Term Pro is a freeware /
	open-source program for MS-Windows.

	set t_Co=16
	set t_AB=^[[%?%p1%{8}%<%t%p1%{40}%+%e%p1%{32}%+5;%;%dm
	set t_AF=^[[%?%p1%{8}%<%t%p1%{30}%+%e%p1%{22}%+1;%;%dm

	Also make sure TTpro's Setup / Window / Full Color is enabled, and make sure
	that Setup / Font / Enable Bold is NOT enabled.
	(info provided by John Love-Jensen <eljay@Adobe.COM>)

--- CTERM ---
hi  x016_Grey0              ctermfg=16   guifg=#000000  "rgb=0,0,0
hi  x017_NavyBlue           ctermfg=17   guifg=#00005f  "rgb=0,0,95
hi  x018_DarkBlue           ctermfg=18   guifg=#000087  "rgb=0,0,135
hi  x019_Blue3              ctermfg=19   guifg=#0000af  "rgb=0,0,175
hi  x020_Blue3              ctermfg=20   guifg=#0000d7  "rgb=0,0,215
hi  x021_Blue1              ctermfg=21   guifg=#0000ff  "rgb=0,0,255
hi  x022_DarkGreen          ctermfg=22   guifg=#005f00  "rgb=0,95,0
hi  x023_DeepSkyBlue4       ctermfg=23   guifg=#005f5f  "rgb=0,95,95
hi  x024_DeepSkyBlue4       ctermfg=24   guifg=#005f87  "rgb=0,95,135
hi  x025_DeepSkyBlue4       ctermfg=25   guifg=#005faf  "rgb=0,95,175
hi  x026_DodgerBlue3        ctermfg=26   guifg=#005fd7  "rgb=0,95,215
hi  x027_DodgerBlue2        ctermfg=27   guifg=#005fff  "rgb=0,95,255
hi  x028_Green4             ctermfg=28   guifg=#008700  "rgb=0,135,0
hi  x029_SpringGreen4       ctermfg=29   guifg=#00875f  "rgb=0,135,95
hi  x030_Turquoise4         ctermfg=30   guifg=#008787  "rgb=0,135,135
hi  x031_DeepSkyBlue3       ctermfg=31   guifg=#0087af  "rgb=0,135,175
hi  x032_DeepSkyBlue3       ctermfg=32   guifg=#0087d7  "rgb=0,135,215
hi  x033_DodgerBlue1        ctermfg=33   guifg=#0087ff  "rgb=0,135,255
hi  x034_Green3             ctermfg=34   guifg=#00af00  "rgb=0,175,0
hi  x035_SpringGreen3       ctermfg=35   guifg=#00af5f  "rgb=0,175,95
hi  x036_DarkCyan           ctermfg=36   guifg=#00af87  "rgb=0,175,135
hi  x037_LightSeaGreen      ctermfg=37   guifg=#00afaf  "rgb=0,175,175
hi  x038_DeepSkyBlue2       ctermfg=38   guifg=#00afd7  "rgb=0,175,215
hi  x039_DeepSkyBlue1       ctermfg=39   guifg=#00afff  "rgb=0,175,255
hi  x040_Green3             ctermfg=40   guifg=#00d700  "rgb=0,215,0
hi  x041_SpringGreen3       ctermfg=41   guifg=#00d75f  "rgb=0,215,95
hi  x042_SpringGreen2       ctermfg=42   guifg=#00d787  "rgb=0,215,135
hi  x043_Cyan3              ctermfg=43   guifg=#00d7af  "rgb=0,215,175
hi  x044_DarkTurquoise      ctermfg=44   guifg=#00d7d7  "rgb=0,215,215
hi  x045_Turquoise2         ctermfg=45   guifg=#00d7ff  "rgb=0,215,255
hi  x046_Green1             ctermfg=46   guifg=#00ff00  "rgb=0,255,0
hi  x047_SpringGreen2       ctermfg=47   guifg=#00ff5f  "rgb=0,255,95
hi  x048_SpringGreen1       ctermfg=48   guifg=#00ff87  "rgb=0,255,135
hi  x049_MediumSpringGreen  ctermfg=49   guifg=#00ffaf  "rgb=0,255,175
hi  x050_Cyan2              ctermfg=50   guifg=#00ffd7  "rgb=0,255,215
hi  x051_Cyan1              ctermfg=51   guifg=#00ffff  "rgb=0,255,255
hi  x052_DarkRed            ctermfg=52   guifg=#5f0000  "rgb=95,0,0
hi  x053_DeepPink4          ctermfg=53   guifg=#5f005f  "rgb=95,0,95
hi  x054_Purple4            ctermfg=54   guifg=#5f0087  "rgb=95,0,135
hi  x055_Purple4            ctermfg=55   guifg=#5f00af  "rgb=95,0,175
hi  x056_Purple3            ctermfg=56   guifg=#5f00d7  "rgb=95,0,215
hi  x057_BlueViolet         ctermfg=57   guifg=#5f00ff  "rgb=95,0,255
hi  x058_Orange4            ctermfg=58   guifg=#5f5f00  "rgb=95,95,0
hi  x059_Grey37             ctermfg=59   guifg=#5f5f5f  "rgb=95,95,95
hi  x060_MediumPurple4      ctermfg=60   guifg=#5f5f87  "rgb=95,95,135
hi  x061_SlateBlue3         ctermfg=61   guifg=#5f5faf  "rgb=95,95,175
hi  x062_SlateBlue3         ctermfg=62   guifg=#5f5fd7  "rgb=95,95,215
hi  x063_RoyalBlue1         ctermfg=63   guifg=#5f5fff  "rgb=95,95,255
hi  x064_Chartreuse4        ctermfg=64   guifg=#5f8700  "rgb=95,135,0
hi  x065_DarkSeaGreen4      ctermfg=65   guifg=#5f875f  "rgb=95,135,95
hi  x066_PaleTurquoise4     ctermfg=66   guifg=#5f8787  "rgb=95,135,135
hi  x067_SteelBlue          ctermfg=67   guifg=#5f87af  "rgb=95,135,175
hi  x068_SteelBlue3         ctermfg=68   guifg=#5f87d7  "rgb=95,135,215
hi  x069_CornflowerBlue     ctermfg=69   guifg=#5f87ff  "rgb=95,135,255
hi  x070_Chartreuse3        ctermfg=70   guifg=#5faf00  "rgb=95,175,0
hi  x071_DarkSeaGreen4      ctermfg=71   guifg=#5faf5f  "rgb=95,175,95
hi  x072_CadetBlue          ctermfg=72   guifg=#5faf87  "rgb=95,175,135
hi  x073_CadetBlue          ctermfg=73   guifg=#5fafaf  "rgb=95,175,175
hi  x074_SkyBlue3           ctermfg=74   guifg=#5fafd7  "rgb=95,175,215
hi  x075_SteelBlue1         ctermfg=75   guifg=#5fafff  "rgb=95,175,255
hi  x076_Chartreuse3        ctermfg=76   guifg=#5fd700  "rgb=95,215,0
hi  x077_PaleGreen3         ctermfg=77   guifg=#5fd75f  "rgb=95,215,95
hi  x078_SeaGreen3          ctermfg=78   guifg=#5fd787  "rgb=95,215,135
hi  x079_Aquamarine3        ctermfg=79   guifg=#5fd7af  "rgb=95,215,175
hi  x080_MediumTurquoise    ctermfg=80   guifg=#5fd7d7  "rgb=95,215,215
hi  x081_SteelBlue1         ctermfg=81   guifg=#5fd7ff  "rgb=95,215,255
hi  x082_Chartreuse2        ctermfg=82   guifg=#5fff00  "rgb=95,255,0
hi  x083_SeaGreen2          ctermfg=83   guifg=#5fff5f  "rgb=95,255,95
hi  x084_SeaGreen1          ctermfg=84   guifg=#5fff87  "rgb=95,255,135
hi  x085_SeaGreen1          ctermfg=85   guifg=#5fffaf  "rgb=95,255,175
hi  x086_Aquamarine1        ctermfg=86   guifg=#5fffd7  "rgb=95,255,215
hi  x087_DarkSlateGray2     ctermfg=87   guifg=#5fffff  "rgb=95,255,255
hi  x088_DarkRed            ctermfg=88   guifg=#870000  "rgb=135,0,0
hi  x089_DeepPink4          ctermfg=89   guifg=#87005f  "rgb=135,0,95
hi  x090_DarkMagenta        ctermfg=90   guifg=#870087  "rgb=135,0,135
hi  x091_DarkMagenta        ctermfg=91   guifg=#8700af  "rgb=135,0,175
hi  x092_DarkViolet         ctermfg=92   guifg=#8700d7  "rgb=135,0,215
hi  x093_Purple             ctermfg=93   guifg=#8700ff  "rgb=135,0,255
hi  x094_Orange4            ctermfg=94   guifg=#875f00  "rgb=135,95,0
hi  x095_LightPink4         ctermfg=95   guifg=#875f5f  "rgb=135,95,95
hi  x096_Plum4              ctermfg=96   guifg=#875f87  "rgb=135,95,135
hi  x097_MediumPurple3      ctermfg=97   guifg=#875faf  "rgb=135,95,175
hi  x098_MediumPurple3      ctermfg=98   guifg=#875fd7  "rgb=135,95,215
hi  x099_SlateBlue1         ctermfg=99   guifg=#875fff  "rgb=135,95,255
hi  x100_Yellow4            ctermfg=100  guifg=#878700  "rgb=135,135,0
hi  x101_Wheat4             ctermfg=101  guifg=#87875f  "rgb=135,135,95
hi  x102_Grey53             ctermfg=102  guifg=#878787  "rgb=135,135,135
hi  x103_LightSlateGrey     ctermfg=103  guifg=#8787af  "rgb=135,135,175
hi  x104_MediumPurple       ctermfg=104  guifg=#8787d7  "rgb=135,135,215
hi  x105_LightSlateBlue     ctermfg=105  guifg=#8787ff  "rgb=135,135,255
hi  x106_Yellow4            ctermfg=106  guifg=#87af00  "rgb=135,175,0
hi  x107_DarkOliveGreen3    ctermfg=107  guifg=#87af5f  "rgb=135,175,95
hi  x108_DarkSeaGreen       ctermfg=108  guifg=#87af87  "rgb=135,175,135
hi  x109_LightSkyBlue3      ctermfg=109  guifg=#87afaf  "rgb=135,175,175
hi  x110_LightSkyBlue3      ctermfg=110  guifg=#87afd7  "rgb=135,175,215
hi  x111_SkyBlue2           ctermfg=111  guifg=#87afff  "rgb=135,175,255
hi  x112_Chartreuse2        ctermfg=112  guifg=#87d700  "rgb=135,215,0
hi  x113_DarkOliveGreen3    ctermfg=113  guifg=#87d75f  "rgb=135,215,95
hi  x114_PaleGreen3         ctermfg=114  guifg=#87d787  "rgb=135,215,135
hi  x115_DarkSeaGreen3      ctermfg=115  guifg=#87d7af  "rgb=135,215,175
hi  x116_DarkSlateGray3     ctermfg=116  guifg=#87d7d7  "rgb=135,215,215
hi  x117_SkyBlue1           ctermfg=117  guifg=#87d7ff  "rgb=135,215,255
hi  x118_Chartreuse1        ctermfg=118  guifg=#87ff00  "rgb=135,255,0
hi  x119_LightGreen         ctermfg=119  guifg=#87ff5f  "rgb=135,255,95
hi  x120_LightGreen         ctermfg=120  guifg=#87ff87  "rgb=135,255,135
hi  x121_PaleGreen1         ctermfg=121  guifg=#87ffaf  "rgb=135,255,175
hi  x122_Aquamarine1        ctermfg=122  guifg=#87ffd7  "rgb=135,255,215
hi  x123_DarkSlateGray1     ctermfg=123  guifg=#87ffff  "rgb=135,255,255
hi  x124_Red3               ctermfg=124  guifg=#af0000  "rgb=175,0,0
hi  x125_DeepPink4          ctermfg=125  guifg=#af005f  "rgb=175,0,95
hi  x126_MediumVioletRed    ctermfg=126  guifg=#af0087  "rgb=175,0,135
hi  x127_Magenta3           ctermfg=127  guifg=#af00af  "rgb=175,0,175
hi  x128_DarkViolet         ctermfg=128  guifg=#af00d7  "rgb=175,0,215
hi  x129_Purple             ctermfg=129  guifg=#af00ff  "rgb=175,0,255
hi  x130_DarkOrange3        ctermfg=130  guifg=#af5f00  "rgb=175,95,0
hi  x131_IndianRed          ctermfg=131  guifg=#af5f5f  "rgb=175,95,95
hi  x132_HotPink3           ctermfg=132  guifg=#af5f87  "rgb=175,95,135
hi  x133_MediumOrchid3      ctermfg=133  guifg=#af5faf  "rgb=175,95,175
hi  x134_MediumOrchid       ctermfg=134  guifg=#af5fd7  "rgb=175,95,215
hi  x135_MediumPurple2      ctermfg=135  guifg=#af5fff  "rgb=175,95,255
hi  x136_DarkGoldenrod      ctermfg=136  guifg=#af8700  "rgb=175,135,0
hi  x137_LightSalmon3       ctermfg=137  guifg=#af875f  "rgb=175,135,95
hi  x138_RosyBrown          ctermfg=138  guifg=#af8787  "rgb=175,135,135
hi  x139_Grey63             ctermfg=139  guifg=#af87af  "rgb=175,135,175
hi  x140_MediumPurple2      ctermfg=140  guifg=#af87d7  "rgb=175,135,215
hi  x141_MediumPurple1      ctermfg=141  guifg=#af87ff  "rgb=175,135,255
hi  x142_Gold3              ctermfg=142  guifg=#afaf00  "rgb=175,175,0
hi  x143_DarkKhaki          ctermfg=143  guifg=#afaf5f  "rgb=175,175,95
hi  x144_NavajoWhite3       ctermfg=144  guifg=#afaf87  "rgb=175,175,135
hi  x145_Grey69             ctermfg=145  guifg=#afafaf  "rgb=175,175,175
hi  x146_LightSteelBlue3    ctermfg=146  guifg=#afafd7  "rgb=175,175,215
hi  x147_LightSteelBlue     ctermfg=147  guifg=#afafff  "rgb=175,175,255
hi  x148_Yellow3            ctermfg=148  guifg=#afd700  "rgb=175,215,0
hi  x149_DarkOliveGreen3    ctermfg=149  guifg=#afd75f  "rgb=175,215,95
hi  x150_DarkSeaGreen3      ctermfg=150  guifg=#afd787  "rgb=175,215,135
hi  x151_DarkSeaGreen2      ctermfg=151  guifg=#afd7af  "rgb=175,215,175
hi  x152_LightCyan3         ctermfg=152  guifg=#afd7d7  "rgb=175,215,215
hi  x153_LightSkyBlue1      ctermfg=153  guifg=#afd7ff  "rgb=175,215,255
hi  x154_GreenYellow        ctermfg=154  guifg=#afff00  "rgb=175,255,0
hi  x155_DarkOliveGreen2    ctermfg=155  guifg=#afff5f  "rgb=175,255,95
hi  x156_PaleGreen1         ctermfg=156  guifg=#afff87  "rgb=175,255,135
hi  x157_DarkSeaGreen2      ctermfg=157  guifg=#afffaf  "rgb=175,255,175
hi  x158_DarkSeaGreen1      ctermfg=158  guifg=#afffd7  "rgb=175,255,215
hi  x159_PaleTurquoise1     ctermfg=159  guifg=#afffff  "rgb=175,255,255
hi  x160_Red3               ctermfg=160  guifg=#d70000  "rgb=215,0,0
hi  x161_DeepPink3          ctermfg=161  guifg=#d7005f  "rgb=215,0,95
hi  x162_DeepPink3          ctermfg=162  guifg=#d70087  "rgb=215,0,135
hi  x163_Magenta3           ctermfg=163  guifg=#d700af  "rgb=215,0,175
hi  x164_Magenta3           ctermfg=164  guifg=#d700d7  "rgb=215,0,215
hi  x165_Magenta2           ctermfg=165  guifg=#d700ff  "rgb=215,0,255
hi  x166_DarkOrange3        ctermfg=166  guifg=#d75f00  "rgb=215,95,0
hi  x167_IndianRed          ctermfg=167  guifg=#d75f5f  "rgb=215,95,95
hi  x168_HotPink3           ctermfg=168  guifg=#d75f87  "rgb=215,95,135
hi  x169_HotPink2           ctermfg=169  guifg=#d75faf  "rgb=215,95,175
hi  x170_Orchid             ctermfg=170  guifg=#d75fd7  "rgb=215,95,215
hi  x171_MediumOrchid1      ctermfg=171  guifg=#d75fff  "rgb=215,95,255
hi  x172_Orange3            ctermfg=172  guifg=#d78700  "rgb=215,135,0
hi  x173_LightSalmon3       ctermfg=173  guifg=#d7875f  "rgb=215,135,95
hi  x174_LightPink3         ctermfg=174  guifg=#d78787  "rgb=215,135,135
hi  x175_Pink3              ctermfg=175  guifg=#d787af  "rgb=215,135,175
hi  x176_Plum3              ctermfg=176  guifg=#d787d7  "rgb=215,135,215
hi  x177_Violet             ctermfg=177  guifg=#d787ff  "rgb=215,135,255
hi  x178_Gold3              ctermfg=178  guifg=#d7af00  "rgb=215,175,0
hi  x179_LightGoldenrod3    ctermfg=179  guifg=#d7af5f  "rgb=215,175,95
hi  x180_Tan                ctermfg=180  guifg=#d7af87  "rgb=215,175,135
hi  x181_MistyRose3         ctermfg=181  guifg=#d7afaf  "rgb=215,175,175
hi  x182_Thistle3           ctermfg=182  guifg=#d7afd7  "rgb=215,175,215
hi  x183_Plum2              ctermfg=183  guifg=#d7afff  "rgb=215,175,255
hi  x184_Yellow3            ctermfg=184  guifg=#d7d700  "rgb=215,215,0
hi  x185_Khaki3             ctermfg=185  guifg=#d7d75f  "rgb=215,215,95
hi  x186_LightGoldenrod2    ctermfg=186  guifg=#d7d787  "rgb=215,215,135
hi  x187_LightYellow3       ctermfg=187  guifg=#d7d7af  "rgb=215,215,175
hi  x188_Grey84             ctermfg=188  guifg=#d7d7d7  "rgb=215,215,215
hi  x189_LightSteelBlue1    ctermfg=189  guifg=#d7d7ff  "rgb=215,215,255
hi  x190_Yellow2            ctermfg=190  guifg=#d7ff00  "rgb=215,255,0
hi  x191_DarkOliveGreen1    ctermfg=191  guifg=#d7ff5f  "rgb=215,255,95
hi  x192_DarkOliveGreen1    ctermfg=192  guifg=#d7ff87  "rgb=215,255,135
hi  x193_DarkSeaGreen1      ctermfg=193  guifg=#d7ffaf  "rgb=215,255,175
hi  x194_Honeydew2          ctermfg=194  guifg=#d7ffd7  "rgb=215,255,215
hi  x195_LightCyan1         ctermfg=195  guifg=#d7ffff  "rgb=215,255,255
hi  x196_Red1               ctermfg=196  guifg=#ff0000  "rgb=255,0,0
hi  x197_DeepPink2          ctermfg=197  guifg=#ff005f  "rgb=255,0,95
hi  x198_DeepPink1          ctermfg=198  guifg=#ff0087  "rgb=255,0,135
hi  x199_DeepPink1          ctermfg=199  guifg=#ff00af  "rgb=255,0,175
hi  x200_Magenta2           ctermfg=200  guifg=#ff00d7  "rgb=255,0,215
hi  x201_Magenta1           ctermfg=201  guifg=#ff00ff  "rgb=255,0,255
hi  x202_OrangeRed1         ctermfg=202  guifg=#ff5f00  "rgb=255,95,0
hi  x203_IndianRed1         ctermfg=203  guifg=#ff5f5f  "rgb=255,95,95
hi  x204_IndianRed1         ctermfg=204  guifg=#ff5f87  "rgb=255,95,135
hi  x205_HotPink            ctermfg=205  guifg=#ff5faf  "rgb=255,95,175
hi  x206_HotPink            ctermfg=206  guifg=#ff5fd7  "rgb=255,95,215
hi  x207_MediumOrchid1      ctermfg=207  guifg=#ff5fff  "rgb=255,95,255
hi  x208_DarkOrange         ctermfg=208  guifg=#ff8700  "rgb=255,135,0
hi  x209_Salmon1            ctermfg=209  guifg=#ff875f  "rgb=255,135,95
hi  x210_LightCoral         ctermfg=210  guifg=#ff8787  "rgb=255,135,135
hi  x211_PaleVioletRed1     ctermfg=211  guifg=#ff87af  "rgb=255,135,175
hi  x212_Orchid2            ctermfg=212  guifg=#ff87d7  "rgb=255,135,215
hi  x213_Orchid1            ctermfg=213  guifg=#ff87ff  "rgb=255,135,255
hi  x214_Orange1            ctermfg=214  guifg=#ffaf00  "rgb=255,175,0
hi  x215_SandyBrown         ctermfg=215  guifg=#ffaf5f  "rgb=255,175,95
hi  x216_LightSalmon1       ctermfg=216  guifg=#ffaf87  "rgb=255,175,135
hi  x217_LightPink1         ctermfg=217  guifg=#ffafaf  "rgb=255,175,175
hi  x218_Pink1              ctermfg=218  guifg=#ffafd7  "rgb=255,175,215
hi  x219_Plum1              ctermfg=219  guifg=#ffafff  "rgb=255,175,255
hi  x220_Gold1              ctermfg=220  guifg=#ffd700  "rgb=255,215,0
hi  x221_LightGoldenrod2    ctermfg=221  guifg=#ffd75f  "rgb=255,215,95
hi  x222_LightGoldenrod2    ctermfg=222  guifg=#ffd787  "rgb=255,215,135
hi  x223_NavajoWhite1       ctermfg=223  guifg=#ffd7af  "rgb=255,215,175
hi  x224_MistyRose1         ctermfg=224  guifg=#ffd7d7  "rgb=255,215,215
hi  x225_Thistle1           ctermfg=225  guifg=#ffd7ff  "rgb=255,215,255
hi  x226_Yellow1            ctermfg=226  guifg=#ffff00  "rgb=255,255,0
hi  x227_LightGoldenrod1    ctermfg=227  guifg=#ffff5f  "rgb=255,255,95
hi  x228_Khaki1             ctermfg=228  guifg=#ffff87  "rgb=255,255,135
hi  x229_Wheat1             ctermfg=229  guifg=#ffffaf  "rgb=255,255,175
hi  x230_Cornsilk1          ctermfg=230  guifg=#ffffd7  "rgb=255,255,215
hi  x231_Grey100            ctermfg=231  guifg=#ffffff  "rgb=255,255,255
hi  x232_Grey3              ctermfg=232  guifg=#080808  "rgb=8,8,8
hi  x233_Grey7              ctermfg=233  guifg=#121212  "rgb=18,18,18
hi  x234_Grey11             ctermfg=234  guifg=#1c1c1c  "rgb=28,28,28
hi  x235_Grey15             ctermfg=235  guifg=#262626  "rgb=38,38,38
hi  x236_Grey19             ctermfg=236  guifg=#303030  "rgb=48,48,48
hi  x237_Grey23             ctermfg=237  guifg=#3a3a3a  "rgb=58,58,58
hi  x238_Grey27             ctermfg=238  guifg=#444444  "rgb=68,68,68
hi  x239_Grey30             ctermfg=239  guifg=#4e4e4e  "rgb=78,78,78
hi  x240_Grey35             ctermfg=240  guifg=#585858  "rgb=88,88,88
hi  x241_Grey39             ctermfg=241  guifg=#626262  "rgb=98,98,98
hi  x242_Grey42             ctermfg=242  guifg=#6c6c6c  "rgb=108,108,108
hi  x243_Grey46             ctermfg=243  guifg=#767676  "rgb=118,118,118
hi  x244_Grey50             ctermfg=244  guifg=#808080  "rgb=128,128,128
hi  x245_Grey54             ctermfg=245  guifg=#8a8a8a  "rgb=138,138,138
hi  x246_Grey58             ctermfg=246  guifg=#949494  "rgb=148,148,148
hi  x247_Grey62             ctermfg=247  guifg=#9e9e9e  "rgb=158,158,158
hi  x248_Grey66             ctermfg=248  guifg=#a8a8a8  "rgb=168,168,168
hi  x249_Grey70             ctermfg=249  guifg=#b2b2b2  "rgb=178,178,178
hi  x250_Grey74             ctermfg=250  guifg=#bcbcbc  "rgb=188,188,188
hi  x251_Grey78             ctermfg=251  guifg=#c6c6c6  "rgb=198,198,198
hi  x252_Grey82             ctermfg=252  guifg=#d0d0d0  "rgb=208,208,208
hi  x253_Grey85             ctermfg=253  guifg=#dadada  "rgb=218,218,218
hi  x254_Grey89             ctermfg=254  guifg=#e4e4e4  "rgb=228,228,228
hi  x255_Grey93             ctermfg=255  guifg=#eeeeee  "rgb=238,238,238
tip_vimcolors_EOF
}

tip_vim_keymap () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << tip_vim_map_EOF


${E_WHITE_FG}Mapping keys in Vim - Tutorial${E_RESET}

Introduction Key mapping refers to creating a shortcut for repeating a sequence of keys or commands. You can map keys to
execute frequently used key sequences or to invoke an Ex command or to invoke a Vim function or to invoke external
commands. Using key maps you can define your own Vim commands.

Vim supports several editing modes - normal, insert, replace, visual, select, command-line and operator-pending. You can
map a key to work in all or some of these modes.

         ${E_WHITE_FG}Command Mode${E_RESET}:Vim starts in Command Mode (navigate, delete, yank, paste, etc. in document)
          ${E_WHITE_FG}Insert Mode${E_RESET}:Enter (i,o,I,O, etc.) you're in INSERT mode. Esc returns to Command mode
          ${E_WHITE_FG}Visual Mode${E_RESET}:Enter ('v', V, Ctrl-v) enters visual, v-line, or v-block mode. Text is highlighted and treated as a unit
          ${E_WHITE_FG}Select Mode${E_RESET}:Enter (gh, gH, g_Ctrl-H) like Visual Mode but with different commands resembling MS Windows. Largely unused.
    ${E_WHITE_FG}Command-line Mode${E_RESET}:set -o vi, the vim CLI to manipulate the unix command line
${E_WHITE_FG}Operator-Pending Mode${E_RESET}:key mapping specific to map a key to a text object. :h text-object for defined objects


The general syntax of a map command is:

${E_WHITE_FG}{cmd} {attr} {lhs} {rhs}${E_RESET}

where 
     {cmd}  is one of ':map' , ':map!' , ':cmap' , ':imap' , ':lmap' , ':nmap' , ':omap' , ':smap' , ':vmap' , ':xmap' , etc.

        map - normal, visual and select and operator pending mode
       map! - insert and command-line mode
       cmap - command-line mode
       imap - insert mode
       nmap - normal mode
       omap - operator pending mode
       smap - select mode
       vmap - visual and select mode
       xmap - visual mode

     {attr} is optional and one or more of the following: <buffer>, <silent>,<expr> <script>, <unique> and <special>.  
            More than one attribute can be specified to a map.  

    <buffer>  applicable only to buffers
    <silent>  silently execute
      <expr>  invoke a function; use return val
    <script>  use recursive maps in your map command, only keys mapped in your script or plugin
    <unique>  useful with the maps defined by a Vim plugin, will fail if the specified key is already mapped
   <special>  in insert mode, pressing <F7> will insert the characters <F7>, to prevent use <special>

        {lhs} left hand side, a sequence of keys that you will use in your shortcut  
        {rhs} right hand side, a sequence of keys that the shortcut will execute

${E_CYAN_FG}Examples${E_RESET}:

map <F2> :echo 'Current time is ' . strftime('%c')<CR> 
map! <F3> <C-R>=strftime('%c')<CR> 
nnoremap <silent> <F2> :lchdir %:p:h<CR>:pwd<CR> 

The first step in creating a map is to ${E_BOLD}${E_ITALIC}decide the sequence of keys${E_RESET} the mapping will run. When you
invoke a map, Vim will execute the sequence of keys as though you entered it from the keyboard. You can test the keys
for your mapping by manually entering the key sequence and verifying that it performs the desired operation.  

The second step is to ${E_BOLD}${E_ITALIC}decide the editing mode${E_RESET} (insert mode, visual mode, command-line mode, normal mode, etc.) in which the map
should work. Instead of creating a map that works in all the modes, it is better to define the map that works only in
selected modes.  

The third step is to ${E_BOLD}${E_ITALIC}find an unused key sequence${E_RESET} that can be used to invoke the map. You can invoke a
map using either a single key or a sequence of keys. :help map-which-keys The above steps are explained in more detail
in the following sections.

${E_WHITE_FG}Creating Keymaps${E_RESET}
${E_WHITE_FG}----------------${E_RESET}
To map a sequence of keys to execute another sequence of keys, use the ':map' command.

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command maps the <F2> key to display the current date and time.

:map <F2> :echo 'Current time is ' . strftime('%c')<CR> 

The following command maps the <F3> key to insert the current date and time in the current buffer:

:map! <F3> <C-R>=strftime('%c')<CR> 

The ':map' command creates a key map that works in normal, visual, select and operator pending modes. The ':map!'
command creates a key map that works in insert and command-line mode.

A better alternative than using the 'map' and 'map!' commands is to use mode-specific map commands which are described
in later sections.

${E_WHITE_FG}Storing the key maps${E_RESET}
${E_WHITE_FG}--------------------${E_RESET}
If you want to map a key for only one Vim session temporarily, then you don't need to save the map
command in a file. When you quit that Vim instance, the temporary map definition will be lost.

If you want to restore the key maps across Vim instances, you need to save the map definition command in a file.

One place to store the map commands is the \${HOME}/.vimrc or \${HOME}/_vimrc or \${VIM}/_vimrc file. If you have filetype
specific key maps, then you can store them in the filetype specific plugin files. The key maps defined by Vim plugins
are stored in the plugin or script file itself.

When adding the map commands to a file, there is no need to prefix the commands with the ':' character.

${E_WHITE_FG}Listing Key Maps${E_RESET}
${E_WHITE_FG}----------------${E_RESET}
You can display a list of existing key maps using the following commands without any arguments:

:map :map!  The first command displays the maps that work in normal, visual and select and operator pending mode. The
second command displays the maps that work in insert and command-line mode.

To display the mode specific maps, prefix the ':map' command with the letter representing the mode.

:nmap - Display normal mode maps 
:imap - Display insert mode maps 
:vmap - Display visual and select mode maps 
:smap - Display select mode maps 
:xmap - Display visual mode maps 
:cmap - Display command-line mode maps 
:omap - Display operator pending mode maps 

${E_CYAN_FG}Example${E_RESET}:

:nmap n  <C-W>*      * <C-W><C-S>* n  <C-W>#      * <C-W><C-S># n  <F2>        * :lchdir %:p:h<CR>:pwd<CR> 

In the output of the above commands, the first column indicates the mode in which the map works. You can interpret the
first column character using the following table:

n       Normal mode map. Defined using ':nmap' or ':nnoremap'.  
i       Insert mode map. Defined using ':imap' or ':inoremap'.  
v       Visual and select mode map. Defined using ':vmap' or ':vnoremap'.  
x       Visual mode map. Defined using ':xmap' or ':xnoremap'.  
s       Select mode map. Defined using ':smap' or ':snoremap'.  
c       Command-line mode map. Defined using ':cmap' or ':cnoremap'.  
o       Operator pending mode map. Defined using ':omap' or ':onoremap'.
<Space> Normal, Visual and operator pending mode map. Defined using ':map' or ':noremap'.  
!       Insert and command-line mode map. Defined using 'map!' or 'noremap!'.  

The following characters may be displayed before the {rhs} of the map:

*  The {rhs} of the map is not re-mappable. Defined using the ':noremap' or ':nnoremap' or ':inoremap', etc. commands.
&  Only script local mappings are re-mappable in the {rhs} of the map. The map command has the <script> attribute.  
@  A buffer local map command with the <buffer> attribute.  

To display all the key maps that start with a particular key sequence, enter the key sequence in the above commands. For
example, the following command displays all the normal mode maps that start with 'g'.

:nmap g 

To display all the buffer-local maps for the current buffer, use the following commands:

:map <buffer> :map! <buffer> 

Typically the output of the above commands will span several pages. You can use the following set of commands to
redirect the output to the vim_maps.txt file:

:redir! > vim_maps.txt :map :map!  :redir END

${E_WHITE_FG}Removing A Keymap${E_RESET}
${E_WHITE_FG}-----------------${E_RESET}
To permanently remove a map, you first need to locate the place where it is defined by using the ':verbose map {lhs}'
command (replace {lhs} with the mapped key sequence). If the map is defined in the .vimrc or _vimrc file or in one of
the files in the vimfiles or .vim directory, then you can edit the file to remove the map.

Another approach is to use the ':unmap' and ':unmap!' commands to remove the map. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, to remove the map for the <F8> key, you can use the following commands:

:unmap <F8> :unmap! <F8> 

Note that after a key is unmapped using the ':unmap' command, it can be mapped again later.
Also you cannot unmap a key used by one of the Vim internal commands. Instead you have to map it to <Nop> to disable its
functionality. If you are trying to disable a key map defined by a plugin, make sure the unmap command is executed after
the key map is defined by the plugin. To do this in .vimrc, use autocmd:

autocmd VimEnter * unmap! <F8> 

Filetype plugins can be a little tricky, because they can redefine mappings any time you open a file of a certain type.
You can just use a different autocmd event for this, e.g.:

autocmd FileType python unmap! <F8> Or, you can place the unmap command in the appropriate after directory. :help
after-directory.

You can remove a mode-specific map by using the mode specific unmap command. The mode-specific unmap commands are listed
below:

nunmap - Unmap a normal mode map 
vunmap - Unmap a visual and select mode map 
xunmap - Unmap a visual mode map 
sunmap - Unmap a select mode map 
iunmap - Unmap an insert and replace mode map 
cunmap - Unmap a command-line mode map 
ounmap - Unmap an operator pending mode map 

Note that in the above unmap commands, if a space character is present at the end of the unmapped key sequence, then the
command will fail. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following unmap command will fail (replace <Space> with a space character):

:nnoremap <F2> :ls<CR> :nunmap <F2><Space> 

To map a key in only a selected set of modes, you can use the ':map' and ':map!' commands and then unmap them using the
mode specific unmap commands in a few modes. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, to map a key in normal and visual mode but not in operator-pending mode, you can use the following commands:

:map <F6> ....  :ounmap <F6> 

To clear all the mappings for a particular mode, you can use the ':mapclear' command. The mode-specific map clear
commands are listed below:

mapclear  - Clear all normal, visual, select and operating pending mode maps 
mapclear! - Clear all insert and command-line mode maps 
nmapclear - Clear all normal mode maps vmapclear - Clear all visual and select mode maps
xmapclear - Clear all visual mode maps smapclear - Clear all select mode maps 
imapclear - Clear all insert mode maps
cmapclear - Clear all command-line mode maps 
omapclear - Clear all operating pending mode maps Mode-specific maps 

Vim supports creating keymaps that work only in specific editing modes. You can create keymaps that work only in normal,
insert, visual, select, command and operator pending modes. The following table lists the various map commands and their
corresponding editing mode:

Commands                Mode 
nmap, nnoremap, nunmap  Normal mode 
imap, inoremap, iunmap  Insert and Replace mode 
vmap, vnoremap, vunmap  Visual and Select mode 
xmap, xnoremap, xunmap  Visual mode 
smap, snoremap, sunmap  Select mode 
cmap, cnoremap, cunmap  Command-line mode 
omap, onoremap, ounmap  Operator pending mode 

Note that the language specific mappings defined using the ':lmap' and ':lnoremap' commands are not discussed here. For
more information about this refer to the Vim help.

Normal mode maps To map keys that work only in the normal mode, use the ':nmap' or ':nnoremap' command. The 'n' in
':nmap' and ':nnoremap' denotes normal mode.

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command maps the <F5> key to search for the keyword under the cursor in the current directory
using the 'grep' command:

:nnoremap <F5> :grep <C-R><C-W> *<CR>

${E_CYAN_FG}Examples${E_RESET}:

The following commands map the 'j' key to execute 'gj' and the 'k' key to execute 'gk'. These are useful for moving
between long wrapped lines.

:nnoremap k gk 
:nnoremap j gj 

The following command maps ',b' to display the buffer list and invoke the ':buffer'
command. You can enter the desired buffer number and hit <Enter> to edit the buffer.

:nnoremap ,b :ls<CR>:buffer<Space> 

In the above command, you can enter <Space> at the end of the map command either literally or by pressing the space bar.

To display the currently defined normal mode maps, use the ':nmap' command without any argument:

:nmap 

To remove a keymap from normal mode, use the ':nunmap' command.  

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command removes the map for the <F9> key from normal mode:

:nunmap <F9> 

If you invoke an Ex command from a map, you have to add a <CR> or <Enter> or <Return> at the end of the Ex
command to execute the command. Otherwise the command will not be executed.  

${E_BOLD}${E_ITALIC}For example${E_RESET}:

:nnoremap <F3> :ls 

With the above map, if you use <F3> in normal mode, you will be left in the ':' command-line after
the text 'ls'. To execute the command, you have to use <CR> at the end of the command:

:nnoremap <F3> :ls<CR> 

Now, when you press <F3>, the 'ls' Ex command will be executed.

From a normal mode map, you can get the keyword under the cursor using the expand('<cword>') function or using the
<C-R><C-W> command.  

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following two map commands provide the same functionality:

:nnoremap ,s :exe 'grep ' . expand('<cword>') . ' *'<CR> 
:nnoremap ,s :grep <C-R><C-W> *<CR> 

Insert mode maps To map keys that work only in the insert and replace modes, use the 'imap' or 'inoremap' command.

${E_CYAN_FG}Example${E_RESET}: The following command maps <F2> to insert the directory name of the current buffer:

:inoremap <F2> <C-R>=expand('%:p:h')<CR> 

To display the currently defined insert mode maps, use the 'imap' command without any argument:

:imap 

To remove a keymap from insert mode, use the ':iunmap' command. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command removes the insert mode map for <F2>.

:iunmap <F2> 

As printable keys insert a character in the current buffer in insert mode, you should use non-printable keys to create
insert mode maps. Some examples for non-printable keys include the function keys <F2>, keys prefixed with the Ctrl or
Alt key.

Alternatively, you can map keys that you're just not likely to need to insert, such as two capital letters in a row.
This can be an attractive option for quick insert-mode access to common normal-mode commands.

To execute Vim normal mode commands from an insert mode map, you have to go from insert mode to normal mode. But after
executing the map, you may want to restore the mode back to insert mode. To do this, you can use the <CTRL-O>
insert-mode key which temporarily goes to normal-mode for one normal mode command and then comes back to insert mode.

${E_BOLD}${E_ITALIC}For example${E_RESET}, to call the Vim function MyVimFunc() from insert mode, you can use the following map command:

:inoremap <F5> <C-O>:call MyVimFunc()<CR> 

One caveat with using the <C-O> command is that if the cursor is after the last character in a line in insert mode, then
<C-O> moves the cursor one character to the left after executing the map.  If you don't want this, then you can use the
<C-\><C-O> command, which doesn't move the cursor. But now the cursor may be placed on a character beyond the end of a
line. The above map command is modified to use the <C-\><C-O> key:

:inoremap <F5> <C-\><C-O>:call MyVimFunc()<CR> 

Both the <C-O> and <C-\><C-O> commands create a new undo point, i.e. you can undo the text inserted before and after
typing these commands separately.

Another alternative for going from insert mode to normal mode is to use the <Esc> key. But it is preferable to use the
<C-O> or <C-\><C-O> command for this.

If you press <Esc> in normal mode to make sure you are in normal mode, then you will hear the error beep sound. Instead,
you can use the CTRL-\ CTRL-N command to go to normal mode. If you are already in normal mode, this command will not
result in the error bell. This command can be used from a map to go to normal mode.

After executing the normal mode commands from an insert mode map, if the cursor position was moved by the map and no new
text was inserted by the commands invoked, then you can use the gi command to restart the insert mode from the previous
position where the insert mode was last stopped.

You can insert the result of a Vim expression in insert mode using the <C-R>= command. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command creates an insert mode map command that inserts the current directory:

:inoremap <F2> <C-R>=expand('%:p:h')<CR> 

If you don't want to insert anything then you can return an empty string from the expression. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, you can invoke a function from the insert mode map to perform some operation but return
an empty string from the function.

The <C-R>= command doesn't create a new undo point. You can also call Vim functions using the <C-R>= command:

:inoremap <F2> <C-R>=MyVimFunc()<CR> 

If the return value of MyVimFunc() is to be ignored and not entered after its call, a ternary operator trick may be
used:

:inoremap <F2> <C-R>=MyVimFunc()?'':''<CR> 

This will return an empty string, independent of what MyVimFunc() returns.

When Vim parses a string in a map command, the \<...> sequence of characters is replaced by the corresponding control
character. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, let us say in insert mode you want the down arrow key to execute <C-N> when the insert complete
popup menu is displayed. Otherwise, you want the down arrow key to move the cursor one line down. You can try the
following command (which doesn't work):

:inoremap <Down> <C-R>=pumvisible() ? '\<C-N>' : '\<Down>'<CR> 

When parsing the above command, Vim replaces <C-N> and <Down> with the corresponding control characters. When you press
the down arrow in insert mode, as there are control characters in the expression now, the command will fail.

To fix this, you should escape the '<' character, so that Vim will not replace '\<C-N>' with the control character when
parsing the command. The following command works:

:inoremap <Down> <C-R>=pumvisible() ? '\<lt>C-N>' : '\<lt>Down>'<CR> 

With the above command, Vim will use the control character only when the map is invoked and not when the above command
is parsed.

To insert a template you should use a Vim abbreviation instead of a insert mode map. For more information about
abbreviations refer to the Vim help.

Note that if the 'paste' option is set, then insert mode maps are disabled.

${E_WHITE_FG}Visual Mode Maps${E_RESET}
${E_WHITE_FG}----------------${E_RESET}
To map keys that work only in visual mode, use the ':vmap' or ':vnoremap' commands. These maps are invoked when you
press the mapped keys after visually selecting a range of characters.

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command maps the g/ key sequence to search for the visually selected sequence of characters:

:vnoremap g/ y/<C-R>"<CR> 

Another visual mode map example to add single quotes around a selected block of text:

:vnoremap qq <Esc>'>a'<Esc>'<i'<Esc> 

To display all the currently defined visual mode maps, use the ':vmap' command without any arguments:

:vmap 

To remove a visual mode map, use the ":vunmap" command. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command removes the visual mode map for g/:

:vunmap g/ 

From a visual mode map, you can either perform a text editing operation on the selected characters or add/remove
characters at the beginning and/or end of the selected region or pass the selected text to some other internal/external
command.

The '< Vim mark represents the first line of a visual region and the '> mark represents the last line of the visual
region. The similar '< mark represents the beginning character position of the visual region and the '> mark represents
the ending character position of the visual region. You can use these marks in your map to perform operation at the
beginning and end of the visual region. If the map is invoked from visual mode, then these marks will refer to the
beginning and end of the previous selection and not to the current selected region.

If you want to use the visually selected text in your map, then you can yank the text and then use it in your map. You
can either yank the text to a register or use the unnamed (") register. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command maps the g/ key sequence to search for the visually selected text:

:vnoremap g/ y/<C-R>"<CR> 

Another approach is to use the above described marks and get the text in the region from the buffer using the getline()
function.

To execute an Ex command from a visual mode map, you have to first enter the command-line mode using the ':' character.

After visually selecting a sequence of characters, when you press ':' to execute a Vim Ex command, Vim automatically
inserts the visual block begin ('<') and end ('>') marks. 

If you invoke an Ex command with this range, then the command is executed for every line in this range. This may be
undesirable. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, if you invoke a Vim function, then the function will be executed separately for each line in
the range (unless the function is defined with the '-range' attribute). 

To remove the visual block start and end marks, use the <C-U> command, which removes all the characters between the
start of the line and the current cursor position, at the beginning of your map. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, 

:vnoremap <F2> :<C-U>call MyVimFunc()<CR> 

When you enter a mapped key sequence in character-wise or line-wise or block-wise visual mode, the same visual map is
invoked. You can use the visualmode() function in your map to differentiate between these modes. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following code maps the <F5> keys in visual mode to invoke the MyFunc() function. The MyFunc() function
uses the visualmode() function to distinguish between the visual modes.  

vnoremap <silent> <F5> :<C-U>call MyFunc()<CR> 

function! MyFunc() 
	let m = visualmode() 
	if m ==# 'v' 
		echo 'character-wise visual' 
	elseif m == 'V' 
		echo 'line-wise visual' 
	elseif m == "\<C-V>" 
		echo 'block-wise visual' 
	endif 
endfunction 

Note that we use ==# for the initial comparison instead of ==. This is because ==# will always make a case-sensitive
comparison, whereas == will consider 'v' and 'V' to be the same if the ignorecase option has been set.

When you enter the command mode using ':' in visual mode, the visual mode is stopped. If you want to re-enter the visual
mode from a function invoked from a map, you can use the gv command:

vnoremap <silent> <F5> :<C-U>call MyFunc()<CR> 

function! MyFunc() 
	normal! gv 
endfunction 

The maps created with the ":vmap" and ":vnoremap" commands work in both Visual mode and Select mode. When a map is
invoked in select mode, Vim temporarily switches to visual mode before executing the map and at the end of the map,
switches back to select mode. So the map behaves the same in visual and select mode.

To create a map that works only in Visual mode and not in Select mode use the ":xmap" and ":xnoremap" commands. All the
other descriptions for the ":vmap" and ":vnoremap" commands also apply to the ":xmap" and ":xnoremap" commands.

To create a map that works only in Select mode and not in Visual mode use the ":smap" and ":snoremap" commands.

${E_WHITE_FG}Command-line Mode Map${E_RESET}
${E_WHITE_FG}----------------------${E_RESET}
To map keys to work only in the command-line mode, use the "cmap" or ":cnoremap" commands.

The command-line mode map works in the following command prompts:

:    Ex command prompt /    Forward search prompt ?    Backward search prompt
>    Debug prompt
@    input() prompt
-    :insert and :append prompts.  You can distinguish between the above prompts using the getcmdtype() function in your map. 

${E_CYAN_FG}Example${E_RESET}:

:cnoremap <F8> <C-R>=MyFunc()<CR> 

function! MyFunc() 
	let cmdtype = getcmdtype() 
	if cmdtype == ':' 
		" Perform Ex command map action 
	elseif cmdtype == '/' || cmdtype == '?' 
		" Perform search prompt map action 
	elseif cmdtype == '@' 
		" Perform input() prompt map action 
	else 
		" Perform other command-line prompt action 
	endif 
endfunction 

To invoke functions from a command-line map, you have to use the '<C-R>=' command or the 'CTRL-\ e' command. An example
map that shows this is below:

:cnoremap <C-F6> <C-R>=Somefunc()<CR> :cnoremap <C-F6> <C-\>eSomefunc()<CR> 

The <C-R>= command inserts the value returned by the invoked function at the current location in the command-line. The
<C-\>e command replaces the entire command-line with the value returned by the invoked function.

The <C-R>= and <C-\>e commands cannot be used in the prompt for getting an expression (represented by =). 

${E_BOLD}${E_ITALIC}For example${E_RESET}, to insert the value of the Vim variable 'abc' in the command line, you can use <C-R>=abc<CR> command. In
the prompt where you enter the variable name, you cannot again use <C-R>= and <C-\>e. To do this use the <expr>
attribute to the map command as explained below.

Another way to invoke a function from a command-line mode map is to use the <expr> attribute as shown below:

:cnoremap <expr> <C-F6> Cmdfunc() 

Using the above map, the value returned by Cmdfunc() is inserted at the current location in the command-line.

In the function invoked by the <C-R>= and <C-\>e commands and <expr> attribute, you can use the 
	getcmdpos() function to get the current position of the cursor in the command. You can use the 
	setcmdpos() function to change the location of the cursor in the command-line. You can use the 
	getcmdline() function to get the current command-line.

It is preferable to use a non-printable control character for invoking a command-line mode map. Otherwise, the map may
interfere with the printable characters used in the Vim Ex commands.

Note that if the 'paste' option is set, then command-line mode maps are disabled.

${E_WHITE_FG}Operator pending mode maps${E_RESET}
${E_WHITE_FG}--------------------------${E_RESET}
You can create maps that work only when waiting for a motion command from an operator
command. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the yank command 'y' yanks the text that is selected by the motion that follows the command. To
yank the current line and the two following lines of text, you can use the command 'y2j'. After pressing 'y', Vim waits
for you to enter the motion command. The operator pending maps can be used here. The operator pending mode maps can be
used to define your own text objects.

Operator pending commands are defined using the ":omap" and ":onoremap" commands.

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command creates an operator pending map for <F6> to select the current inner block defined by
"{" and "}".

:onoremap <F6> iB 

You can now yank an inner block using the y<F6> command, delete an inner block using the d<F6> command, etc.

To change the starting location of the operator from a operator-pending mode map, you can start visual mode and select
the desired range of characters. One disadvantage in starting visual mode is that the previous visual region will be
lost.  

${E_WHITE_FG}Mapping Mouse Event${E_RESET}
${E_WHITE_FG}--------------------${E_RESET}
You can map mouse events similar to mapping keys to perform some action. The following mouse events can be mapped:

<LeftMouse>     - Left mouse button press 
<RightMouse>    - Right mouse button press 
<MiddleMouse>   - Middle mouse button press 
<LeftRelease>   - Left mouse button release 
<RightRelease>  - Right mouse button release 
<MiddleRelease> - Middle mouse button release 
<LeftDrag>      - Mouse drag while Left mouse button is pressed 
<RightDrag>     - Mouse drag while Right mouse button is pressed 
<MiddleDrag>    - Mouse drag while Middle mouse button is pressed 
<2-LeftMouse>   - Left mouse button double-click 
<2-RightMouse>  - Right mouse button double-click 
<3-LeftMouse>   - Left mouse button triple-click 
<3-RightMouse>  - Right mouse button triple-click 
<4-LeftMouse>   - Left mouse button quadruple-click
<4-RightMouse>  - Right mouse button quadruple-click 
<X1Mouse>       - X1 button press 
<X2Mouse>       - X2 button press
<X1Release>     - X1 button release 
<X2Release>     - X2 button release 
<X1Drag>        - Mouse drag while X1 button is pressed 
<X2Drag>        - Mouse drag while X2 button is pressed Few examples for mapping the above mouse events is given below.

To jump to the tag under the cursor when the tag is double clicked, you can use the following map:

:nnoremap <2-LeftMouse> :exe "tag ". expand("<cword>")<CR> 

The above map uses the expand() function to get the keyword under the cursor and then invokes the "tag" command with the
current keyword. The "execute" command is used to concatenate the tag command and the output of the expand() function.

To map the X1 and X2 buttons to go forward and backward in the jump list, you can use the following map:

:nnoremap <X1Mouse> <C-O> :nnoremap <X2Mouse> <C-I> 

The above maps use the <C-O> and <C-I> normal mode commands to walk the jump list.

When you paste text using the middle mouse button, the text is pasted at the current cursor position. To paste at the
position of the middle mouse button click, you can use the following map:

:nnoremap <MiddleMouse> <LeftMouse><MiddleMouse> 

The above map first moves the cursor to the point where the click is made and then invokes the <MiddleMouse> functionality.

If you create a map for one of these mouse events, it overrides the internal default handling of that event by Vim. To
pass the event to Vim, so that the default handling is also done, you can use "nnoremap" and specify the event in the
{rhs} of the map. 

${E_BOLD}${E_ITALIC}For example${E_RESET},

:nnoremap <LeftRelease> <LeftRelease>:call MyFunc()<CR> 

With the above map, when the Left mouse button is pressed, the cursor is moved to that location and then the function
MyFunc() is called.

You can disable a mouse event, by mapping it to <Nop> If you have a scrollwheel and often accidentally paste text when
scrolling text, you can use the following mappings to disable the pasting with the middle mouse button:

:nnoremap <MiddleMouse> <Nop> :inoremap <MiddleMouse> <Nop>

${E_WHITE_FG}Nested (recursive) Maps${E_RESET}
${E_WHITE_FG}-----------------------${E_RESET}
When executing a mapped key sequence, if the {lhs} is not a prefix of the {rhs}, then Vim scans
and recursively replaces any mapped keys in the {rhs} of the map. This allows you to define nested and recursive
mappings. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, consider the following set of commands:

:map <F2>  :echo 'Current time = ' . strftime('%c')<CR> 
:map <F3> <F2> 

When you press <F3>, Vim executes the mapped key sequence for <F2> and displays the current time.

Note that Vim recursively checks for mappings on the {rhs} of a map when executing the map and not when defining the
map. In the above example, if you redefine the map for <F2> later, then <F3> will execute the new map for <F2>.

If you include the {lhs} of a map in the {rhs}, then you will create an infinitely recursive key map. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following insert mode map command creates an infinitely recursive map:

:imap ab xyzab 

With the above map, when you enter "ab" in insert mode, it is replaced with "xyz" followed by "ab" which
is replaced by "xyz" and so on. You can interrupt the recursive map by pressing CTRL-C.

Vim will recursively replace the mapped key sequence in the {rhs} of a map till it encounters an error. This can be used
to create a recursive map that stops on error. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command creates a map for \s to replace "emacs" with "vi" in all the files
in the argument list:

:nmap \s  :%s/emacs/vi/g \| update \| n<CR>\s 

The "\s" at the end of the {rhs} in the map creates a recursive map. The recursive map will stop when it reaches the
last file in the argument list as the "n" command will fail.

If the {rhs} of a map begins with the {lhs}, then it is not recursively replaced. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command will not create a recursive map for x:

:nmap x xyz 

If you want to invoke other maps from your map, then define your maps using the ":map", ":map!", ":nmap",
":imap", ":vmap", ":cmap", ":xmap", ":smap" and ":omap" commands.

To prevent Vim from recursively replacing the mapped keys in the {rhs} of map, you can set the 'noremap' option. But
instead of setting this option, it is preferable to use the 'noremap' command.

You can use the 'noremap' command to execute the {rhs} of a map literally without any map substitutions. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, consider the following command which visually selects the current paragraph:

:map <F2> vip 

If a map is defined for any character sequence in the {rhs}, then the above command will break. For
example, consider the following map command which maps 'vi' to invoke 'gg':

:map vi gg 

When you invoke <F2>, "vi" in the {rhs} will be replaced with "gg" resulting in an unexpected result. To prevent this
from happening, you can use the following map command:

:noremap <F2> vip 

Vim has the "noremap" version of the map command for all the mode specific map commands. 
You can use "nnoremap", "inoremap", "cnoremap", "vnoremap", "snoremap", "xnoremap" and "onoremap". In most of the map
commands, it is better to use the "noremap" version of the command to prevent unexpected behavior.

When a key sequence which is mapped using "noremap" is entered at the end of an abbreviation, the abbreviation will not
be expanded. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command creates an insert mode abbreviation for "vi":

:iabbr vi Vi Improved

In insert mode, when you enter "vi" followed by a space or Enter or some other control character, it is
replaced with "Vi Improved". If you have the following map command for the <Enter> key:

:inoremap <Enter> <Enter><C-G>u 

Now, if you press <Enter> after entering "vi", it will not be expanded to "Vi Improved".  You can expand the
abbreviation by pressing <Space> or by entering Ctrl-].

${E_MAGENTA_FG}Further information: ${E_RESET}

${E_WHITE_FG}Unused Keys${E_RESET}
${E_WHITE_FG}-----------${E_RESET}
In your private maps you should use key sequences that are not used by Vim and by other Vim plugins. 

Finding unused keys :help map-which-keys

Many of the key sequences that you can enter from the keyboard are used by Vim to implement the various internal
commands. If you use a key sequence in your map that is already used by Vim, then you will not be able to use the
functionality provided by Vim for that key sequence. To get a list of the key sequences used by Vim, read the following
help topic:

:help index.txt (File: /usr/share/vim/vim90/doc/index.txt)

If you don't use some Vim functionality invoked by a particular key sequence or you have an alternate key sequence to
use that functionality then you can use that key sequence in your maps.

Some of the key sequences may be used by the existing Vim scripts and plugins. 

To display the list of keys that are currently mapped, use the following commands:

	:map :map!  

To determine the script or plugin that defines a map for a key sequence, use the following command.

	:verbose map <key> 

In the above command, replace <key> with the desired key sequence. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, to list all the locations where maps beginning with "," are defined, use the following command:

	:verbose map , 

Try to use an unused key sequence in your maps. Typically, the <F2>, <F3>, ... etc function keys are unused. The
function keys in combination with Control, Alt and Shift can also be used. But some of the key combinations may not work
in all the terminal emulators. Most of the key combinations should work in GUI Vim.

You can also prefix the desired key sequence with a backslash (\) or comma (,) or underscore (_), etc. and use that in
your maps.

Note that you cannot map the Shift or Alt or Ctrl keys alone as they are key modifiers. You have to combine these key
modifiers with other keys to create a map.

You should not use a frequently used Vim key sequence at the start of your maps. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, you should not start your normal mode map key sequence with "j" or "k" or "l" or "h".
These keys are used for moving the cursor in normal mode. If you use any of these keys at the beginning of your maps,
then you will observe a delay when you enter a single "j" or "k" or "l" or "h".

${E_WHITE_FG}Key notation${E_RESET}
${E_WHITE_FG}------------${E_RESET}
When defining a map command, you can enter printable characters like 'a', 'V', etc. literally. You can
enter non-printable control characters (like Ctrl-G, Alt-U, Ctrl-Shift-F2, F2, etc.) in several different ways.

You can enter a non-printable control character in a map command by preceding it with CTRL-V. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, to map the Ctrl-K key to display the buffer list, you can use the following map command:

:map <press Ctrl-V><press Ctrl-K> :ls<press Ctrl-V><press Enter> 

The Ctrl-V key sequence is used to escape the following control character.

The following table shows the mapping between some of the keys on the keyboard and the equivalent Ctrl-key combination:

Ctrl-I      Tab 
Ctrl-[      Esc 
Ctrl-M      Enter 
Ctrl-H      Backspace 

If you use one of the Ctrl-key combination in the above table in a map, the map also applies to the corresponding key.

Both the keys produce the same key scan code.

${E_BOLD}${E_ITALIC}For example${E_RESET}, if you create a map for CTRL-I, then you can invoke the map by pressing Ctrl-I or the Tab key.

On Unix like systems, the Ctrl-S and Ctrl-Q keys may be used for terminal flow control. If you map these keys in Vim,
then when you invoke them, Vim will not receive these key sequences. To use these keys in Vim, you have to change the
flow control characters used by the terminal using the 'stty start' and stty stop' commands to some other character or
disable the terminal flow control using the following command:

\$ stty -ixon Similarly, Ctrl-Z is used to suspend Vim on Unix-like systems. To use Ctrl-Z in your maps, you can change
the suspend character using the 'stty susp' command.

On MS-Windows, if the mswin.vim file is used, then CTRL-V is mapped to paste text from the clipboard. In this case, you
can use CTRL-Q or CTRL+SHIFT+V instead of CTRL-V to escape control characters.

To create a map for the Ctrl-v key, you have to enter it four times:

:imap ^V^V^V^V EscapeCharacter 

In the above command to enter a single ^V, you have to press Ctrl and v. When Vim parses the above command, it replaces
the ^V^V^V^V sequence with ^V^V (two Ctrl-V characters). When the map is invoked, Vim replaces the two Ctrl-V characters
with a single Ctrl-V character.

The Ctrl-J character represents the linefeed and is internally used by Vim to represent the Nul character. You cannot
create a map for Ctrl-J by using the following command:

"The following command doesn't work 

:imap <press Ctrl-V><press Ctrl-j> Newlinecharacter 

You can also enter a control character by pressing Ctrl-V followed by the decimal or octal or hexadecimal value of the
character. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, to enter CTRL-P, you can press Ctrl-V followed by 016 (decimal) or x10 (hexadecimal) or o020.

Instead of entering the control characters directly in a map command as described above, it is preferable to use
symbolic key notation for the control characters for readability. Vim supports representing control characters using
symbolic notation like <F1>, <C-W>, <C-S-F1>, etc.

To determine the special key code representation that can be used in a map command, in insert mode, press the <CTRL-K>
key followed by the key.

 Ctrl key modifier: <C-key> (Ctrl-R is <C-R>). 
Shift key modifier: <S-key> (Shift-F2 is <S-F2>) 
  Alt key modifier: <A-key> or <M-key>

You can combine one or more key modifiers: Ctrl+Shift+F3 you can use <C-S-F3>. 

Super is represented <D-key> in MacVim and <T-key> in gtk2 gvim. In gvim it doesn't work with all the keys.

The Vim key notation for other special characters is listed below:

<BS>           Backspace 
<Tab>          Tab 
<CR>           Enter 
<Enter>        Enter 
<Return>       Enter 
<Esc>          Escape 
<Space>        Space 
<Up>           Up arrow 
<Down>         Down arrow 
<Left>         Left arrow 
<Right>        Right arrow 
<F1> - <F12>   Function keys 1 to 12 #1, #2..#9,#0  Function keys F1 to F9, F10 
<Insert>       Insert 
<Del>          Delete 
<Home>         Home 
<End>          End 
<PageUp>       Page-Up 
<PageDown>     Page-Down 
<bar>          the '|' character, which otherwise needs to be escaped '\|' 

Note that Vim understands only those keys that are supplied by the operating system to Vim. If a particular key sequence
is handled by a window manager or is intercepted by the operating system, then Vim will not see that key sequence. Then,
you can not use that key sequence in Vim.

To determine whether Vim receives a key sequence, in insert mode press <CTRL-V> followed by the key sequence. If you see
some characters in the buffer, then Vim is receiving the entered key sequence.

If the escape sequence received by Vim is not a standard sequence, you can set the sequence to the desired key. For
example, let us say <PageUp> is generating a non-standard key sequence in your system. Then you can use the following
command:

:set <PageUp>=<type Ctrl-V><type PageUp> 

In the above command, the first <PageUp> is inserted literally (8 characters).  The argument after = is entered by
pressing Ctrl-V followed by the <PageUp> key.

You can also specify a character by its numeric value in a map. A character is represented by <Char-xxx>, where xxx is
the value of the character in decimal or octal or hexadecimal.

${E_BOLD}${E_ITALIC}For example${E_RESET}, the key CTRL-P has a value of 16 (decimal). This is represented by <Char-16> (in decimal), <Char-020> (in
octal) and <Char-0x10> (in hexadecimal). You can create a map for <CTRL-P> using any one of the following commands:

:nnoremap <C-P> { :nnoremap <Char-16> { :nnoremap <Char-020> { :nnoremap <Char-0x10> { 

You can also use the termcap entry for a key in the map. The termcap entries are represented using the format <t_xx>
where 'xx' is replaced with the key. You can get a list of termcap keys using the ":set termcap" command. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, to map F8 you can use <t_F8>:

:nnoremap <t_F8> :make<CR> 

But it is preferable to use key notations instead of terminal codes for special keys.


${E_WHITE_FG}Maps With The Same Prefix${E_RESET}
${E_WHITE_FG}-------------------------${E_RESET}
If more than one mapped key sequence starts with the same subsequence of keys then when invoking the map you will notice
a delay. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the ";" (semi-colon) command in normal mode repeats the previous f or t or F or T command. Assume
that your map commands also start with ";". When you press ";", Vim needs to wait for you to enter sufficient number of
characters to distinguish between the built-in internal command and your mapped commands.

When the 'timeout' option is set (which is the default), then Vim waits for the number of milliseconds specified in the
'timeoutlen' option for a mapped key sequence to complete. The default setting for 'timeoutlen' is one second.

If the 'timeout' option is reset, then Vim will not timeout for mapped key sequences. But it is better not to change the
'timeout' option setting and leave the option in its default value. Instead, if you want more or less delay before a
mapped key sequence times out, you can try increasing or decreasing the 'timeoutlen' setting.

Consider the following maps:

:nnoremap ;g :echo 'First command'<CR> :nnoremap ;k :echo 'Second command'<CR> 

When you press ';' to repeat the last 't' or 'f' or 'T' or 'F' command, Vim will now wait for 'timeoutlen' milliseconds
to check whether you are going to enter 'g' or 'k'. If you enter any other character or don't enter any character for a
second, then Vim will repeat the last 't' or 'f' or 'T' or 'F' command. If you enter 'g' or 'k' after ';', then Vim will
execute the corresponding map.

For the above described reason, it is better to avoid starting your mapped key sequence with a frequently used Vim
command like j, k, l, etc.


${E_WHITE_FG}Map Comments${E_RESET}
${E_WHITE_FG}------------${E_RESET}
You cannot add a Vim comment in the same line as the map command. The comment will be included in the map
command and executed when the key sequence is entered. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, using the following command, when you press <F2>, Vim will try to execute the comment
also as a series of key presses (resulting in error).

:map <F2> :ls<CR>     " Map to display the list of buffers 

You can add the comment before the line that defines the map:

"Map to display the list of buffers 
:map <F2> :ls<CR> 

${E_WHITE_FG}Supplying A Count To A Map${E_RESET}
${E_WHITE_FG}--------------------------${E_RESET}
To repeat a normal mode Vim command, you can specify a count before the command. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, to move the cursor 3 lines up, you can use the '3k' command. If you specify a count
before a mapped key sequence, the map may not be repeated by the specified count.

When a count is entered before invoking a map, the count will be prepended to the key sequence executed for the map. For
example, assume you have mapped <F7> to move the cursor by 5 characters to the right:

:nnoremap <F7> 5l 

If you invoke the above map with a count of 2 using 2<F7>, the cursor will not be moved 10 characters to the right.
Instead, the cursor will be moved 25 characters to the right. This is because the count 2 is prepended to the 5 in the
map resulting in 25.

To allow repeating a map by a specified count, you have to define your map using either the '=' expression register, the
execute command, or a Vim function.

The '=' expression register allows you to specify an expression for the register contents. To use the expression
register in your map, you have to combine that with the '@' operator. The '@' operator executes the contents of a
register. If a count is specified before the '@' operator, then it executes the contents of a register by the specified
count.

${E_BOLD}${E_ITALIC}For example${E_RESET}, change the above map command to:

:nnoremap <F7> @='5l'<CR> 

Now, if you use 2<F7>, the cursor will be moved 10 characters to the right.

Some things to note about using the '=' register in your map. After specifying an expression, you have to use <CR> to
end the command-line. If you want to use the escape character in the expression, you have to escape it using CTRL-V. For
example, if you want to define a map to add the '#' character at the beginning of the current line, exit the insert mode
and move the cursor one line down, you can use the following command:

:nnoremap <F4> @='I#<C-V><Esc>j'<CR> 
Now if you press 3<F4>, the 3 lines starting from the current line are prefixed with the '#' character.

In the above map, if you specify a key sequence after the contents of the expression register, then those keys will not
be executed by the '@' operator. So the specified count doesn't apply to those keys. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, in the above map, if you move the 'j' out of the contents of the expression register:

:nnoremap <F4> @='I#<C-V><Esc>'<CR>j 

Now, if you execute '3<F4>', three '#' characters will be added to the beginning of the current line and the cursor is
moved to the following line.

Another approach, which is useful when mapping to Ex commands, is to build a command string with the concatenate
operator '.' and execute this with the 'execute' command. 

${E_CYAN_FG}Example${E_RESET}:

:nnoremap g<C-T> :<C-U>exe v:count1 . "tag"<CR> 

This will map 'g<C-T>' to ':tag' and '5g<C-T>' to ':5tag'.

The v:count1 variable returns 1 if a count is not specified to the last normal mode command. The v:count variable
returns 0 if a count is not specified to the last normal mode command/map. In the above map, <C-U> is used to erase the
text on the command-line before invoking the function.

A third approach to allow repeating a map is to use a Vim function to define the map. A Vim function can be defined to
accept a count and repeat an operation that many number of times. You can use the "range" attribute to define a function
that accepts a count.

If you supply a count to a function that doesn't accept a range, then you will get the 'Invalid range' error message.

${E_CYAN_FG}Example${E_RESET}:

function! Myfunc() 
	" Function that doesn't accept a range 
endfunction 

:nnoremap _w :call Myfunc()<CR> 

If you specify a count to the _w command, then you will see the 'Invalid range' error message.

If you want your map to accept a range, then you have to specify the range attribute when defining the function as shown
below:

function! Myfunc()
	range echo 'range = ' . a:firstline . ',' . a:lastline 
endfunction 

:nnoremap _w :call Myfunc()<CR>

Now you can pass a count to the _w map. The a:firstline and a:lastline variables in the function refer to the starting
line number and ending line number of the range supplied to the function. The default is the current line number.

You can also use the internal v:count and v:count1 Vim variables in your function to get the count specified to the last
normal mode command or map. 

${E_CYAN_FG}Example${E_RESET}:

:nnoremap <C-W> :<C-U>call Myfunc()<CR> 

function! Myfunc() 
	let c = v:count 
	" Do something count number of times
endfunction

${E_WHITE_FG}Using Multiple Ex Commands In A Map${E_RESET}
${E_WHITE_FG}-----------------------------------${E_RESET}
You can specify multiple Ex commands separated by "|" (bar) in the Ex command line (":"). The "|" is used as the command
separator. 

${E_BOLD}${E_ITALIC}For example${E_RESET},

:set invignorecase | set ignorecase?  

If you specify "|" in the {rhs} of a map, then Vim will treat it as a command separator and only the first command will
be part of the map and the subsequent commands will be executed when defining the map. 

${E_BOLD}${E_ITALIC}For example${E_RESET},

:nnoremap <F9> :set invignorecase | set ignorecase?<CR> 

In the above command, "set ignorecase?" will not be part of the map for <F9>.

You have to escape the "|" by using backslash (\) or by using the <Bar> symbolic notation or by using CTRL-V. The
following commands will work:

:nnoremap <F9> :set invignorecase \| set ignorecase?<CR>
:nnoremap <F9> :set invignorecase <Bar> set ignorecase?<CR> 
:nnoremap <F9> :set invignorecase <press Ctrl-V>| set ignorecase?<CR> 

Some Ex commands use the command that follows them (separated by |) as part of the command itself. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the ":global" (or ":g") command repeats the command that follows it for every matched
pattern. In the following command,

:g/foo/s/abc/xyz/g | echo 'Completed substitution' 

The ":echo" command is repeated for every 'foo' found in the current buffer. To execute the ":echo" command only once
after the ":g" command completes, you have to use the ":exe" command.

:exe 'g/foo/s/abc/xyz/ge' | echo 'Completed substitution' 

If your map uses one of these commands like ":g" then you have to use ":exe" in your map command.

Another way to invoke multiple Ex commands from a map is to invoke them separately as shown below:

:nnoremap <F9> :set invignorecase<CR>:set ignorecase?<CR> 

Ex commands invoked from a map are not added to the command history. You can't recall the individual commands invoked by
a map from the command-line.

${E_WHITE_FG}Using Space Characters In A Map${E_RESET}
${E_WHITE_FG}-------------------------------${E_RESET}
If you want to use a space character in the {lhs} of a map command, then you have to use
<Space> or escape the space character with CTRL-V (need to use two CTRL-Vs). 

${E_CYAN_FG}Example${E_RESET}:

nnoremap q<Space> M 

The above command creates a normal mode map for the key sequence "q" followed by the space character to move the cursor
to the middle of the page.

If you want to use the space character at the beginning of the {rhs} of a map command, then use <Space>. In other places
in the {rhs}, you can use the space character by pressing the space bar. 

${E_CYAN_FG}Example${E_RESET}:

inoremap <C-F4> <Space><Space><Space> 

The above command creates an insert mode map for the key sequence CTRL-F4 to enter three space characters.

Note that if you inadvertently use a space character at the end of the {rhs} in a map command, then the map may behave
differently. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command maps the backspace character in normal mode to behave like the 'X'
command and delete the character before the cursor:

nnoremap <BS> X 

If there is a space character after "X" in the above command, then the map will delete the character before the cursor
but leave the cursor at the current location instead of moving it back by one position. You can locate these kinds of
errors, by looking at the output of the ":map" command. In the ":map" output, the space character at the end of the
{rhs} in a map will be shown as "<Space>".

${E_WHITE_FG}Disabling Key And Mouse Event${E_RESET}
${E_WHITE_FG}------------------------------${E_RESET}
You can disable key and mouse events by mapping them to the special string "<Nop>". 

${E_BOLD}${E_ITALIC}For example${E_RESET}, to disable the <F4> key in normal mode, you can use the following command:

:nmap <F4> <Nop> 

You can use the mode specific map command to disable a key in a particular mode.

The <Nop> sequence has a special meaning only if it appears by itself in the {rhs} of a map. You cannot use <Nop> with
other keys in the {rhs} of a map. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following command will not disable the <F1> key:

:inoremap <F1> <Nop><Nop> 

You can disable mouse buttons and mouse events by mapping them to <Nop>. 

${E_BOLD}${E_ITALIC}For example${E_RESET} to disable the <MiddleMouse> button, you can use the following command:

:imap <MiddleMouse> <Nop> 

${E_WHITE_FG}Error In Mapped Key Sequence${E_RESET}
${E_WHITE_FG}-----------------------------${E_RESET}
When executing the key sequences in a key map, if Vim encounters an error, then the map will be aborted and the
remaining key sequences will not be executed. You will not see any error message indicating that this has happened. If
you have the 'errorbells' or 'visualbell' option set, then you will see the screen flash or hear the audio beep.

${E_BOLD}${E_ITALIC}For example${E_RESET}, consider the following key map that maps <F5> to toggle the case of the first letter of the current word.

nmap <F5> wb~ 

In most cases the above map will work as desired. But when the cursor is at the last word in the last line of a file,
the above map will not work. In the last word of a file, the "w" command will fail and will not move the cursor to
the next word. So the remaining part of the map will not be executed.

One way to workaround this problem is to split the command into two parts and execute them using the ":exec" command:

nmap <F5> :exec 'normal w'<Bar>exec 'normal b~'<CR> 

${E_WHITE_FG}Maps And 'cpoptions' Option${E_RESET}
${E_WHITE_FG}---------------------------${E_RESET}
The 'cpoptions' Vim option contains many flags that control the compatibility level of Vim with the Vi behavior. To get
the current value of the 'cpoptions' option, use the following command:

:set cpoptions?  

When Vim is running in Vi-compatible mode, all the possible flags are set in the 'cpoptions' option.

The flags in the 'cpoptions' Vim option affect map definitions and their usage. These flags are described below.

If the flag 'b' is present in 'cpoptions', then a "|" character in a map command is treated as the end of the map
command. This means that you cannot use backslash (\) to escape the "|" character in map command definitions.

${E_CYAN_FG}Example${E_RESET}:

:nnoremap <F5> :set invhlsearch \| set hlsearch?<CR> 

If the 'b' flag is present in 'cpoptions', then the above map command definition will fail. All the characters after the
backslash will not be part of the map.

If the flag 'B' is present in 'cpoptions', then the backslash character is not treated as a special character in map
commands. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, let us say you want to create an insert-mode map for the <F6> key to insert the text "Press
<Home> to go to first character". For this, you can try using the following command:

imap <F6> Press <Home> to go to first character 

When you press <F6> in the insert mode, the <Home> in the above map will cause Vim to move the cursor to the first
character in the line and insert the reminder of the text there. To literally enter the text "<Home>", you need to
escape it:

imap <F6> Press \<Home> to go to first character If the flag 'B' is not present in 'cpoptions', then the above map
command will insert the correct text. If the flag 'B' is present, then the backslash character is not treated as a
special character and the above map will not insert the correct text. To treat <Home> literally independent of the
'cpoptions' setting, you can use the following command:

imap <F6> Press <lt>Home> to go to first character 

In the above command, the notation <lt> is used for "<" in "<Home>".

If the flag 'K' is present in 'cpoptions', then you can cancel the invocation of a map in the middle of the key sequence
by pressing <Esc>. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, let us say you have the following map command:

:nnoremap <F3><F3> :ls<CR> 

If the flag 'K' is present, then after entering the first <F3>, you can cancel the map by pressing <Esc>. If the flag
'K' is not present, then if you don't press any key after the first <F3>, Vim will wait for 'timeoutlen' milliseconds
before cancelling the map (assuming the 'timeout' option is set).

If the flag 'k' is present in 'cpoptions', then raw key codes are not recognized in map commands. You can enter raw key
code in a map command by pressing Ctrl-V followed by a control key. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, consider the following map command:

nnoremap <press Ctrl-V><press Up arrow> gk 

The above command maps the raw key code for the up arrow key to invoke the gk command. If the 'k' flag is not present in
'cpoptions', then the above command will properly work. If the 'k' flag is present in 'cpoptions', then the above map
command will not work.

If the flag '<' is present in 'cpoptions', then special keys codes like <Tab>, <C-K>, <F1>, etc. are not recognized in
maps. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, consider the following maps:

:nnoremap <M-Right> <C-W>l :nnoremap <M-Left> <C-W>h 

If the '<' flag is present in 'cpoptions', then the above map commands will not work as the special key codes <M-Right>,
<M-Left> and <C-W> will not be recognized.

${E_WHITE_FG}Maps And 'paste' Option${E_RESET}
${E_WHITE_FG}-----------------------${E_RESET}
While pasting text into a Vim buffer, to disable automatic indentation and interpreting mapped
key sequences in the inserted text, you can set the 'paste' option. When the 'paste' option is set, mapped key sequences
are ignored. By default, the 'paste' option is disabled. If your mapped keys are not working in a buffer, check whether
the 'paste' option is set.

Map attributes You can modify the behavior of a key map by specifying several attributes in the map command. The
supported attributes are <buffer>, <silent>, <special>, <script>, <expr>, and <unique>. You can specify one or more of
these attributes in a map command immediately after the map command name.

Buffer-local maps When you create a map, the mapped key can be used in all the Vim buffers. To create a map that is
applicable only to specific buffers, use the <buffer> attribute to the map command. 

${E_BOLD}${E_ITALIC}For example${E_RESET},

:setlocal makeprg=gcc\ -o\ %< :nnoremap <buffer> <F3> :make<CR> 

The above command creates a map to compile the file opened in the current buffer. You can add the above set of commands
to a filetype plugin. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, you can add it to file ~/.vim/after/ftplugin/c.vim (Unix) or
\${HOME}/vimfiles/after/ftplugin/c.vim (Windows)—create any missing directories or files. Now, you can compile a C file in
the current buffer, by pressing the <F3> key. When you open a Java file, this command will not be available.

When a buffer is deleted, the buffer local mappings for that buffer are removed. When a buffer is unloaded or hidden,
you will not lose the mappings.

When you remove a buffer local map, you have to specify the <buffer> attribute to the ":unmap" or ":mapclear" command.
Without the <buffer> attribute you cannot remove the map.

To display all the buffer-local mappings for the current buffer, use the following commands:

:map <buffer> 
:map! <buffer> 

To display the mode specific buffer-local maps, use the map command for that mode in the above command.

${E_WHITE_FG}Silent Maps${E_RESET}
${E_WHITE_FG}-----------${E_RESET}
When a map is invoked, the sequence of keys executed is displayed on the screen. If an Ex command is invoked
by the map, then you can see the Ex command at the Vim status line. To silently execute a map, use the <silent>
attribute for the map. 

${E_BOLD}${E_ITALIC}For example${E_RESET},

:nnoremap <silent> <F2> :lchdir %:p:h<CR>:pwd<CR> 

The above command maps the <F2> key to change to the directory of the current file and then display the current
directory. When you invoke the above command, due to the <silent> attribute, you will not see the commands that are
executed.

If the commands invoked by the map display a message, then those messages will be visible even though <silent> attribute
is specified for the map command. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, in the above command, the current directory displayed by the ":pwd" command will be visible.

Expression maps For simple maps, the action to be carried out for a key sequence can be defined without using a Vim
function. But for complex maps, it is simpler to use a Vim function to implement the action for the map.

You can use the <expr> attribute to a map command to invoke a Vim function and use the returned value as the key
sequence to execute.

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following code creates a normal mode map to change to the directory of the current buffer.

function! ChangeToLocalDir() 
	lchdir %:p:h 
	return '' 
endfunction 

nnoremap <expr> _c ChangeToLocalDir() 

In this example, the function returns an empty string so the map takes no action other than executing the function.

The <expr> attribute can be used with all the mode specific map commands.

${E_WHITE_FG}Special Characters In Map${E_RESET}
${E_WHITE_FG}--------------------------${E_RESET}
To use non-printable characters using the <> notation like <F5> in a map command, the '<' flag should not be present in
the 'cpoptions' option. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the following map command will not work:

:set cpo+=< :inoremap <F7> <C-X><C-N> 

In insert mode, if you press <F7>, instead of executing the map, the characters <F7> will be inserted. To prevent this,
you can use the <special> map attribute:

:inoremap <special> <F7> <C-X><C-N> 

With the <special> map attribute, independent of the 'cpoptions' option setting, Vim will correctly process the <> key
codes in the {rhs} of a map command.

Using maps in Vim plugins and scripts A Vim plugin or script can define new key maps to let the user invoke the commands
and functions provided by the plugin. A Vim plugin can also invoke key maps defined by other Vim plugins.

A plugin can choose to map any available key. But to avoid surprising (annoying) the user, it is better not to use the
keys that already have pre-defined functionality in Vim.

In a Vim plugin, the ":normal" command is used to execute normal mode commands. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, the "gqip" normal mode command is used to format a paragraph. To invoke this command from
a Vim plugin, the following line can be used:

normal gqip If any of the keys in "gqip" is mapped, then the mapped key sequence will be executed. This may change the
expected behavior of the "gqip" command. To avoid this, add the "!" suffix to the "normal" command:

normal! gqip With the "!" suffix, the "normal" command executes the built-in functionality provided by Vim for the
specified sequence of keys.

To invoke a script local function, defined with the "s:" prefix, from a map, you have to prefix the function name with
<SID>. You cannot use the "s:" prefix for the script-local function, as the map will be invoked from outside of the
script context.

:inoremap <expr> <C-U> <SID>InsertFunc() 

A plugin may map one or more keys to easily invoke the functionality provided by the plugin. In the plugin functions
used by these types of maps, it is advisable not to alter user Vim option settings, register contents and marks.
Otherwise, the user will be surprised to see that some options are changed after invoking a plugin provided map.

${E_WHITE_FG}Map Leader${E_RESET}
${E_WHITE_FG}----------${E_RESET}
If the key maps provided by all the Vim plugins start with the same key, then it is easier for a user to
distinguish between their own key maps and the ones provided by plugins. To facilitate this, Vim provides a special
keyword that can be used in a map command.

If the {lhs} key sequence of a map command starts with the string "<Leader>", then Vim replaces it with the key set in
the 'mapleader' variable. The default setting for the 'mapleader' variable is backslash ('\'). Note that 'mapleader' is
a Vim variable and not a Vim option. The value of this variable can be changed using the 'let' command. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, to set it to '_' (underscore), you can use the following command in your vimrc file:

let mapleader = "_" 

Vim replaces <Leader> with the 'mapleader' value only when defining the map and not when the map is
invoked. This means that after several map commands are defined if the 'mapleader' variable is changed, it will not
affect the previously defined maps.

${E_BOLD}${E_ITALIC}For example${E_RESET}, consider the following map command defined by a plugin:

nnoremap <Leader>f :call <SID>JumpToFile()<CR> 

When defining the above command, Vim replaces <Leader> with the value of the 'mapleader' variable. If the user didn't
set the 'mapleader' variable then the above map can be invoked by entering \f. If the user sets the 'mapleader' to a
comma (','), then it can be invoked using ,f.

The <Leader> prefix should be used for global mappings (applicable to all buffers) defined by a plugin. For buffer-local
mappings, the <LocalLeader> prefix should be used. Vim will replace this with the value set in the 'maplocalleader'
variable. The default value for this variable is backslash ('\'). The <LocalLeader> is generally used in mappings
defined by a Vim filetype plugin.

The 'mapleader' and 'maplocalleader' variables allow the user to choose different keys as starting keys for global
mappings and buffer-local mappings defined by Vim plugins.

Script maps If you want to use recursive maps in your map command, but want to use only those keys mapped in your script
or plugin, then you can use the <script> attribute in the map definition. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, consider the following two map commands in a script file:

noremap <SID>(FindTopic) /Topic<CR> 
nmap <script> ,dt <SID>(FindTopic)dd 

Within the second map command, only the '<SID>(FindTopic)' part is remapped. Without '<script>', 'dd' could be remapped
too if someone defined a mapping for it.

If you use the <script> attribute with a ":noremap" command, then the <script> attribute overrides the ":noremap"
command. The {rhs} of the map is still scanned for script-local key mappings. But the maps defined outside of the script
are not used.

Unique maps If you want to make sure that the mapped key is unique and doesn't interfere with other existing mappings,
use the <unique> map attribute. This attribute is particularly useful with the maps defined by a Vim plugin. A map
definition with the <unique> attribute will fail if the specified key is already mapped.

:nnoremap <unique> \s :set invhlsearch<CR> 

The above command will fail, if the user already has a mapping for the "\s" key sequence.

Use of <Plug> If you are developing a Vim plugin or script and you want to provide the user with the flexibility of
assigning their own key map to invoke a function provided by your script, then you can prefix the map with <Plug>.

${E_BOLD}${E_ITALIC}For example${E_RESET}, let us say a plugin has a function s:VimScriptFn() and the user has to create a map to assign a key to
invoke this function. The plugin can provide the following map to simplify this:

noremap <unique> <Plug>ScriptFunc :call <SID>VimScriptFn()<CR> Note that in the above map command, instead of the
typical key sequence for the {lhs} of the map, the <Plug>ScriptFunc text is used. The <Plug> generates a unique key
sequence that a user cannot enter from a keyboard. The above map is visible outside of the script where it is defined.

With the above command, the user can assign _p to invoke the script function as shown below:

:nmap _p <Plug>ScriptFunc

Map related functions Vim provides built-in functions to check whether a key sequence is mapped or not and to get the
mapped key sequence.

maparg() To get the {rhs} of a map command from a script or plugin, use the maparg() function. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, consider the following commands:

:nnoremap <C-F2> 2<C-G> :let x = maparg("<C-F2>", "n") :echo x 

The variable 'x' will be set to the mapped key sequence "2<C-G>".

The first argument to the maparg() function specifies the key sequence and the second argument specifies the editing
mode. The maparg() function checks whether the specified key sequence is mapped in the specified mode and returns the
{rhs} of the map if it is defined. If the mode is not specified, then the maparg() function checks for the map in the
normal, visual and operator pending modes.

The maparg() function can be used to chain map commands. 

${E_BOLD}${E_ITALIC}For example${E_RESET}, let us say you want to define a map for <Tab>. But at the same time you don't want to
lose the existing map (if any) for <Tab>. Then you can do the following:

:exe 'nnoremap <Tab> ==' . maparg('<Tab>', 'n') 

The above command maps <Tab> to invoke the == command and then invoke the existing map for <Tab> in normal mode.

${E_WHITE_FG}mapcheck({name} [, {mode} [, {abbr}]])${E_RESET}
${E_WHITE_FG}--------------------------------------${E_RESET}

To check whether a map is defined for a key sequence, you can use the mapcheck() function. 

${E_CYAN_FG}Example${E_RESET}:

:echo mapcheck(';g', 'n') mode() 

In a map command, you can use the mode() Vim function to get the current editing mode.  But this function returns 'n'
(normal) or 'c (command-line) in most cases. So this function cannot be used reliably from a map command to get the
current mode. Instead, you should pass the current mode as an argument to the called function.  

${E_BOLD}${E_ITALIC}For example${E_RESET}, if you want to use a Vim function Somefunc() in several mode-specific map commands and
want to distinguish between the modes in the function, then you can do the following:

:nnoremap _g :call Somefunc('n')<CR> 
:inoremap _g <C-O>:call Somefunc('i')<CR> 
:vnoremap _g :<C-U>call Somefunc('v')<CR> hasmapto() 

To check whether a map is defined for a particular key sequence, you can use the hasmapto() function. Note that this
function checks for the key sequence in the {rhs} of a map. 

${E_CYAN_FG}Example${E_RESET}:

if !hasmapto(":grep") 
	" Define a mapping to invoke the :grep command 
endif 

The hasmapto() function checks for the specified key sequence anywhere in the {rhs} of a map (not necessarily at the
beginning of the map).

The hasmapto() function also accepts an optional {mode} argument which allows you to check whether a map definition
exists in a particular mode.

if !hasmapto(":grep", 'n') 
	" Define a normal mode map to invoke :grep 
endif

${E_WHITE_FG}Additional Info${E_RESET}
${E_WHITE_FG}---------------${E_RESET}

Verbose Commands 

The more pieces of configuration and plugins you’ll add to Vim, the more you’ll wonder where they’ve
been created in your config files. 

The command :verbose can help you: it will output at what line of what file a precise
configuration have been declared.

More precisely, :verbose can output the declarations of:

Abbreviations Options Mapping User commands 

For example, I’ve set the option undodir in my vimrc. If I run :verbose set undodir?, 
I’ll get the following output:

Last set from ~/.config/nvim/init.vim line 354 

Keeping your configuration well organized and simple is the best strategy. 
But everything gets messy overtime, especially when experimenting with new configuration or plugins. 
I don’t use verbose often but, when I need it, I’m always happy to have it.

Vim help :help :verbose-cmd 

Mapping Special Arguments 

We’ve seen the basics of mapping in a previous article, but we didn’t speak about the special arguments it can take.
Most of them can be used for abbreviations, too.

Here are the most useful ones:

	<silent> - Doesn’t output the mapping in the Vim command-line. If you want to also drop the output of the command linked
	to the mapping, add the command :silent.  

	<buffer> - The mapping’s scope is reduced to the current buffer only. These mappings have the priority on the global
	ones.  

	<expr> - The mapping executes a Vimscript expression instead of a Vim command.  

	<unique> - The mapping fails if it already exists. It’s useful if you don’t want to override any mapping defined
	previously.  

	<Cmd> - The mapping can run a command without quitting the current mode you’re in.  A special argument should be used as
	first argument for any mapping or abbreviation. The argument 

	<Cmd> is an exception: it should be used just before the command itself.

To understand how it works, let’s take some examples:

:nnoremap <silent> <leader><f6> :source \${MYVIMRC}<CR> 
The command :source \${MYVIMRC} won’t be displayed in the Vim command-line when hitting LEADER F6.  

:iab <expr> cdate strftime('%Y-%m-%d') 
The Vimscript function strftime is executed when the abbreviation cdate is used.  

:inoremap <c-d> <Cmd>delete<cr> 
Execute the command :delete without leaving INSERT mode.  

:nnoremap <leader><f6> :silent :source \${MYVIMRC}<CR> 
The output of the command :source \${MYVIMRC} will be dropped, thanks to the command :silent.  We’ll see a use case for
the special argument <buffer> below.

Vim help :help map-arguments 

Mapping Operator Pending Mode 

Operators are NORMAL mode keystrokes which need to be combined with motions or text-objects. For example, d, c, or y are
operators. I’ve written about them in the very first article of this series.

When we type one of these operators in NORMAL mode, we switch to OPERATING-PENDING mode. At that point, vim waits for a
motion (or text-object), and then come back to NORMAL mode.

Vim let’s you create new mapping for this OPERATOR-PENDING mode with the command :onoremap. Concretely, you’ll be able
to create new motions for all existing operators.

For example:

:onoremap ic i{ 
We’ve created here a new text-object ic to use an operator inside curly brackets. 
You can try it out to delete the content between two curly brackets for example, by:

Placing the cursor inside the curly brackets.  Hitting dic in NORMAL mode.  

The text-object (or motion) created with :onoremap always begins where your cursor is. That’s why we need to place our
cursor inside the curly brackets in our previous example. But it would be even better if we could act on the next curly
brackets on the current line, without worrying where the cursor is. 

The following command will make this dream a reality:
:onoremap nc :normal! f{vi{<cr> 

Let’s look at this example more closely:

:normal!  Execute keystrokes as if you were in NORMAL mode (see Vim for Advanced Users).  
f{        Find the next curly bracket on the line (see Vim for Beginners).  
vi{       Switch to VISUAL mode and select inside the curly brackets.  
<cr>      Key notation for the ENTER key to validate our command (carriage return, see Vim for Intermediate Users).  

The operator will be applied on the selection made in VISUAL mode. 

To illustrate this idea, let’s look at the following content:

My super┃line {with curly brackets} 

The symbol ┃ represents the cursor position. If you hit the keystroke dnc, you’ll delete what’s inside the next curly
bracket. 

The result will be:

My super line {} 

The cursor will end up on the last curly bracket.

Vim help :help omap-info 

The Command Execute 

Let’s look again at the mapping we’ve set above:

:onoremap nc :normal! f{vi{<cr> 

The key notation <cr> is considered a special character when you create a mapping. It works with mappings, but it won’t
work with the :normal command by itself.

For example, you can try to run the following to replace the next occurrence of “emacs” with “vim”:

:normal /emacs<cr>ciwvim 

This time, Vim doesn’t recognize <cr> as a special character, so the command won’t work. To go around this limitation,
you can use CTRL+V (see Vim for Adept Users). In that precise case, we would need to hit CTRL+V ENTER while writing our
command. We would end up with something like this:

:normal! /emacs^Miwvim 

The command :execute can solve our problem in a more elegant way. It lets you execute a command from a string. You can
then use string constants for these special characters, all prefixed with a \. 

Here’s an equivalent of our silly example:

:execute "normal! /emacs\<cr>ciwvim" 

All the key notations you can use with :map or :abbreviate have their string constant equivalents.

When you give multiple arguments to execute, they’re concatenated into one string and separated with spaces. If you
don’t want the spaces, use a dot instead. 

For example:

:execute 'echo "this" "is" "a" "str"."ing"' 

The output will be: “this is a string”.

Vim help :help execute :help expr-quote 

Autocommands Basics 

Autocommands can automatically run a command when a specific event happens. More precisely, it adds a command to a list
of command linked to a precise event. When this event is fired, every command of the list of commands are executed.

An event can be opening Vim, reading any file, or writing a markdown file for example.

Here are the basics to manipulate autocommands:

:autocmd <event> <pattern> <cmd> or :au <event> <pattern> <cmd> 

Add the command <cmd> to the list of commands executed automatically when the event <event> is fired. The pattern
<pattern> filter the files where the autocommand should be applied.  :autocmd <event> or :au <event> - Output the list
of commands executed when the event <event> is fired.  :autocmd! <event> or :au! <event> - Delete the list of
autocommands of the event <event>.  

To clarify all this jargon, here are some examples:

:autocmd BufWrite * echom "Write..." 
Output “Write” each time any file is saved. The wildcard * means “every file”.

:autocmd BufNew *.md echom "Read..." 
Output “Read” each time a new markdown buffer is created. Unsurprisingly, The pattern *.md means every filename
finishing with .md.  After running these commands, you can try to write a file (command :w) to see if it works. If you
don’t see the message in the command-line, run :messages to display them.

Multiple Events and Patterns You can also create an autocommand with more than one event or pattern, separated with a
comma. 

For example:

:autocmd BufNew,BufWrite *.md,*.js,*.php echom "Create or write md, js, or php..." The command echom "Create or write
md, js or php..." will run when a markdown, JavaScript, or PHP buffer is created (BufNew) or saved (BufWrite).

Note that the pattern can be a bit different depending on the events you listen to. For a description of all events
available, see :help autocommand-events.

Finally, if you want the scope of the autocmd to be limited to the current buffer, you can use the special pattern
<buffer>.

Autocommand Groups 

Why Using Autocommand Groups?  As the name indicates, an autocommand group is a group of one or more autocommands. When
you create an autocommand as we did above, it’s added automatically to a default autocommand group without a name. You
can create autocommand groups with names and add autocommands to it, too. You can think of it as namespaces for
autocommands.

To understand this concept, let’s see where it’s useful to use autocommand groups. As we saw, each time you create an
autocommand, it’s added to the list of command triggered when a specific event occurs; even if this command is already
part of the list.

Let’s look at an example. 

First, let’s add this autocommand to your vimrc:

autocmd BufWritePre * echom "Write..." 

You can then try the following:

Source your virmc twice (by running :source \${MYVIMRC} twice).  Run :autocmd BufWrite.  This last command will output the
list of commands executed when the event BufWrite is triggered. It will output something like this:

BufWritePre *         echom "Write..." echom "Write..." 

The command echom "Write..." appears two times in the command list for the pattern *. As a result, each time the event
occurs on any file, the command will run two times.

More often than not, we want to add our commands to the command list only once. Otherwise, it will impact performances
each time the event is fired and, if the command is not idempotent, nasty bugs will pop up.

Using autocommand groups can solve this problem. Here are the basic commands you can use to manipulate these groups:

:augroup
Output all autocommand groups.  

:augroup <name> or aug <name> 
Call a new autocommand group named <name>.

All autocommands created after this command will be part of the group.  

:augroup! <name> or aug! <name> 
Delete the group named <name>.  

:augroup END 
End the autocommand group. If you define an autocommand after this one, it won’t be part of the group.  

As always, here’s an example:

:augroup messages :autocmd BufWrite * echom "Write..." :augroup END 
The autocmd is now part of the autocommand group messages.

By itself, it doesn’t solve our problem. If you add the three lines above in your vimrc and source multiple times, the
autocommand in the group messages will be added to the autocommand list each time.

We saw above that you can delete autocommands with the command au! <event>. This will work if the autocommand is not in
a named group. If you run au! BufWrite for example, it will delete every autocommand in the nameless autocommand group
(the default one), but not the one in the group messages we’ve created above.

To solve our problem, we could delete every autocommand belonging to the group messages after creating the group itself:

:augroup messages :au! messages :autocmd BufWrite * echom "Write..." :augroup END 

If these lines are in your vimrc and you source it three times, every autocommand will be deleted from the group
messages each time, before being added again. In short, our problem is solved: the command echom "Write..." will always
appear once and only once in our list of command.

When we use au! between the initialization of the group (augroup messages) and the end of the initialization (augroup
END), we don’t have to indicate the name of the group. Vim will understand, in that case, that we want to delete every
autocommand of the group declared just before. In short, the following commands are equivalent to the ones above:

:augroup messages :au!  :autocmd BufWrite * echom "Write..." :augroup END 
Redeclaring an autocommand group won’t recreate it, but it will add autocommands in the existing group instead. For
example, you can do something like that:

augroup vimrc au!  augroup END

augroup vimrc autocmd BufWrite * echom "Write..." augroup END 

Two things happen here:

A group vimrc is declared.  Autocommands are declared and added to the group vimrc.  In short, every autocommand added
to the group vimrc is merged with the command :au!. You can even do better: when you create an autocommand, you can add
it to an existing group directly. To do that, you can indicate the name of the group just between the command autocmd
and the event name as follows:

augroup vimrc au!  augroup END

autocmd vimrc BufWrite * echom "Write..." 

You’re now able to reload your vimrc as much as you want, your autocommands will only appear once in the autocommand
list. It applies for other sourced files too, like the ones you might have in your folder ftplugin for example.

Ignoring Events If you want to run a command without firing any event, you can use the command :noautocmd. To take our
previous example, if you want to ignore the event BufWrite when running the command :w, you can run the following:

:noautocmd w Vim help :help autocmd :help autocommand-events :help autocmd-events-abc 

Custom Functions 
Writing custom functions for Vim to make your craziest dreams come true should be the goal of any Vim Follower out there.

It’s true that many functions are already available on the infinite Internet. You can simply copy and paste them without
worrying how they work. That said, knowing the basics of Vimscript functions can allow you to adapt them to your needs.

Checking Existing Functions 
Let’s see first how you can display the functions already available:

:function or :fu - List all declared function.  :function /<pattern> or :fu /<pattern> - Filter all declared functions
with the pattern <pattern>.  Creating Or Copying Functions Looking at a simple function will help us understand how they
work. Here’s one:

function DeleteTrailingWS() abort normal mz %s/\v\s+\$//ge normal \'z endfunc This function delete trailing whitespaces in
a whole buffer. Let’s look at it in more details:

function - Keyword to declare a function. You can add a bang (function!) to overwrite a previously declared function
with the same name.  DeleteTrailingWS - Name of the function. It should always begin with an uppercase letter.  abort -
Stop the function when an error occurs.  Be careful if you use function! (with a bang): you might overwrite a function
from one of your plugin. It can open the door to random bugs difficult to fix.

If you look at the body of our function, they are simply Vim commands. They are executed in order:

normal mz - Save the cursor position using the mark z.  %s/\v\s+\$//ge - Delete every whitespace in the current buffer,
using the substitute command.  % - Range for the whole buffer.  \v - Use the very magic mode.  \s - Represent any
whitespace.  Flag e - Doesn’t output an error if the search pattern fail.  normal \'z - Go back to the mark z (the cursor
position when the function was invoked).  I’ve already written about all these commands in Vim for Advanced Users. For
more details about Vim regexes, see Vim for Adept Users.

You can then call the function using the command :call as follows:

:call DeleteTrailingWS() You can also create a new mapping for some of your function if you want to:

nnoremap <leader>ds :call DeleteTrailingWS() Autoloading Functions You can create function in your vimrc directly as we
did above, but it might create some problems. Imagine that the name of the function conflict with a function from one of
your plugin: the bugs occuring can be difficult to debug.

Additionally, all the functions declared in your vimrc will be automatically loaded when you open Vim, even if you never
use them. It would be more efficient to load them when you call them the first time.

It’s where the autoload folder comes in handy. This folder is located in the Vim’s runtime paths.

When Vim needs to find something, it will look at the Vim’s runtime paths. The folder containing your vimrc is one of
these paths, for example. To display all of them, you can run the command :set runtimepath?.

The folder autoload is one of these paths too. Any function created in this folder will have namespaces, and they will
be loaded on demand. Exactly what we want!

You can create the autoload folder where your vimrc is. Then, you can create Vimscript files in there; the name of the
file will be the namespace for your functions.

For example, you can create the file “general.vim” in the autoload folder. Then, you can write in the file the following
function:

function general#DeleteTrailingWS() abort normal mz %s/\v\s+\$//ge normal \'z endfunc When you call the function with
:call general#DeleteTrailingWS(), Vim will:

Look inside the autoload directory for a file called general.  Search for a function called DeleteTrailingWS inside this
file.  Load and execute the function.  Additionally, you can easily display every function for the namespace <namespace>
by running the command :function /<namespace>. For example, if you want to display all the functions for the namespace
general, run :function /general.

For more fine-grained namespaces, you can add sub-directories in the autoload directory. For example, you can create the
following:

autoload/my/super/namespace.vim Then, you’ll need to add the namespace “my#super#namespace” to the functions you create
in the file namespace.vim. For example:

function my#super#namespace#DeleteTrailingWS() abort normal mz %s/\v\s+\$//ge normal \'z endfunc Vim help :help functions
:help autoload-function :help call :help 'runtimepath' User Commands Now that we’re able to create our own functions,
what about increasing our power with our own custom Vim commands? We’ll then be able to run these user commands using
the COMMAND-LINE mode, like any other command.

Basics Like functions, custom user commands should always begin with an uppercase letter, to differentiate them from
Vim’s built-in commands.

Continuing our ritual, here are three useful commands to manipulate user commands:

:command or :com - Output all user commands.  :command <command> or :com <command> - Output all user commands starting
with <command>.  :command <attributes> <name> <cmd> or :com <attributes> <name> <cmd> - Define a new user command with
the name <name> running the command <cmd>. The attributes <attributes> indicate the number of arguments (among other
things).  Similarly to custom functions, you can add a bang when you declare a command (:command!). In that case, if a
command already exists with the same name, it will be overwritten.

Attributes for User Commands There are four different categories of attribute you can use when creating a user command:

Argument handling Range handling Completion behavior Special cases We’ll only cover the most important one in this
article: the argument handling. It allows us to specify the number of argument a user command can take, with the
attribute -nargs:

-nargs=0 - No argument allowed (default).  -nargs=1 - One argument is required.  -nargs=* - Any number of arguments
allowed.  -nargs=? - 0 or 1 argument allowed.  -nargs=+ - One argument or more are required.  To indicate where the
arguments should be inserted in the command, you need to use the placeholder <args>. For example, you can write the
following in your vimrc:

function IScream(content) 
	echom toupper(a:content) 
endfunction

command -nargs=1 Scream call IScream(<args>) As you can see, you can call the arguments of a function in its body using
a:<arg_name>. To try your new user command, source your vimrc with :source \${MYVIMRC} and run the following:

:Scream "hello" When a user command call a function which can take multiple arguments, you need to separate them with
whitespaces and use the placeholder <f-args> instead of <args>.

If there is only one argument allowed, Vim will consider the whitespace as part of the argument itself.

Finally, if you need your user command to be only available in the current buffer, you can also add the attribute
-buffer. It’s mandatory if you create user commands in your runtime folder ftplugin.

Vim help :help user-commands Special Strings for Vim Commands Let’s now look at special strings you can use in
COMMAND-LINE mode. These placeholders will be replaced under the hood with their representations. Here’s a list of the
most useful ones:

% - Relative path of the current file.  <cword> - Word under the cursor.  <cWORD> - WORD under the cursor.  <cfile> -
Filepath under the cursor.  <afile> - File open in the buffer when executing autocommands.  <sfile> - Filename of
sourced file when used with command :source.  You can also use the following with %:

:p - Output the absolute path instead of the relative one. Also expand the tilda ~ to the home directory.  :. - Make the
file path relative to the working directory.  :~ - Make the file path relative to the home directory (if possible).  :h
- Keep the head of the file path (remove the last element).  :t - Keep the tail of the file path (remove everything
except the last element).  :r - Keep the root of the file name (remove its extension).  :e - Remove everything except
the extension of the filename.  :s?pat?sub? - Substitute the first occurrence of “pat” with “sub”.  :gs?pat?sub? -
Substitute all occurrences of “pat” with “sub”.  These special strings only work when a command expects a filename as
argument; as a result, it makes this functionality quite limited. Fortunately, You can use the function
expand(<special_string>) to expand these placeholders in any command.

For example, you can try to run the following:

:echom expand("%") :echom expand("%:p") :echom expand("<cword>") Here’s a more useful example we already saw in the
article Vim for Advanced Users:

nnoremap gX <silent> execute \ "!xdg-open" expand('%:p:h') . "/" . expand("<cfile>") " &"<cr> You should now be able to
understand this command:

<silent> - The mapping won’t appear in the command line when used.  execute - Execute a string as a Vim command.
expand('%:p:h') - Output the head of the absolute path.  expand("<cfile>") - Output the filepath under the cursor in the
current buffer.  In short, this mapping will open the relative filepath under the cursor using the CLI xdg-open.

This command shouldn’t take more than one line, but the backslash \ allows us to write it on two lines for a better
readibility. Its fancy name is “line continuation symbol”.

If you’re used to write shell scripts, remember that the line continuation symbol is not at the end of the line, but at
the beginning of the next one.

Vim help :help cmdline-special :help line-continuation A Complete Example Let’s summarize most of what we saw in this
article with a final example. We want to:

Create the user command DevDocs. This command will automatically open the website https://devdocs.io/ and search the
word under the cursor.  Map the command to <leader>D in NORMAL mode. This mapping will be available for python, ruby,
JavaScript, go, html, and PHP filetypes.  Here’s a possible solution:

augroup vimrc autocmd!  augroup END

command! -nargs=? DevDocs call system('xdg-open https://devdocs.io/#q=<args>')

autocmd vimrc FileType python,ruby,javascript,go,html,php nnoremap <buffer><leader>D execute "DevDocs " .
expand('<cword>')<CR> We first declare an autocommand group vimrc.  We declare the user command DevDocs, accepting 0 or
1 argument.  We declare an autocommand linked to the event FileType. We indicate the filetypes which will trigger the
autocommand.  We use the special argument <buffer> to make the mapping only available in the current buffer. Without
that, the mapping would be available in every buffer regardless of the filetype.  The autocommand use expand('<cword>'),
which is replaced by the word under the cursor.  The event FileType can be useful to assign precise mappings to a whole
range of filetypes. We need, with this event, to give filetypes as autocommand patterns (like python or ruby for
example). Remember that you can output the filetype of the current buffer with :set filetype?.

The binary xdg-open is only available for Linux-based systems. If you want the autocommand to work on macOS too, you can
use the following:

command -nargs=? DevDocs call system('type open &>/dev/null && open https://devdocs.io/#q=<args> || xdg-open
https://devdocs.io/#q=<args>') The autocommand verifies if the binary open exists (for macOS) and, if it doesn’t, it
uses xdg-open.

Take Control of Your Vim Destiny Creating your own functions, commands, and mapping for tedious operations will help you
focus on more important tasks. Additionally, you’ll bring more efficient in your whole workflow. How great is that?

Let’s summarize what we saw in this article:

You can use the command :verbose to output where an abbreviation, option, mapping, or user command, is defined.  Special
arguments are available for your mappings to extend its power.  Operator pending map allow you to define motions for
operators.  The command :execute can execute a string as if it was a command.  Autocommands can run a defined command
when an event is triggered.  You can use autocommand groups to organize your autocommand.  Autocommand groups are
mandatory if you don’t want to add multiple times the same command in the autocommand list. It can happen when a
Vimscript file is loaded multiple time (like your vimrc).  Custom functions can execute numerous Vim commands one after
the other.  It’s better to autoload custom functions to be able to use namespaces and for Vim to start quicker.  User
commands are commands you can personalize for your own needs.  A last tip: if you want the list of Vimscript functions
you can use, split in different category (like “Variables” or “Date and Time”), you can look at :help function-list.


tip_vim_map_EOF
}

tip_vlc () {
vlc --longhelp --advanced 
}

tip_zsh () {
cat << tip_zsh_EOF_1
${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}

${E_CYAN_FG}Search headers: ARRAYS PARAM TYPESET READ REDIRECTION BUILTIN VI ${E_RESET}

${E_WHITE_FG}Operators${E_RESET}
In the native mode of operation, the following operators are supported (listed in decreasing order of precedence):

${E_CYAN_FG}= += -= *= /= %= &= ^= |= <<= >>= &&= ||= ^^= **= ${E_WHITE_FG}assignment${E_RESET}
${E_CYAN_FG}                                    + - ! ~ ++ -- ${E_WHITE_FG}unary plus/minus, logical NOT, complement, {pre,post}{in,de}crement${E_RESET}
${E_CYAN_FG}                                               ** ${E_WHITE_FG}exponentiation${E_RESET}
${E_CYAN_FG}                                            * / % ${E_WHITE_FG}multiplication, division, modulus (remainder)${E_RESET}
${E_CYAN_FG}                                              + - ${E_WHITE_FG}addition, subtraction${E_RESET}
${E_CYAN_FG}                                        < > <= >= ${E_WHITE_FG}comparison${E_RESET}
${E_CYAN_FG}                                            == != ${E_WHITE_FG}equality and inequality${E_RESET}
${E_CYAN_FG}                                               && ${E_WHITE_FG}logical AND${E_RESET}
${E_CYAN_FG}                                            || ^^ ${E_WHITE_FG}logical OR, XOR${E_RESET}
${E_CYAN_FG}                                              ? : ${E_WHITE_FG}ternary operator${E_RESET}
${E_CYAN_FG}                                                , ${E_WHITE_FG}comma operator${E_RESET}
${E_CYAN_FG}                                            << >> ${E_WHITE_FG}bitwise shift left, right${E_RESET}
${E_CYAN_FG}                                                & ${E_WHITE_FG}bitwise AND${E_RESET}
${E_CYAN_FG}                                                ^ ${E_WHITE_FG}bitwise XOR${E_RESET}
${E_CYAN_FG}                                                | ${E_WHITE_FG}bitwise OR${E_RESET}
 The  operators  ‘&&’,  ‘||’,  ‘&&=’, and ‘||=’ are short-circuiting, and only one of the latter two expressions in a ternary operator is evaluated.
 Note the precedence of the bitwise AND, OR, and XOR operators.

${E_WHITE_FG}CONDITIONAL EXPRESSIONS${E_RESET}
       A  conditional  expression  is  used  with the [[ compound command to test attributes of files and to compare strings.  Each expression can be con‐
       structed from one or more of the following unary or binary expressions:

       ${E_WHITE_FG}-a${E_RESET} file
              true if file exists.

       ${E_WHITE_FG}-b${E_RESET} file
              true if file exists and is a block special file.

       ${E_WHITE_FG}-c${E_RESET} file
              true if file exists and is a character special file.

       ${E_WHITE_FG}-d${E_RESET} file
              true if file exists and is a directory.

       ${E_WHITE_FG}-e${E_RESET} file
              true if file exists.

       ${E_WHITE_FG}-f${E_RESET} file
              true if file exists and is a regular file.

       ${E_WHITE_FG}-g${E_RESET} file
              true if file exists and has its setgid bit set.

       ${E_WHITE_FG}-h${E_RESET} file
              true if file exists and is a symbolic link.

       ${E_WHITE_FG}-k${E_RESET} file
              true if file exists and has its sticky bit set.

       ${E_WHITE_FG}-n${E_RESET} string
              true if length of string is non-zero.

       ${E_WHITE_FG}-o${E_RESET} option
              true if option named option is on.  option may be a single character, in which case it is a single letter option  name.   (See  the  section
              ‘Specifying Options’.)

              When no option named option exists, and the POSIX_BUILTINS option hasn’t been set, return 3 with a warning.  If that option is set, return 1
              with no warning.

       ${E_WHITE_FG}-p${E_RESET} file
              true if file exists and is a FIFO special file (named pipe).

       ${E_WHITE_FG}-r${E_RESET} file
              true if file exists and is readable by current process.

       ${E_WHITE_FG}-s${E_RESET} file
              true if file exists and has size greater than zero.

       ${E_WHITE_FG}-t${E_RESET} fd  true if file descriptor number fd is open and associated with a terminal device.  (note: fd is not optional)

       ${E_WHITE_FG}-u${E_RESET} file
              true if file exists and has its setuid bit set.

       ${E_WHITE_FG}-v${E_RESET} varname
              true if shell variable varname is set.

       ${E_WHITE_FG}-w${E_RESET} file
              true if file exists and is writable by current process.

       ${E_WHITE_FG}-x${E_RESET} file
              true  if  file  exists  and is executable by current process.  If file exists and is a directory, then the current process has permission to
              search in the directory.

       ${E_WHITE_FG}-z${E_RESET} string
              true if length of string is zero.

       ${E_WHITE_FG}-L${E_RESET} file
              true if file exists and is a symbolic link.

       ${E_WHITE_FG}-O${E_RESET} file
              true if file exists and is owned by the effective user ID of this process.

       ${E_WHITE_FG}-G${E_RESET} file
              true if file exists and its group matches the effective group ID of this process.

       ${E_WHITE_FG}-S${E_RESET} file
              true if file exists and is a socket.

       ${E_WHITE_FG}-N${E_RESET} file
              true if file exists and its access time is not newer than its modification time.

       file1 ${E_WHITE_FG}-nt${E_RESET} file2
              true if file1 exists and is newer than file2.

       file1 ${E_WHITE_FG}-ot${E_RESET} file2
              true if file1 exists and is older than file2.

       file1 ${E_WHITE_FG}-ef${E_RESET} file2
              true if file1 and file2 exist and refer to the same file.

       string ${E_WHITE_FG}=${E_RESET} pattern
       string ${E_WHITE_FG}==${E_RESET} pattern
              true if string matches pattern.  The two forms are exactly equivalent.  The ‘=’ form is the traditional shell syntax (and hence the only one
              generally used with the test and [ builtins); the ‘==’ form provides compatibility with other sorts of computer language.

       string ${E_WHITE_FG}!=${E_RESET} pattern
              true if string does not match pattern.

       string ${E_WHITE_FG}=~${E_RESET} regexp
              true if string matches the regular expression regexp.  If the option RE_MATCH_PCRE is set regexp is tested as a PCRE regular expression  us‐
              ing  the  zsh/pcre module, else it is tested as a POSIX extended regular expression using the zsh/regex module.  Upon successful match, some
              variables will be updated; no variables are changed if the matching fails.

              If the option BASH_REMATCH is not set the scalar parameter MATCH is set to the substring that matched the pattern and the integer parameters
              MBEGIN and MEND to the index of the start and end, respectively, of the match in string, such that if string is contained  in  variable  var
              the  expression  ‘\${var[\$MBEGIN,\$MEND]}’  is identical to ‘\$MATCH’.  The setting of the option KSH_ARRAYS is respected.  Likewise, the array
              match is set to the substrings that matched parenthesised subexpressions and the arrays mbegin and mend to the indices of the start and  end
              positions,  respectively, of the substrings within string.  The arrays are not set if there were no parenthesised subexpressions.  For exam‐
              ple, if the string ‘a short string’ is matched against the regular expression ‘s(...)t’, then (assuming the option KSH_ARRAYS  is  not  set)
              MATCH,  MBEGIN  and  MEND  are  ‘short’,  3 and 7, respectively, while match, mbegin and mend are single entry arrays containing the strings
              ‘hor’, ‘4’ and ‘6’, respectively.

              If the option BASH_REMATCH is set the array BASH_REMATCH is set to the substring that matched the pattern followed by  the  substrings  that
              matched parenthesised subexpressions within the pattern.

       string1 ${E_WHITE_FG}<${E_RESET} string2
              true if string1 comes before string2 based on ASCII value of their characters.

       string1 ${E_WHITE_FG}>${E_RESET} string2
              true if string1 comes after string2 based on ASCII value of their characters.

       exp1 ${E_WHITE_FG}-eq${E_RESET} exp2
              true  if  exp1  is  numerically equal to exp2.  Note that for purely numeric comparisons use of the ((...)) builtin described in the section
              ‘ARITHMETIC EVALUATION’ is more convenient than conditional expressions.

       exp1 ${E_WHITE_FG}-ne${E_RESET} exp2
              true if exp1 is numerically not equal to exp2.

       exp1 ${E_WHITE_FG}-lt${E_RESET} exp2
              true if exp1 is numerically less than exp2.

       exp1 ${E_WHITE_FG}-gt${E_RESET} exp2
              true if exp1 is numerically greater than exp2.

       exp1 ${E_WHITE_FG}-le${E_RESET} exp2
              true if exp1 is numerically less than or equal to exp2.

       exp1 ${E_WHITE_FG}-ge${E_RESET} exp2
              true if exp1 is numerically greater than or equal to exp2.

       ${E_WHITE_FG}(${E_RESET} exp ${E_WHITE_FG})${E_RESET}
              true if exp is true.

       ${E_WHITE_FG}!${E_RESET} exp  true if exp is false.

       exp1 ${E_WHITE_FG}&&${E_RESET} exp2
              true if exp1 and exp2 are both true.

       exp1 ${E_WHITE_FG}||${E_RESET} exp2
              true if either exp1 or exp2 is true.

 

${E_WHITE_FG}Dead Tilde${E_RESET}
Compose Key:<Right><Alt>

For á you press Compose+' then a
For € you press Compose+= then e

etc...

${E_WHITE_FG}Sudo Execution${E_RESET}
Not working: sudo echo 300 > /sys/block/md0/md/stripe_cache_size"

The "echo 300" is executed using sudo, which outputs 300 to stdout in the normal way. Then as your normal user, you are
trying to take that output and write to /sys/

Sudo isn't a magic command that elevates privileges for your whole command line. It takes the arguments you passed to
it and executes them as a program. Bash (which is running as a normal user) executes 'sudo echo 300' then takes that
output and tries to write it to a file. Note that the writing to the file is done by zsh which is running as the
normal user.

This should work:

sudo zsh -c "echo 300 > /sys/block/md0/md/stripe_cache_size"

sudo will execute zsh with higher privileges, and then that root zsh will execute the whole command.

${E_WHITE_FG}Redirect output of command${E_RESET}
<(command)

${E_WHITE_FG}Redirect output of command to another command${E_RESET}
< <(command)

As in:

while read X;do
	do_something_with_X
done< <(command)

${E_WHITE_FG}Redirect output of command to another command using a different file descriptor${E_RESET}

while IFS= read -ru3 LINE || [ -n "\$LINE" ]; do
	if [[ \${LINE:l} =~ "interfacesadded" && \${LINE:l} =~ "terminal" ]];then
		win_max terminal
	elif [[ \${LINE:l} =~ "startservicebyname" ]];then
		WAIT_FOR=deluge
	elif [[ \${LINE:l} =~ "desktop" ]];then
		if [[ -n \${WAIT_FOR} && \${LINE:l} =~ \${WAIT_FOR} ]];then
			win_max \${WAIT_FOR}
			WAIT_FOR=''
		fi
	fi
done 3< <( dbus-monitor | grep --line-buffered -i "startservicebyname\|desktop\|interfacesadded")
${E_WHITE_FG}See also ${E_CYAN_FG}REDIRECTION${E_RESET}


${E_WHITE_FG}Find command regex types${E_RESET}
find: valid -regextype values
-----------------------------
‘findutils-default’
‘ed’
‘emacs’
‘gnu-awk’
‘grep’
‘posix-awk’
‘awk’
‘posix-basic’
‘posix-egrep’
‘egrep’
‘posix-extended’
‘posix-minimal-basic’
‘sed’
-----------------------------

${E_WHITE_FG}Embed foreign script within zsh script${E_RESET}
inline_edit () {
	local PROMPT=${1}
	local CUR_VALUE=${2}
	local PERL_SCRIPT

	read -r -d '' PERL_SCRIPT <<'___EOF'
	use warnings;
	use strict;
	use Term::ReadLine;

	my $term = new Term::ReadLine 'gsq';
	$term->parse_and_bind("set editing-mode vi");

	system('sleep .1;xdotool key Home &');
	while ( defined ($_ = $term->readline($ARGV[0],$ARGV[1])) ) {
		print $_;
		exit;
	}
___EOF

perl -e "$PERL_SCRIPT" ${PROMPT} ${CUR_VALUE}
}

${E_WHITE_FG}Reformat text with long lines${E_RESET}
fold -w120 -s <(sed -e 's/^ *//g' -e 's/\t/ /g' -e 's/  / /g' zsh_redir.txt)

${E_WHITE_FG}Get last field with cut${E_RESET}
ZONES+=(\$(echo \${Z} | rev | cut -d'/' -f -2 | rev))

${E_WHITE_FG}Test for empty response from read -sk1 RESPONSE${E_RESET}
[[ \${RESPONSE} == \$'\x0A' ]] && exit

${E_MAGENTA_FG}Order of Operations ${E_WHITE_FG}PEMDAS${E_RESET}
The order of operations can be remembered by the acronym PEMDAS,
which stands for: parentheses, exponents, multiplication and division from left to right,
and addition and subtraction from left to right. If there are no parentheses or exponents,
start with multiplication and division from left to right.

${E_MAGENTA_FG}Unique HEAD lines in sorted list${E_RESET}
LAST_HEAD=?
for L in \${LIST};do
	HEAD=\${L:h}
	TAIL=\${L:t}
	[[ \${LAST_HEAD} != \${HEAD} ]] && echo "\n\${E_WHITE_FG}\${HEAD}\${E_RESET}"
	echo "\${TAIL}"
	LAST_HEAD=\${HEAD}
done

${E_MAGENTA_FG}ZSH Redirecting only stderr to a pipe.${E_RESET}
==========================================
exec 3>&1                              # Save current "value" of stdout.
ls -l 2>&1 >&3 3>&- | grep bad 3>&-    # Close fd 3 for 'grep' (but not 'ls').
#              ^^^^   ^^^^
exec 3>&-                              # Now close it for the remainder of the script.
==========================================

${E_MAGENTA_FG}Unique Lines (no sort)${E_RESET}
awk '!x[\${0}]++'

${E_MAGENTA_FG}Counting chars in a string${E_RESET}
MATCHED=\$(awk '{print gsub(/\|/,"")}' <<<\${STRING}) #count pipe delimiters

${E_MAGENTA_FG}Mounting Notes${E_RESET}
Remount / as RW
mount -o rw,remount /

Mount Mac drive as RW
sudo mount -t hfsplus -o force,rw /dev/sdb2 /media/kmiller/MAC_DRIVE

${E_WHITE_FG}File to variable ${E_RESET}
var=\$(< file)

${E_WHITE_FG}Command to variables with read${E_RESET}
read -r var1 var2 var3 < <(COMMAND)
Ex: read -r WEEK YEAR MONTH DAY HOUR MINUTE SECOND < <(date +'%W %Y %m %d %H %M %S')

${E_WHITE_FG}Using Command Substitution and the Here-String${E_RESET}
read -r var1 var2 var3 <<< "101 202 303"
Ex: read -r WEEK YEAR MONTH DAY HOUR MINUTE SECOND <<< "$(date +'%W %Y %m %d %H %M %S')"

${E_WHITE_FG}Changing the Delimiter${E_RESET}
IFS='@' read -r WEEK_NO DATE_TIME WEEK_DAY <<< "$(date +'%W@%F %T@%A')"

${E_WHITE_FG}Using an Array${E_RESET}
readarray -d' ' -t ARR <<< "$(date +'%W %Y %m %d %H %M %S')"
The default delimiter used by the readarray command is a newline character. 
Change the delimiter using the -d option.

${E_MAGENTA_FG}ARRAYS${E_RESET}

${E_WHITE_FG}Regular arrays${E_RESET}
typeset -a TEST
TEST=("one" "two" "three times") #assignment

${E_WHITE_FG}To get index:${E_RESET}
for i in \${arr}; do
	echo "index \${arr[(ie)\${i}]}";
done

${E_WHITE_FG}To delete an element from a regular array: ${E_RESET}
TEST[N]=() #method 1

TEST=("\${(@)TEST:#two}") #method 2

TEST=(\${TEST[@]/#%three times}) #method 2a
The #% prefix forces whole word matching.  Very important if the elements contain spaces!

${E_WHITE_FG}To test for element in array${E_RESET}
foo=(a b c)
[[ \${foo[(i)b]} -le \${#foo} ]] && echo yes || echo no

You can see what you get out of those two expressions by simply doing:

echo \${foo[(i)a]} \${#foo}
1 3

echo \${foo[(i)b]} \${#foo}
2 3

echo \${foo[(i)c]} \${#foo}
3 3

echo \${foo[(i)d]} \${#foo}
4 3

Method 2: 
if ((\${array}[(Ie)\${value}])); then
	echo "HIT"
fi

Searching for text

Array snippet - elements 14:20

5013:13:126:miles
5014:14:126:miles
5017:17:126:miles:last
5088:8:128:miles:last
5054:14:127:miles:last
5250:10:132:miles
5276:36:132:miles

echo ${LIST[(r)*last]} 5017:17:126:miles:last
echo ${LIST[(R)*last]} 5054:14:127:miles:last
echo ${LIST[(i)*last]} 16
echo ${LIST[(I)*last]} 18


${E_WHITE_FG}To prepend an element in array${E_RESET}
ARRAY=('PREPEND' \${ARRAY[@]})

${E_WHITE_FG}Associative arrays${E_RESET}
typeset -A ARR
ARR[key]=value #assignment

\${(k)ARR} = access keys
\${(v)ARR} = access values

${E_WHITE_FG}To delete elements from a associative array:${E_RESET}
unset "associative_array[key]"

And with an associative array such as:

typeset -A h
h[foo]=bar
h[empty]=""

To delete the empty ones:

h=("\${(kv@)h[(R)?*]}")

${E_WHITE_FG}Word Splitting${E_RESET}
To supress: LIST=("\${(@f)\$(command)}") 
LIST = array of command results i.e. LIST = ( "\${ (@f) \$(command) }" )

To force: \${=LIST}

var="two words"
If you assign an element directly: DIR+=\${var}, no splitting takes place

${E_WHITE_FG}Reverse Lookups${E_RESET}
\${(k)ARRAY[(r)\${VALUE}]} reverse lookup

${E_WHITE_FG}zsh${E_RESET}
to reverse keys <=> values
In zsh, where the primary syntax for defining a hash is hash=(k1 v1 k2 v2...) like in perl

keys=( "\${(@k)hash}" )
values=( "\${(@v)hash}" )

typeset -A reversed
reversed=( "\${(@)values:^keys}" ) # array zipping operator
Or using the Oa parameter expansion flag to reverse the order of the key+value list:

typeset -A reversed
reversed=( "\${(@kvOa)hash}" )

or using a loop:
for k v ( "\${(@kv}hash}" ) reversed[\$v]=\$k

The @ and double quotes is to preserve empty keys and values 

As the expansion of elements in associative arrays is in no particular order, if 
several elements of \$hash have the same value (which will end up being a key in 
\$reversed), you can't tell which key will be used as the value in \$reversed.

${E_WHITE_FG}loop${E_RESET}
You'd use the R hash subscript flag to get elements based on value instead of key, 
combined with e for exact (as opposed to wildcard) match, and then get the keys for 
those elements with the k parameter expansion flag:

for value ("\${(@u)hash}")
  print -r "elements with '\$value' as value: \${(@k)hash[(Re)\$value]}"

${E_WHITE_FG}perl approach${E_RESET}
zsh (contrary to ksh93) doesn't support arrays of arrays, but its variables can contain 
the NUL byte, so you could use that to separate elements if the elements don't otherwise 
contain NUL bytes, or use the \${(q)var} / \${(Q)\${(z)var}} to encode/decode a list using quoting.

typeset -A seen
for k v ("\${(@kv)hash}")
  seen[\$v]+=" \${(q)k}"

for k v ("\${(@kv)seen}")
  print -r "elements with '\$k' as value: \${(Q@)\${(z)v}}"

${E_WHITE_FG}ksh93${E_RESET}
ksh93 was the first shell to introduce associative arrays in 1993. The syntax for assigning 
values as a whole means it's very difficult to do it programmatically contrary to zsh, but 
at least it's somewhat justified in ksh93 in that ksh93 supports complex nested data structures.

In particular, here ksh93 supports arrays as values for hash elements, so you can do:

typeset -A seen
for k in "\${!hash[@]}"; do
  seen[\${hash[\$k]}]+=("\$k")
done

for k in "\${!seen[@]}"; do
  print -r "elements with '\$k' as value \${x[\$k][@]}"
done

${E_WHITE_FG}bash${E_RESET}
bash added support for associative arrays decades later, copied the ksh93 syntax, but not the other 
advanced data structures, and doesn't have any of the advanced parameter expansion operators of zsh.
(note that bash associative arrays don't support empty keys). 

In bash, you could use the quoted list approach mentioned in the zsh using printf %q or with newer 
versions \${var@Q}.

typeset -A seen
for k in "\${!hash[@]}"; do
  printf -v quoted_k %q "\$k"
  seen[\${hash[\$k]}]+=" \$quoted_k"
done

for k in "\${!seen[@]}"; do
  eval "elements=(\${seen[\$k]})"
  echo -E "elements with '\$k' as value: \${elements[@]}"
done

Since bash associative arrays don't support the empty value as a key, it won't 
work if some of \$hash's values are empty. You could choose to replace the empty string with some place 
holder like <EMPTY> or prefix the key with some character that you'd later strip for display.


${E_WHITE_FG}Some common array flags${E_RESET}
\${(k)ARRAY} = keys (assoc array)
\${(v)ARRAY} = values (assoc array)
\${(kv)ARRAY} = keys and values (assoc array)
\${(o)ARRAY} = lex sort asc
\${(on)ARRAY} = numeric element sort asc
\${(On)ARRAY} = numeric element sort desc
\${(O)ARRAY} = lex sort desc
\${(a)ARRAY} = index sort
\${(Oa)ARRAY} = index sort desc
\${(q)ARRAY} = quoted elements
\${(Q)ARRAY} = strip quoted elements
\${(L)ARRAY} = lower case elements
\${(U)ARRAY} = upper case elements
\${(C)ARRAY} = upper case first letter of elements
\${(u)ARRAY} = unique elements

${E_WHITE_FG}Some useful gymnastics${E_RESET}
\${ARRAY[(ie)\${ELEMENT}]} = return index of element

${E_MAGENTA_FG}Some common file name modifiers:${E_RESET}
${E_CYAN_FG}Example${E_RESET}:${E_WHITE_FG}VAR=/one/two/three/xxx.txt${E_RESET}
\${VAR:t} = xxx.txt, the filename w/o path like basename
\${VAR:h} = /one/two/three, the path like dirname
\${VAR:e} = txt, the file extension
\${VAR:r} = /one/two/three/xxx, the filename without extension
\${VAR:t:r} = xxx, the filename without path or extension by combining flags

${E_WHITE_FG}Substring matching:${E_RESET}

${E_MAGENTA_FG}To match a string with a substring, we can use:${E_RESET}
\${str#substr} Deletes shortest match of \${substr} from front of \${str}
\${str##substr} Deletes longest match of \${substr} from front of \${str}

${E_WHITE_FG}WORD='hello - world - how - are - you'${E_RESET}

${E_MAGENTA_FG}For example: remove part before 'how*', or o*${E_RESET}

\${WORD%how*} == 'hello - world - '
\${WORD%o*} == 'hello - world - how - are - y'
\${WORD%%o*} == 'hell'

${E_MAGENTA_FG}Or remove the part after '* - '${E_RESET}

\${WORD#* - } = 'world - how - are - you'
\${WORD##* - } = 'you'
)

tip_zsh_EOF_1

local VAR=/one/two/three/xxx.txt
echo "Live Code..."
echo "${E_GREEN_FG}\${VAR:t} -> ${E_WHITE_FG}${VAR:t}${E_RESET}"
echo "${E_GREEN_FG}\${VAR:h} -> ${E_WHITE_FG}${VAR:h}${E_RESET}"
echo "${E_GREEN_FG}\${VAR:e} -> ${E_WHITE_FG}${VAR:e}${E_RESET}"
echo "${E_GREEN_FG}\${VAR:r} -> ${E_WHITE_FG}${VAR:r}${E_RESET}"
echo "${E_GREEN_FG}\${VAR:t:r} -> ${E_WHITE_FG}${VAR:t:r}${E_RESET}\n"

cat << tip_zsh_EOF_2
${E_WHITE_FG}Word Splitting${E_RESET}
\${(s/:/)PATH}

${E_MAGENTA_FG}Tests${E_RESET}
-----
(( \${1} )) && echo "\${1} is not missing" || echo "\${1} is missing"
(( \${2} )) && echo "\${2} is not missing" || echo "\${2} is missing"

[[ \${1} -eq 1 ]] && echo "\${1} is 1"
[[ \${1} -eq 1 ]] && echo "\${1} is 1" || echo "\${1} not 1"
[[ \${1} -eq 1 && \${2} -eq 1 ]] && echo "\${1} AND \${2} are 1" || echo "\${1} not 1 OR \${2} not 1"

${E_WHITE_FG}Testing STDIN, STDOUT, STDDERR${E_RESET}
if [[ -t 0 ]];then
	echo "input is from terminal"
else
	echo "input is redirected"
fi

if [[ -t 1 ]];then
	echo "output is to terminal"
else
	echo "output is redirected"
fi

if [[ -t 2 ]];then
	echo "stderr goes to terminal"
else
	echo "stderr is redirected"
fi

${E_WHITE_FG}Testing for piped input${E_RESET}
PIPE=false
if [[ ! -t 0 ]];then
	PIPE=true
fi
if [[ \${PIPE} == "false" ]];then
	echo "Args: \${@}"
else
	{ read a; echo "Piped Args:\${a}" } 
fi

${E_WHITE_FG}Example Output${E_RESET}
--------------
echo "xxx.txt" | testit -s A B
Args: -s A B
Piped Args:xxx.txt

${E_MAGENTA_FG}String Indexing${E_RESET}
---------------
$ a=abcdefghijklmnopqrstuvwxyz b=xyzd
$ echo \${a[(i)[\${b}]]}
4

With i, you get the index of the first match 
(or one plus the length of the haystack if 
there's no match). With I instead, you get 
the last match (or 0 if there's no match).

${E_MAGENTA_FG}Increment Operator${E_RESET}
------------------
for i in {1..7}
do
	   #stuff
done

${E_MAGENTA_FG}DEBUG Arrays${E_RESET}

funcfiletrace
-------------
This array contains the absolute line numbers and corresponding file names for the point where 
the current function, sourced file, or (if EVAL_LINENO is set) eval command was called. The 
array is of the same length as funcsourcetrace and functrace, but differs from funcsourcetrace 
in that the line and file are the point of call, not the point of definition, and differs 
from functrace in that all values are absolute line numbers in files, rather than relative to 
the start of a function, if any.

funcsourcetrace
---------------
This array contains the file names and line numbers of the points where the functions, sourced 
files, and (if EVAL_LINENO is set) eval commands currently being executed were defined. The 
line number is the line where the 'function name' or 'name ()' started. In the case of an 
autoloaded function the line number is reported as zero. The format of each element is 
filename:lineno.

For functions autoloaded from a file in native zsh format, where only the body of the function 
occurs in the file, or for files that have been executed by the source or '.' builtins, the 
trace information is shown as filename:0, since the entire file is the definition. The source 
file name is resolved to an absolute path when the function is loaded or the path to it
otherwise resolved.

Most users will be interested in the information in the funcfiletrace array instead.

funcstack
---------
This array contains the names of the functions, sourced files, and (if EVAL_LINENO is set) eval 
commands. currently being executed. The first element is the name of the function using the 
parameter.

The standard shell array zsh_eval_context can be used to determine the type of shell construct 
being executed at each depth: note, however, that is in the opposite order, with the most 
recent item last, and it is more detailed, for example including an entry for toplevel, the main 
shell code being executed either interactively or from a script, which is not present in 
${funcstack}.

functrace
---------
This array contains the names and line numbers of the callers corresponding to the functions 
currently being executed. The format of each element is name:lineno. Callers are also shown for 
sourced files; the caller is the point where the source or '.' command was executed.


${E_WHITE_FG}PARAMETER EXPANSION${E_RESET}
-------------------
       The  character  '\$'  is	used to introduce parameter expansions.  See zshparam(1) for a description of
       parameters, including arrays, associative arrays, and sub‐ script notation to access individual array
       elements.

       Note in particular the fact that words of unquoted parameters are not automatically split on whitespace
       unless the option SH_WORD_SPLIT is set; see references to this option below for more details.  This is an
       important difference from other shells.

       In  the	expansions  discussed  below that require a pattern, the form of the pattern is the same as that
       used for filename generation; see the section 'Filename Generation'.  Note that these patterns, along
       with the replacement text of any substitutions, are themselves subject to parameter  expansion,	command
       substitu‐ tion, and arithmetic expansion.  In addition to the following operations, the colon modifiers
       described in the section 'Modifiers' in the section 'History Expan‐ sion' can be applied:  for example,
       \${i:s/foo/bar/} performs string substitution on the expansion of parameter \${i}.

       In the following descriptions, 'word' refers to a single word substituted on the command line, not necessarily
       a space delimited  word.   With	default  options, after the assignments:

	      array=("first word" "second word") scalar="only word"

       then  \${array}  substitutes  two  words,  'first  word'  and 'second word', and \${scalar} substitutes a single
       word 'only word'.  This may be modified by explicit or implicit word-splitting, however.  The full rules
       are complicated and are noted at the end.

       \${name}
	      The value, if any, of the parameter name is substituted.	The braces are required if the expansion is
	      to be followed by a  letter,  digit,  or	underscore that  is not to be interpreted as part of name.
	      In addition, more complicated forms of substitution usually require the braces to be present;
	      exceptions, which only apply if the option KSH_ARRAYS is not set, are a single subscript or any
	      colon modifiers appearing after the name, or  any  of  the  characters '^', '=', '~', '#' or '+'
	      appearing before the name, all of which work with or without braces.

	      If  name is an array parameter, and the KSH_ARRAYS option is not set, then the value of each element
	      of name is substituted, one element per word.  Other‐ wise, the expansion results in one word only;
	      with KSH_ARRAYS, this is the first element of an array.  No field splitting is done on the result
	      unless the SH_WORD_SPLIT option is set.  See also the flags = and s:string:.

       \${+name}
	      If name is the name of a set parameter '1' is substituted, otherwise '0' is substituted.

       \${name-word} \${name:-word}
	      If name is set, or in the second form is non-null, then substitute its value; otherwise substitute word.
	      In the second form name may be omitted, in which case word is always substituted.

       \${name+word} \${name:+word}
	      If name is set, or in the second form is non-null, then substitute word; otherwise substitute nothing.

       \${name=word} \${name:=word} \${name::=word}
	      In the first form, if name is unset then set it to word; in the second form, if name is unset or
	      null then set it to word; and in the third form, uncondi‐ tionally set name to word.  In all forms,
	      the value of the parameter is then substituted.

       \${name?word} \${name:?word}
	      In  the first form, if name is set, or in the second form if name is both set and non-null, then
	      substitute its value; otherwise, print word and exit from the shell.  Interactive shells instead
	      return to the prompt.  If word is omitted, then a standard message is printed.

       In any of the above expressions that test a variable and substitute an alternate word, note that you
       can use standard shell quoting in the word value  to  selec‐ tively override the splitting done by the
       SH_WORD_SPLIT option and the = flag, but not splitting by the s:string: flag.

       In the following expressions, when name is an array and the substitution is not quoted, or if the '(@)'
       flag or the name[@] syntax is used, matching and replace‐ ment is performed on each array element separately.


	      If the pattern matches the beginning of the value of name, then substitute the value of name with
	      the matched portion deleted; otherwise, just  substitute the value of name.  In the first form, the
	      smallest matching pattern is preferred; in the second form, the largest matching pattern is preferred.

       \${name%pattern} \${name%%pattern}
	      If  the  pattern	matches the end of the value of name, then substitute the value of name with
	      the matched portion deleted; otherwise, just substitute the value of name.  In the first form, the
	      smallest matching pattern is preferred; in the second form, the largest matching pattern is preferred.

       \${name:#pattern}
	      If the pattern matches the value of name, then substitute the empty string; otherwise, just substitute
	      the value of name.  If name is an array the  match‐ ing array elements are removed (use the '(M)'
	      flag to remove the non-matched elements).

       \${name:|arrayname}
	      If  arrayname  is  the name (N.B., not contents) of an array variable, then any elements contained in
	      arrayname are removed from the substitution of name.  If the substitution is scalar, either because
	      name is a scalar variable or the expression is quoted, the elements of arrayname are instead tested
	      against the entire expression.

       \${name:*arrayname}
	      Similar  to  the preceding substitution, but in the opposite sense, so that entries present in both
	      the original substitution and as elements of arrayname are retained and others removed.

       \${name:^arrayname} \${name:^^arrayname}
	      Zips two arrays, such that the output array is twice as long as the shortest (longest for ':^^')
	      of name and arrayname, with  the	elements  alternatingly being picked from them. For ':^', if one
	      of the input arrays is longer, the output will stop when the end of the shorter array is reached.  Thus,

		     a=(1 2 3 4); b=(a b); print \${a:^b}

	      will output '1 a 2 b'.  For ':^^', then the input is repeated until all of the longer array has been
	      used up and the above will output '1 a 2 b 3 a 4 b'.

	      Either  or  both	inputs	may be a scalar, they will be treated as an array of length 1 with the scalar
	      as the only element. If either array is empty, the other array is output with no extra elements inserted.

	      Currently the following code will output 'a b' and '1' as two separate elements, which can be
	      unexpected. The second print  provides  a  workaround  which should continue to work if this is changed.

		     a=(a b); b=(1 2); print -l "\${a:^b}"; print -l "\${\${a:^b}}"

       \${name:offset} \${name:offset:length}
	      This  syntax  gives effects similar to parameter subscripting in the form \${name}[start,end], but is
	      compatible with other shells; note that both offset and length are interpreted differently from the
	      components of a subscript.

	      If offset is non-negative, then if the variable name is a scalar substitute the contents starting
	      offset  characters  from	the  first  character  of  the string,	and if name is an array substitute
	      elements starting offset elements from the first element.  If length is given, substitute that many
	      characters or elements, otherwise the entire rest of the scalar or array.

	      A positive offset is always treated as the offset of a character or element in name from the first
	      character or element of the array  (this	is  different from native zsh subscript notation).  Hence 0
	      refers to the first character or element regardless of the setting of the option KSH_ARRAYS.

	      A negative offset counts backwards from the end of the scalar or array, so that -1 corresponds to
	      the last character or element, and so on.

	      When  positive,  length  counts  from the offset position toward the end of the scalar or array.
	      When negative, length counts back from the end.  If this results in a position smaller than offset,
	      a diagnostic is printed and nothing is substituted.

	      The option MULTIBYTE is obeyed, i.e. the offset and length count multibyte characters where appropriate.

	      offset and length undergo the same set of shell substitutions as for scalar assignment; in addition,
	      they  are  then  subject	to  arithmetic	evaluation.  Hence, for example

		     print \${foo:3} print \${foo: 1 + 2} print \${foo:\$(( 1 + 2))} print \${foo:\$(echo 1 + 2)}

	      all have the same effect, extracting the string starting at the fourth character of \${foo} if the
	      substitution would otherwise return a scalar, or the array starting at the fourth element if \${foo}
	      would return an array.  Note that with the option KSH_ARRAYS \${foo} always returns a scalar (regardless
	      of the use of the offset syntax) and a form such as \${foo[*]:3} is required to extract elements of
	      an array named foo.

	      If  offset  is  negative,  the - may not appear immediately after the : as this indicates the
	      \${name:-word} form of substitution.  Instead, a space may be inserted before the -.  Furthermore,
	      neither offset nor length may begin with an alphabetic character or & as these are  used	to
	      indicate	history-style modifiers.  To substitute a value from a variable, the recommended approach
	      is to precede it with a \$ as this signifies the intention (parameter substitu‐ tion can easily be
	      rendered unreadable); however, as arithmetic substitution is performed, the expression \${var: offs}
	      does work,  retrieving  the  offset from \${offs}.

	      For  further  compatibility with other shells there is a special case for array offset 0.  This usually
	      accesses the first element of the array.	However, if the substitution refers to the positional
	      parameter array, e.g. \${@} or \$*, then offset 0 instead refers to \${0}, offset 1 refers to \${1},  and
	      so  on.	In other words, the positional parameter array is effectively extended by prepending \${0}.
	      Hence \${*:0:1} substitutes \${0} and \${*:1:1} substitutes \${1}.

       \${name/pattern/repl} \${name//pattern/repl} \${name:/pattern/repl}
	      Replace  the  longest possible match of pattern in the expansion of parameter name by string repl.
	      The first form replaces just the first occurrence, the second form all occurrences, and the third
	      form replaces only if pattern matches the entire string.	Both pattern and repl are  subject  to
	      double-quoted substitution,  so  that expressions like \${name/\${opat}/\${npat}} will work, but obey
	      the usual rule that pattern characters in \${opat} are not treated specially unless either the option
	      GLOB_SUBST is set, or \${opat} is instead substituted as \${~opat}.

	      The pattern may begin with a '#', in which case the pattern must match at the start of the string,
	      or '%', in which case it must match at the end  of  the string, or '#%' in which case the pattern
	      must match the entire string.  The repl may be an empty string, in which case the final '/' may also
	      be omitted.  To quote the final '/' in other cases it should be preceded by a single backslash;
	      this is not necessary if the '/' occurs inside a substituted parameter.  Note also that the '#',
	      '%' and '#%' are not active if they occur inside a substituted parameter, even at the start.

	      If, after quoting rules apply, \${name} expands to an array, the replacements act on each element
	      individually.  Note also the effect of the I and S param‐ eter expansion flags below; however,
	      the flags M, R, B, E and N are not useful.

	      For example,

		     foo="twinkle twinkle little star" sub="t*e" rep="spy" print \${foo//\${~sub}/\${rep}} print
		     \${(S)foo//\${~sub}/\${rep}}

	      Here, the '~' ensures that the text of \${sub} is treated as a pattern rather than a plain string.
	      In the first case, the longest match for t*e  is	substi‐ tuted and the result is 'spy star',
	      while in the second case, the shortest matches are taken and the result is 'spy spy lispy star'.

       \${#spec}
	      If  spec	is  one of the above substitutions, substitute the length in characters of the result
	      instead of the result itself.  If spec is an array expres‐ sion, substitute the number of elements
	      of the result.  This has the side-effect that joining is skipped even in quoted  forms,  which  may
	      affect  other sub-expressions in spec.  Note that '^', '=', and '~', below, must appear to the left of
	      '#' when these forms are combined.

	      If  the option POSIX_IDENTIFIERS is not set, and spec is a simple name, then the braces are optional;
	      this is true even for special parameters so e.g. \${#}- and \${#}* take the length of the string \$- and
	      the array \$* respectively.  If POSIX_IDENTIFIERS is set, then braces are required for the # to be
	      treated  in this fashion.

       \${^spec}
	      Turn  on the RC_EXPAND_PARAM option for the evaluation of spec; if the '^' is doubled, turn it off.
	      When this option is set, array expansions of the form foo\${xx}bar, where the parameter xx is set
	      to (a b c), are substituted with 'fooabar foobbar foocbar' instead of the default 'fooa b cbar'.
	      Note that  an empty array will therefore cause all arguments to be removed.

	      Internally,  each such expansion is converted into the equivalent list for brace expansion.  E.g.,
	      \${^var} becomes {\${var}[1],\${var}[2],...}, and is processed as described in the section 'Brace Expansion'
	      below: note, however, the expansion happens immediately, with any explicit brace expansion happening
	      later.  If word splitting is also in effect the \${var}[N] may themselves be split into different
	      list elements.

       \${=spec}
	      Perform  word splitting using the rules for SH_WORD_SPLIT during the evaluation of spec, but regardless
	      of whether the parameter appears in double quotes; if the '=' is doubled, turn it off.  This forces
	      parameter expansions to be split into separate words before substitution, using IFS as a delimiter.
	      This is done by default in most other shells.

	      Note  that  splitting  is  applied  to  word in the assignment forms of spec before the assignment
	      to name is performed.  This affects the result of array assignments with the A flag.

       \${~spec}
	      Turn on the GLOB_SUBST option for the evaluation of spec; if the '~' is doubled, turn it off.  When this
	      option is set,  the  string  resulting  from  the expansion  will be interpreted as a pattern anywhere
	      that is possible, such as in filename expansion and filename generation and pattern-matching contexts
	      like the right hand side of the '=' and '!=' operators in conditions.

	      In nested substitutions, note that the effect of the ~ applies to the result of the current level of
	      substitution.  A surrounding pattern operation on the result  may  cancel it.  Hence, for example,
	      if the parameter foo is set to *, \${~foo//\*/*.c} is substituted by the pattern *.c, which may be
	      expanded by filename generation, but \${\${~foo}//\*/*.c} substitutes to the string *.c, which will
	      not be further expanded.

       If a \${...} type parameter expression or a \$(...) type command substitution is used in place of name
       above, it is expanded first and the result is used as if  it were  the  value  of  name.   Thus	it  is
       possible to perform nested operations:  \${\${foo#head}%tail} substitutes the value of \${foo} with both 'head'
       and 'tail' deleted.  The form with \$(...) is often useful in combination with the flags described next;
       see the examples below.	Each name or nested \${...} in  a  parameter expansion may also be followed by a
       subscript expression as described in Array Parameters in zshparam(1).

       Note  that  double  quotes  may appear around nested expressions, in which case only the part inside is
       treated as quoted; for example, \${(f)"\$(foo)"} quotes the result of \$(foo), but the flag '(f)' (see below)
       is applied using the rules for unquoted expansions.  Note further that quotes are themselves nested in
       this con‐ text;  for  example,  in  "\${(@f)"\$(foo)"}",  there are two sets of quotes, one surrounding
       the whole expression, the other (redundant) surrounding the \$(foo) as before.

${E_WHITE_FG}Parameter Expansion Flags${E_RESET}
-------------------------
       If the opening brace is directly followed by an opening parenthesis, the string up to the matching closing
       parenthesis will be taken as  alist  of  flags.   In cases  where repeating a flag is meaningful, the
       repetitions need not be consecutive; for example, '(q%q%q)' means the same thing as the more readable
       '(%%qqq)'.  The following flags are supported:

       #      Evaluate the resulting words as numeric expressions and output the characters corresponding to the resulting integer.  
              Note that this form is entirely distinct from use of the # without parentheses.

              If the MULTIBYTE option is set and the number is greater than 127 (i.e. not an ASCII character) it is treated as a Unicode character.

       %      Expand  all % escapes in the resulting words in the same way as in prompts (see EXPANSION OF PROMPT SEQUENCES 
              in zshmisc(1)). If this flag is given twice, full prompt expansion is done on the resulting words, depending on the 
              setting of the PROMPT_PERCENT, PROMPT_SUBST and PROMPT_BANG options.

       @      In double quotes, array elements are put into separate words.  E.g., '"\${(@)foo}"' is equivalent to '"\${foo[@]}"' and 
              '"\${(@)foo[1,2]}"' is the  same  as '"\${foo}[1]" "\${foo}[2]"'.  This is distinct from field splitting by the f, s or z flags, 
              which still applies within each array element.

       A      Convert  the  substitution  into an array expression, even if it otherwise would be scalar.  This has lower precedence than subscripting, 
              so one level of nested expansion is required in order that subscripts apply to array elements.  Thus \${\${(A)name}[1]} yields the full 
              value of name when name is scalar.

              This assigns an array parameter with '\${...=...}', '\${...:=...}' or '\${...::=...}'.  If this flag is repeated (as in 'AA'), assigns an  
              associative array parameter. Assignment is made before sorting or padding; if field splitting is active, the word part is split before 
              assignment. The name part may be a subscripted range for ordinary arrays; when assigning an associative array,the  word  part  must
              be converted  to  an  array,  for  example  by  using '\${(AA)=name=...}' to activate field splitting.

              Surrounding  context  such  as  additional  nesting  or use of the value in a scalar assignment may cause the array to be joined back 
              into a single string again.

       a      Sort in array index order; when combined with 'O' sort in reverse array index order.  Note that 'a' is therefore equivalent to the  
              default but  'Oa'  is useful for obtaining an array's elements in reverse order.

       b      Quote  with  backslashes only  characters  thatare special to pattern matching. This is useful when the contents of the variable are to 
              be tested using GLOB_SUBST, including the \${~...} switch.  Quoting using one of the q family of flags does not work for this purpose 
              since quotes are not stripped from non-pattern  characters  by  GLOB_SUBST.   In other words,

              pattern=\${(q)str} [[ \${str} = \${~pattern} ]]

              works if \${str} is 'a*b' but not if it is 'a b', whereas

              pattern=\${(b)str} [[ \${str} = \${~pattern} ]]

              is always true for any possible value of \${str}.

       c      With  \${#name},  count the total number of characters in an array, as if the elements were concatenated with spaces between them.  
              This is not a true join of the array, so other expressions used with this flag may have an effect on the elements of the array before 
              it is counted.

       C      Capitalize the resulting words.  'Words' in this case refers to sequences of alphanumeric characters separated by non-alphanumerics,
              not  to  words that result from field splitting.

       D      Assume  the  string  or  array  elements contain directories and attempt to substitute the leading part of these by names. The remainder 
              of the path (the whole of it if the leading part was not substituted) is then quoted so that the whole string can be used as a shell 
              argument.  This is the reverse of  '~' substitution:  see the section FILENAME EXPANSION below.

       e      Perform  parameter  expansion,  command substitution and arithmetic expansion on the result. Such expansions can be nested but too deep
              recursion may have unpredictable effects.

       f      Split the result of the expansion at newlines. This is a shorthand for 'ps:\n:'.

       F      Join the words of arrays together using newline as a separator.  This is a shorthand for 'pj:\n:'.

 g:opts:      Process escape sequences like the echo builtin when no options are given (g::).  With the o option, octal escapes don't take a leading 
              zero.With  the  c option, sequences like '^X' are also processed.  With the e option, processes '\M-t' and similar sequences like the 
              print builtin.  With both of the o and e options, behaves like the print builtin except that in none of these modes is '\c' interpreted.

       i      Sort case-insensitively.May be combined with 'n' or 'O'.

       k      If name refers to an associative array, substitute the keys (element names) rather than the values of the elements. Used with subscripts 
              (including ordinary  arrays), force indices or keys to be substituted even if the subscript form refers to values. However,this flag may 
              not be combined with subscript ranges. With the KSH_ARRAYS option a subscript '[*]' or '[@]' is needed to operate on the whole array, as usual.

       L      Convert all letters in the result to lower case.

       n      Sort decimal integers numerically; if the first differing characters of two test strings are not digits, sorting is lexical. Integers 
              with more  initial zeroes  are  sorted  before those with fewer or none.  Hence the array 'foo1 foo02 foo2 foo3 foo20 foo23' is sorted 
              into the order shown.  May be combined with 'i' or 'O'.

       o      Sort the resulting words in ascending order; if this appears on its own  the  sorting  is  lexical and  case-sensitive  (unless  the  
              locale  renders  it case-insensitive).  Sorting in ascending order is the default for other forms of sorting, so this is ignored if 
              combined with 'a', 'i' or 'n'.

       O      Sort the resulting words in descending order; 'O' without 'a', 'i' or 'n' sorts in reverse lexical order.  May be combined with 
              'a', 'i' or 'n' to reverse the order of sorting.

       P      This forces the value of the parameter name to be interpreted as a further parameter name, whose value will be used where appropriate.   
              Note  that  flags set with one of the typeset family of commands (in particular case transformations) are not applied to the value of 
              name used in this fashion.

              If  used with a nested parameter or command substitution, the result of that will be taken as a parameter name in the same way.  
              For example, if you have 'foo=bar' and 'bar=baz', the strings \${(P)foo}, \${(P)\${foo}}, and \${(P)\$(echo bar)} will be expanded 
              to 'baz'.

              Likewise, if the reference is itself nested, the expression with the flag is treated as if it were directly replaced by theparameter
              name.   It  is  an error  if  this  nested  substitution produces an array with more than one word.  For example, if 'name=assoc' where 
              the parameter assoc is an associative array, then '\${\${(P)name}[elt]}' refers to the element of the associative subscripted 'elt'.

       q      Quote characters that are special to the shell in the resulting words with backslashes; unprintable or invalid characters are  quoted  
              using  the  \$'\NNN' form, with separate quotes for each octet.

              If  thisflag  is  given twice, the resulting words are quoted in single quotes and if it is given three times, the words are quoted in 
              double quotes; in these forms no special handling of unprintable or invalid characters is attempted.  If the flag is given four times, 
              the words are quoted in single quotes preceded  by  a \$.  Note that in all three of these forms quoting is done unconditionally, even 
              if this does not change the way the resulting string would be interpreted by the shell.

              If a q- is given (only a single q may appear), a minimal form of single quoting is used that only quotes the string if needed to protect  
              special  charac‐ ters.Typically this form gives the most readable output.

              If  a  q+ is given, an extended form of minmal quoting is used that causes unprintable characters to be rendered using \$'...'.  This 
              quoting is similar to that used by the output of values by the typeset family of commands.

       Q      Remove one level of quotes from the resulting words.

       t      Use a string describing the type of the parameter where the value of the parameter would usually appear. This string consists  of  keywords  
              separated  by hyphens ('-'). The first keyword in the string describes the main type, it can be one of 'scalar', 'array', 'integer', 'float' 
              or 'association'. The other keywords describe the type in more detail:

              local  for local parameters

              left   for left justified parameters
              
              right_blanks for right justified parameters with leading blanks
              
              right_zeros for right justified parameters with leading zeros
              
              lower  for parameters whose value is converted to all lower case when it is expanded
              
              upper  for parameters whose value is converted to all upper case when it is expanded
              
              readonly for readonly parameters
              
              tag    for tagged parameters
              
              export for exported parameters
              
              unique for arrays which keep only the first occurrence of duplicated values
              
              hide   for parameters with the 'hide' flag
              
              hideval for parameters with the 'hideval' flag
              
              special for special parameters defined by the shell

       u      Expand only the first occurrence of each unique word.

       U      Convert all letters in the result to upper case.

       v      Used with k, substitute (as two consecutive words) both the key and the value of each associative array element.  
              Used with subscripts, force values to be substituted even if the subscript form refers to indices or keys.

       V      Make any special characters in the resulting words visible.

       w      With \${#name}, count words in arrays or strings; the s flag may be used to set a word delimiter.

       W      Similar to w with the difference that empty words between repeated delimiters are also counted.

       X      With  this  flag,  parsing  errors  occurring with the Q, e and # flags or the pattern matching forms such as '\${name#pattern}' 
              are reported.  Without the flag, errors are silently ignored.

       z      Split the result of the expansion into words using shell parsing to find the words, i.e. taking into account any quoting in the value.  
              Comments  are  not treated  specially  but  as  ordinary strings, similar to interactive shells with the INTERACTIVE_COMMENTS option 
              unset (however, see the Z flag below for related options)

              Note that this is done very late, even later than the '(s)' flag. So to access single words in the result use nested expansions as  
              in  '\${\${(z)foo}[2]}'.  Likewise, to remove the quotes in the resulting words use '\${(Q)\${(z)foo}}'.

       0      Split the result of the expansion on null bytes.This is a shorthand for 'ps:\0:'.

              The  following  flags (except p) are followed by one or more arguments as shown.  Any character, or the matching pairs 
              '(...)', '{...}', '[...]', or '<...>', may be used in place of a colon as delimiters, but note that when a flag takes more than 
              one argument, a matched pair of delimiters must surround each argument.

       p      Recognize the same escape sequences as the print builtin in string arguments to any of the flags described below that follow this argument.

              Alternatively, with this option string arguments may be in the form \${var} in which case the value of the  variable  is  substituted.
              Note  this  form  is strict; the string argument does not undergo general parameter expansion.

              For example,

              sep=: val=a:b:c print \${(ps.\${sep}.)val} splits the variable on a :.

       ~      Strings  inserted into the expansion by any of the flags below are to be treated as patterns.  This applies to the string arguments of 
              flags that follow ~ within the same set of parentheses.  Compare with ~ outside parentheses, which forces the entire substituted string 
              to be treated as  a  pattern. Hence, for example,

              [[ "?" = \${(~j.|.)array} ]] treats  '|'  as  a  pattern  and succeeds if and only if \${array} contains the string '?' as an element.
              The ~ may be repeated to toggle the behaviour; its effect only lasts to the end of the parenthesised group.

j:string:     Join the words of arrays together using string as a separator.  Note that this occurs before field splitting by the s:string: flag  
              or  theSH_WORD_SPLIT option.

l:expr::string1::string2:
              Pad the resulting words on the left.  Each word will be truncated if required and placed in a field expr characters wide.

              The  arguments  :string1:  and  :string2: are optional; neither, the first, or both may be given.  Note that the same pairs of 
              delimiters must be used for each of the three arguments.  The space to the left will be filled with string1 (concatenated as often as 
              needed) or spaces if string1 is not  given.  If both  string1 and string2 are given, string2 is inserted once directly to the left of 
              each word, truncated if necessary, before string1 is used to produce any remaining padding.

              If either of string1 or string2 is present but empty, i.e. there are two delimiters together at that point, the first character of \${IFS} 
              is used instead.

              If the MULTIBYTE option is in effect, the flag m may also be given, in which case widths will be used for the calculation of padding; 
              otherwise individual multibyte characters are treated as occupying one unit of width.

              If the MULTIBYTE option is not in effect, each byte in the string is treated as occupying one unit of width.

              Control characters are always assumed to be one unit wide; this allows the mechanism to be used for generating repetitions of 
              control characters.

       m      Only  useful together with one of the flags l or r or with the # length operator when the MULTIBYTE option is in effect.  Use the 
              character width reported by the system in calculating how much of the string it occupies or the overall length of the string.  Most 
              printable characters have a width of one  unit, however certain Asian character sets and certain special effects use wider characters; 
              combining characters have zero width.  Non-printable characters are arbitrarily counted as zero width; how they would actually be 
              displayed will vary.

              If the m is repeated, the character either counts zero (if it has zero width), else one.For printable character strings this has the 
              effect ofcounting the  number of glyphs (visibly separate characters), except for the case where combining characters themselves have 
              non-zero width (true in certain alphabets).

r:expr::string1::string2:
              As l, but pad the words on the right and insert string2 immediately to the right of the string to be padded.

              Left and right padding may be used together.  In this case the strategy is to apply left padding to the first half width of each of the  
              resulting  words, and right padding to the second half.  If the string to be padded has odd width the extra padding is applied on the left.

s:string:     Force  field  splitting at the separator string.Note that a string of two or more characters means that all of them must match in sequence; 
              this differs from the treatment of two or more characters in the IFS parameter.  See also the = flag and the SH_WORD_SPLIT option.An empty 
              string may also be  given in which case every character will be a separate element.

              For  historical  reasons,  the  usual behaviour that empty array elements are retained inside double quotes is disabled for arrays 
              generated by splitting; hence the following:

              line="one::three" print -l "\${(s.:.)line}" produces two lines of output for one and three and  elides  the  empty  field.   
              To  override  this behaviour,  supply  the  '(@)'  flag  aswell,  i.e.  "\${(@s.:.)line}".

Z:opts:       As  z  but  takes a combination of option letters between a following pair of delimiter characters.  With no options the effect is 
              identical to z.  (Z+c+) causes comments to be parsed as a string and retained; any field in the resulting array beginning with an 
              unquoted comment character is a comment.  (Z+C+) causes  comments  to  be  parsed and removed.  The rule for comments is standard: 
              anything between a word starting with the third character of \${HISTCHARS}, default #, up to the next newline is a comment.  (Z+n+) 
              causes unquoted newlines to be treated as ordinary whitespace, else they are treated  as  if  they are shell code delimiters and converted 
              to semicolons.  Options are combined within the same set of delimiters, e.g. (Z+Cn+).

_:flags:      The underscore (_) flag is reserved for future use.  As of this revision of zsh, there are no valid flags; anything following an 
              underscore, other than an empty pair of delimiters, is treated as an error, and the flag itself has no effect.

              The following flags are meaningful with the \${...#...} or \${...%...} forms.  The S and I flags may also be used with the \${.../...} forms.

       S      Search substrings as well as beginnings or ends; with # start from the beginning and with % start from the end  of  the  string.With  
              substitution  via \${.../...} or \${...//...}, specifies non-greedy matching, i.e. that the shortest instead of the longest match should 
              be replaced.

 I:expr:      Search  the  exprth match (where expr evaluates to a number).  This only applies when searching for substrings, either with the S flag, 
              or with \${.../...} (only the exprth match is substituted) or \${...//...} (all matches from the exprth on are substituted).The default 
              is to take the first match.

              The exprth match is counted such that there is either one or zero matches from each starting position in the  string,  although  for  
              global  substitution matches  overlapping  previous  replacements are ignored.  With the \${...%...} and \${...%%...} forms, the starting 
              position for the match moves backwards from the end as the index increases, while with the other forms it moves forward from the start.

              Hence with the string which switch is the right switch for Ipswich?  substitutions of the form \${(SI:N:)string#w*ch} as N increases 
              from 1 will match and remove 'which', 'witch', 'witch' and 'wich'; the form using '##' will match  andremove 'which switch is the right
              switch for Ipswich', 'witch is the right switch for Ipswich', 'witch for Ipswich' and 'wich'. The form using '%' will remove the same 
              matches as for '#', but in reverse order, and the form using '%%' will remove the same matches as for '##' in reverse order.

       B      Include the index of the beginning of the match in the result.

       E      Include the index one character past the end of the match in the result (note this is inconsistent with other uses of parameter index).

       M      Include the matched portion in the result.

       N      Include the length of the match in the result.

       R      Include the unmatched portion in the result (the Rest).

   Rules
       Here is a summary of the rules for substitution; this assumes that braces are present around the substitution,
       i.e. \${...}.  Some particular examples  are  given below.  Note that the Zsh Development Group accepts no
       responsibility for any brain damage which may occur during the reading of the following rules.

       1. Nested substitution
      If multiple nested \${...} forms are present, substitution is performed from the inside outwards.
      At each level, the substitution takes account of whether the current value is a scalar or an array,
      whether the whole substitution is in double quotes, and what flags are supplied to the current level
      of substi‐ tution,  just  as if the nested substitution were the outermost.  The flags are not
      propagated up to enclosing substitutions; the nested substitution will return either a scalar or
      an array as determined by the flags, possibly adjusted for quoting.  All the following steps take
      place where applicable at  all levels of substitution.

      Note  that, unless the '(P)' flag is present, the flags and any subscripts apply directly to the
      value of the nested substitution; for example, the expan‐ sion \${\${foo}} behaves exactly the same
      as \${foo}.  When the '(P)' flag is present in a nested substitution, the other substitution rules
      are  applied  to the value before it is interpreted as a name, so \${\${(P)foo}} may differ from \${(P)foo}.

      At  eachnested level of substitution, the substituted words undergo all forms of single-word
      substitution (i.e. not filename generation), including com‐ mand substitution, arithmetic
      expansion and filename expansion (i.e. leading ~ and =).Thus, for example, \${\${:-=cat}:h} expands
      to the  directory  where the  cat program resides.  (Explanation: the internal substitution has
      no parameter but a default value =cat, which is expanded by filename expansion to a full path;
      the outer substitution then applies the modifier :h and takes the directory part of the path.)

       2. Internal parameter flags
      Any parameter flags set by one of the typeset family of commands, in particular the -L, -R, -Z, -u
      and -l options  for  padding  and  capitalization,  are applied  directly  to the parameter value.
      Note these flags are options to the command, e.g. 'typeset -Z'; they are not the same as the flags
      used within parameter substitutions.

      At the outermost level of substitution, the '(P)' flag (rule 4.)ignores these transformations
      and uses the unmodified value of the parameter as the name to  be replaced.  This is usually the
      desired behavior because padding may make the value syntactically illegal as a parameter name,
      but if capitalization changes are desired, use the \${\${(P)foo}} form (rule 25.).

       3. Parameter subscripting
      If the value is a raw parameter reference with a subscript, such as \${var[3]}, the effect of subscripting
      is applied  directly  tothe  parameter.   Sub‐ scripts are evaluated left to right; subsequent
      subscripts apply to the scalar or array value yielded by the previous subscript.Thus if var is an
      array, \${var[1][2]} is the second character of the first word, but \${var[2,4][2]} is the entire third
      word (the second word of the range  of  words  two  through four of the original array).Any number of
      subscripts may appear.  Flags such as '(k)' and '(v)' which alter the result of subscripting are applied.

       4. Parameter name replacement
      At  the  outermost  level  of  nesting  only,  the '(P)' flag is applied.  This treats the value
      so far as a parameter name (which may include a subscript expression) and replaces that with the
      corresponding value.  This replacement occurs later if the '(P)' flag appears in a nested substitution.

      If the value so far names a parameter that has internal flags (rule 2.), those internal flags are
      applied to the new value after replacement.

       5. Double-quoted joining
      If the value after this process is an array, and the substitution appears in double quotes, and
      neither an '(@)' flag nor a '#' length operator is present at  the  current  level,  then words of
      the value are joined with the first character of the parameter \${IFS}, by default a space, between
      each word (single word arrays are not modified).If the '(j)' flag is present, that is used for
      joining instead of \${IFS}.

       6. Nested subscripting
      Any remaining subscripts (i.e. of a nested substitution) are evaluated at this point, based
      on whether the value is an array or a  scalar.   As  with  3., multiple subscripts can appear.
      Note that \${foo[2,4][2]} is thus equivalent to \${\${foo[2,4]}[2]} and also to "\${\${(@)foo[2,4]}[2]}"
      (the nested substitu‐ tion returns an array in both cases), but not to "\${\${foo[2,4]}[2]}" (the
      nested substitution returns a scalar because of the quotes).

       7. Modifiers
      Any modifiers, as specified by a trailing '#', '%', '/' (possibly doubled) or by a set of modifiers
      of the form ':...' (see the section 'Modifiers' in the section 'History Expansion'), are applied to
      the words of the value at this level.

       8. Character evaluation
      Any '(#)' flag is applied, evaluating the result so far numerically as a character.

       9. Length
      Any initial '#' modifier, i.e. in the form \${#var}, is used to evaluate the length of the expression
      so far.

       10. Forced joining
      If  the  '(j)' flag is present, or no '(j)' flag is present but the string is to be split as given
      by rule 11., and joining did not take place at rule 5., any words in the value are joined together
      using the given string or the first character of \${IFS} if none.  Note that the '(F)' flag implicitly
      suppliesa string for joining in this manner.

       11. Simple word splitting
      If one of the '(s)' or '(f)' flags are present, or the '=' specifier was present (e.g. \${=var}),
      the word is split on occurrences of the specified string, or (for = with neither of the two flags
      present) any of the characters in \${IFS}.

      If no '(s)', '(f)' or '=' was given, but the word is not quoted and the option SH_WORD_SPLIT is set,
      the word is split on occurrences of any of the  char‐ acters in \${IFS}.  Note this step, too, takes
      place at all levels of a nested substitution.

       12. Case modification
      Any case modification from one of the flags '(L)', '(U)' or '(C)' is applied.

       13. Escape sequence replacement
      First any replacements from the '(g)' flag are performed, then any prompt-style formatting from the
      '(%)' family of flags is applied.

       14. Quote application
      Any quoting or unquoting using '(q)' and '(Q)' and related flags is applied.

       15. Directory naming
      Any directory name substitution using '(D)' flag is applied.

       16. Visibility enhancement
      Any modifications to make characters visible using the '(V)' flag are applied.

       17. Lexical word splitting
      If  the  '(z)'  flag  orone of the forms of the '(Z)' flag is present, the word is split as if it
      were a shell command line, so that quotation marks and other metacharacters are used to decide what
      constitutes a word.  Note this form of splitting is entirely distinct from that described  by  rule
      11.:  it does not use \${IFS}, and does not cause forced joining.

       18. Uniqueness
      If the result is an array and the '(u)' flag was present, duplicate elements are removed from the array.

       19. Ordering
      If the result is still an array and one of the '(o)' or '(O)' flags was present, the array is reordered.

       20. RC_EXPAND_PARAM
      At  thispoint  the decision is made whether any resulting array elements are to be combined element
      by element with surrounding text, as given by either the RC_EXPAND_PARAM option or the '^' flag.

       21. Re-evaluation
      Any '(e)' flag is applied to the value, forcing it to be re-examined for new parameter substitutions,
      but also for command and arithmetic substitutions.

       22. Padding
      Any padding of the value by the '(l.fill.)' or '(r.fill.)' flags is applied.

       23. Semantic joining
      In contexts where expansion semantics requires a single word to result, all  words  are  rejoined
      with  the  firstcharacter  of  IFS  between.   So  in '\${(P)\${(f)lines}}' the value of \${lines}
      is split at newlines, but then must be joined again before the '(P)' flag can be applied.

      If a single word is not required, this rule is skipped.

       24. Empty argument removal
      If  the substitution does not appear in double quotes, any resulting zero-length argument, whether from
      a scalar or an element of an array, is elided from the list of arguments inserted into the command line.

      Strictly speaking, the removal happens later as the same happens with other forms of substitution;
      the point to note here is simply that itoccursafter any of the above parameter operations.

       25. Nested parameter name replacement
      If  the  '(P)' flag is present and rule 4. has not applied, the value so far is treated as a parameter
      name (which may include a subscript expression) and replaced with the corresponding value, with
      internal flags (rule 2.) applied to the new value.

${E_WHITE_FG}Parameter Modifiers${E_RESET}
-------------------
       After the optional word designator, you can add a sequence of one or more of the following modifiers, each
       preceded by a ':'.  These modifiers also work  on  the result of filename generation and parameter expansion,
       except where noted.

       a      Turn  a  file  name  into an absolute path:  prepends the current directory, if necessary; remove '.' path segments; 
              and remove '..' path segments and the segments that immediately precede them.

              This transformation is agnostic about what is in the filesystem, i.e. is on the logical, not the physical directory.  
              It takes place in the same manner as when  changingdirectories  when  neither of the options CHASE_DOTS or CHASE_LINKS 
              is set.For example, '/before/here/../after' is always transformed to '/before/after', regardless of whether '/before/here' 
              exists or what kind of object (dir, file, symlink, etc.) it is.

       A      Turn a file name into an absolute path as the 'a' modifier does, and then pass the result through the realpath(3) 
              library function  to  resolve  symbolic links.

              Note: on systems that do not have a realpath(3) library function, symbolic links are not resolved,
              so on those systems 'a' and 'A' are equivalent.

              Note: foo:A and realpath(foo) are different on some inputs.  For realpath(foo) semantics, see the 'P' modifier.

       c      Resolve  a command name into an absolute path by searching the command path given by the PATH variable.
              This does not work for commands containing directory parts.  Note also that this does not usually work as a 
              glob qualifier unless a file of the same name is found in the current directory.

       e      Remove all but the part of the filename extension following the '.'; see the definition of the filename extension 
              in the description  of  the  r  modifier below.  Note that according to that definition the result will be empty 
              if the string ends with a '.'.

       h      Remove a trailing pathname component, leaving the head.  This works like 'dirname'.

       l      Convert the words to all lowercase.

       p      Print the new command but do not execute it.  Only works with history expansion.

       P      Turn  a  file  name  into an absolute path, like realpath(3).  The resulting path will be absolute, have neither '.' 
              nor '..' components, and refer to the same directory entry as the input filename.

              Unlike realpath(3), non-existent trailing components are permitted and preserved.

       q      Quote the substituted words, escaping further substitutions.  Works with history expansion and parameter expansion, 
              though for parameters it is only  useful if the resulting text is to be re-evaluated such as by eval.

       Q      Remove one level of quotes from the substituted words.

       r      Remove  a  filename  extension  leaving the root name.  Strings with no filename extension are not altered.  A filename 
              extension is a '.' followed by any number of characters (including zero) that are neither '.' nor '/' and that continue 
              to the end of the string.  For example, the extension of 'foo.orig.c' is '.c', and 'dir.c/foo' has no extension.

s/l/r[/]      Substitute  r  for l as described below.The substitution is done only for the first string that
              matches l.  For arrays and for filename generation, this applies to each word of the expanded text.
              See below for further notes on substitutions.

              The forms 'gs/l/r' and 's/l/r/:G' perform global substitution, i.e. substitute every occurrence of r for l.
              Note that the g or :G must appear in  exactly the position shown.

              See further notes on this form of substitution below.

       &      Repeat  the previous s substitution.  Like s, may be preceded immediately by a g.  In parameter expansion the & must 
              appear inside braces, and in filename generation it must be quoted with a backslash.

       t      Remove all leading pathname components, leaving the tail.  This works like 'basename'.

       u      Convert the words to all uppercase.

       x      Like q, but break into words at whitespace.  Does not work with parameter expansion.

              The s/l/r/ substitution works as follows.  By default the left-hand side of substitutions are not patterns,
              but character strings.  Any character can be used  as the  delimiter  in  placeof  '/'.   A  backslash
              quotes the delimiter character.The character '&', in the right-hand-side r, is replaced by the text from
              the left-hand-side l.  The '&' can be quoted with a backslash.  A null l uses the previous string either
              from the previous l or from thecontextual  scan  string  s from  '!?s'.   Youcan  omit the rightmost
              delimiter if a newline immediately follows r; the rightmost '?' in a context scan can similarly be omitted.
              Note the same record of the last l and r is maintained across all forms of expansion.
       
              Note that if a '&' is used within glob qualifiers an extra backslash is needed as a & is a special character in this case.

              Also note that the order of expansions affects the interpretation of l and r.  When used in a history expansion,
              which occurs before any other expansions, l  and r are treated as literal strings (except as explained for
              HIST_SUBST_PATTERN below).  When used in parameter expansion, the replacement of r into the parameter's
              value is done first, and then any additional process, parameter, command, arithmetic, or brace references
              are applied, which may evaluate those substitutions and expansions  more  than once if l appears more than
              once in the starting value.  When used in a glob qualifier, any substitutions or expansions are performed
              once at the time the qualifier is parsed, even before the ':s' expression itself is divided into l and r sides.
 
              If the option HIST_SUBST_PATTERN is set, l is treated as a pattern of the usual form described in the
              section FILENAME GENERATION below.  This can be used in all theplaceswhere  modifiers  are  available;
              note,  however,that in globbing qualifiers parameter substitution has already taken place, so parameters
              in the replacement string should be quoted to ensure they are replaced at the correct time.  Note also
              that complicated patterns used in globbing  qualifiers  may  need the  extended glob qualifier notation
              (#q:s/.../.../) in order for the shell to recognize the expression as a glob qualifier.Further, note that
              bad patterns in the substitution are not subject to the NO_BAD_PATTERN option so will cause an error.
 
              When HIST_SUBST_PATTERN is set, l may start with a # to indicate that the pattern must match at the start
              of the string to be substituted, and a % may appear  at the start or after an # to indicate that the pattern
              must match at the end of the string to be substituted.  The % or # may be quoted with two backslashes.
 
              For example, the following piece of filename generation code with the EXTENDED_GLOB option:
 
              print *.c(#q:s/#%(#b)s(*).c/'S\${match[1]}.C'/)

              takes  the expansion of *.c and applies the glob qualifiers in the (#q...) expression, which consists of a
              substitution modifier anchored to the start and end of each word (#%).  This turns on backreferences ((#b)),
              so that the parenthesised subexpression is  available  in  the  replacement  string  as\${match[1]}.
              The replacement string is quoted so that the parameter is not substituted before the start of filename generation.
 
              The  following  f,  F, w and W modifiers work only with parameter expansion and filename generation.
              They are listed here to provide a single point of reference for all modifiers.
 
       f      Repeats the immediately (without a colon) following modifier until the resulting word doesn't change any more.

 F:expr:      Like f, but repeats only n times if the expression expr evaluates to n.  Any character can be used
              instead of the ':'; if '(', '[', or '{' is used as  the opening delimiter, the closing delimiter
              should be ')', ']', or '}', respectively.

       w      Makes the immediately following modifier work on each word in the string.

  W:sep:      Like w but words are considered to be the parts of the string that are separated by sep. Any character
              can be used instead of the ':'; opening parentheses are handled specially, see above.
		  
${E_WHITE_FG}Examples${E_RESET}
--------
       The flag f is useful to split a double-quoted substitution line by line.  For example, \${(f)"\$(<file)"}
       substitutes the contents of file  divided  so  that  each line is an element of the resulting array.
       Compare this with the effect of \$(<file) alone, which divides the file up by words, or the same inside
       double quotes, which makes the entire content of the file a single string.

       The following illustrates the rules for nested parameter expansions.  Suppose that \${foo} contains the array
       (bar baz):

       "\${(@)\${foo}[1]}"
	      This produces the result b.  First, the inner substitution "\${foo}", which has no array (@) flag,
	      produces a single word result "bar baz".	The outer sub‐ stitution "\${(@)...[1]}" detects that
	      this is a scalar, so that (despite the '(@)' flag) the subscript picks the first character.

       "\${\${(@)foo}[1]}"
	      This  produces  the  result  'bar'.   In this case, the inner substitution "\${(@)foo}" produces the
	      array '(bar baz)'.  The outer substitution "\${...[1]}" detects that this is an array and picks the
	      first word.  This is similar to the simple case "\${foo[1]}".

       As an example of the rules for word splitting and joining, suppose \${foo} contains the array '(ax1 bx1)'.	Then

       \${(s/x/)foo}
	      produces the words 'a', '1 b' and '1'.

       \${(j/x/s/x/)foo}
	      produces 'a', '1', 'b' and '1'.

       \${(s/x/)foo%%1*}
	      produces 'a' and ' b' (note the extra space).  As substitution occurs before either joining or
	      splitting, the  operation   first  generates  the  modified array (ax bx), which is joined to give
	      "ax bx", and then split to give 'a', ' b' and ''.  The final empty string will then be elided,
	      as it is not in dou‐ ble quotes.


${E_MAGENTA_FG}ZSH Globbing${E_RESET}
------------
Let's start with a simple problem. Suppose you have a directory hierarchy full of text files with their execute permission bit 
set. How can you recursively turn off the execute permission for files, but leave the execute permissions for the directories 
alone? With the Bourne shell, you might do something like this:

 % find . -type f -print | xargs chmod -x
 
Using zsh and globs (special strings containing wildcard characters like ?, *, etc.) the solution is simpler. zshs 
globbing abilities are good enough to make find unnecessary. We need only run this to get the same result:

 % chmod -x **/*(.)
 
The leading **/ tells zsh to glob recursively. The * following that means to get everything. Finally, the glob ends in a (.), 
which is a glob qualifier, that restricts the matching to files.

Heres another example (with additional glob qualifiers).  Suppose an unwanted visitor compromised the security of your 
machine, and you want to find out if he implanted any trojan horses (trojan horses are programs that disguise themselves as 
regular Linux commands like passwd and then transmit stolen information back to the evildoer) and check the entire filesystem 
to see if any executable files have been modified since yesterday. In zsh, this can be done with:

% print -l /**/*(*.m-1)
 
Notice how glob qualifiers can be chained together. This time, we have * which means executables, . which means plain 
files, and m-1 which limits matches to anything with a modification time of one day or less. The -l option tells print 
to print out each value on a separate line. As you can see, using glob qualifiers together with recursive globbing makes zshs 
globbing system just as powerful as the find program.

For a full list of glob qualifiers, see the Glob Qualifiers section of the zshexpn man page. For more on filename generation 
and pattern matching, see section 5.9 of the Zsh Users Guide (http://zsh.sunsite.dk/Guide/).

${E_WHITE_FG}Data Types and Attributes${E_RESET}
-------------------------

Weve just seen how globbing can generate huge lists of filenames. But once you have a list, the question is how to 
contain it. An array works perfectly for this. In the following command, list will be assigned a list of all the files in 
/usr/bin.

 % list=(/usr/bin/*)
 
This array can then be accessed in a number of ways that programmers (especially Perl programmers) may find familiar. 
However, be careful. In zsh, arrays are indexed from 1 instead of 0. Below are some examples using arrays.

To get the array size, use a \${#} before the array name:

 % print \${#list}
 462

Both positive numbers and negative numbers can be used as indexes into the array. Positive numbers count forward from the start of 
the array; negative numbers count backward from the end of the array:

 % print \${list}[462]
 /usr/bin/zprint

 % print \${list}[-462]
 /usr/bin/a2p
 
To retrieve multiple values as a sub-list (or a slice), we can add a comma between starting and ending index numbers:

 % print -l \${list[23,25]}
 /usr/bin/atq
 /usr/bin/atrm
 /usr/bin/atstatus

To retrieve from element 2 till the end:

 % print -l \${list[@]:2}


The array is just one of zshs five data types. The other four types are: association (a hash table), scalar (a string), float, 
and integer. In general, type is handled automatically (as far as the programmer is concerned). For example, the following code 
assigns a scalar value to theory, a float to pi, and an integer to a without the need for type to be declared explicitly:

 % theory=conspiracy
 % pi=3.14159
 % a=42
 
However, one exception is associations. You must first declare a variable as an associative array before it takes on the behavior 
of one. This is done by using the built-in command typeset -A variable:

 % typeset -A hash
 % hash[brown]=Mmm..  hash browns
 % hash[table]=clever data structure
 % print \${hash[brown]}

 Mmm..  hash browns
 
typeset is actually quite versatile. It can be used to pre-declare variables of specific types (scalar, int, float, 
array), although its not strictly necessary. It can also give special attributes to variables. Lets look at some examples.

The -Z 3 option makes the variable agent at least three characters long, padded with zeros if necessary.

 % typeset -Z 3 agent
 % agent=7
 % print \${agent}
 007
 
The -r option can make a variable read-only.

 % typeset -r agent
 % agent=secret
 zsh: read-only variable: agent
 
The -U option forces an array to have unique contents and duplicate values are ignored.

 % typeset -U unique_set
 % unique_set=(1 2 4 8 16 8 4 2 1)

 print \${unique_set}
 1 2 4 8 16

zsh can also tie scalar variables and array variables together with the -T option, effectively giving you two interfaces to the 
same data. In Figure One, you can see how the variables \${DIR} and \${dir} are tied together.

Figure One: Tying scalars to arrays

 % typeset -T DIR dir
 % dir=(/etc /var/log /usr/local/bin)
 % print \${DIR}
 /etc:/var/log:/usr/local/bin

 % DIR=/tmp:/opt
 % print -l \${dir}
 /tmp
 /opt

This feature is extremely useful for dealing with PATH-like variables. In fact, the \${PATH}, \${FPATH}, and \${MANPATH} environment 
variables already have matching \${path}, \${fpath}, and \${manpath} variables associated with them when zsh starts up. And since 
arrays cant be exported, being able to store the arrays contents into a single string is very useful.

(The reason arrays cant be exported is because the shell environment is a feature of Unix, not a part of zsh. zsh can 
support any the data types it wants, but the environment only understands strings. This prevents collections like arrays or 
associations from being exported. However, float, integer, and scalar variables can be exported without problems.)

For more on typeset, use tab-completion to see a complete list of available special attributes (by typing typeset -[TAB]) or read 
the zshbuiltins man page.

${E_WHITE_FG}Using Flags and Modifiers to Transform Data${E_RESET}
-------------------------------------------

Now that we have data stored in variables, lets learn how to manipulate it. In shell programming, data manipulation has 
traditionally been done by programs like sed and awk which are usually used in a long and contrived series of backticks and 
pipes. However, zsh scripts can often avoid this by using flags and modifiers. Lets look at a simple example:

 % place=santa barbara
 % print -l \${(U)place} \${place:u} \${place}

 SANTA BARBARA
 SANTA BARBARA
 santa barbara
 
Here, we make the entire string upper-case, first using the (U) flag and then using the :u modifier. Then, we print \${place} 
without any modifiers or flags to show that the variable was not actually changed.

(Why a (U) flag and a :u modifier? There isnt much difference between them; you may prefer one or the other depending on your 
coding style.)

Lets initialize an array that well use for some more examples:

% list=(
   /usr/bin/perl
   /var/log/wtmp
   /etc/inetd.conf
 )
 
One feature unique to modifiers is specialized filename transformations. A filename transformation can do the same things 
that basename and dirname can. We can use the -t flag to simulate basename and the -h flag to simulate dirname:

 % print \${list:t}
 perl wtmp inent.conf
 % print \${list:h}
 /usr/bin /var/log /etc

We can also simulate grep -v (inverted grep) using the :# mdodifier to filter out items from list that match the given glob 
pattern.

 % print \${list:#/etc*}
 /usr/bin/perl /var/log/wtmp
 
To simulate a normal grep, the (M) flag is used to reverse the meaning of :#.

 % print \${(M)list:#/etc*}
 /etc/inetd.conf
 
Finally, you can combine and nest flags and modifiers to perform complex data manipulations. Unfortunately, the result often looks 
like line noise. In the next example, we store the complete path names of all entries from /usr/bin in list. Then we print out the 
file names (in upper case) of all entries that have ssh anywhere in the path.

 % list=(/usr/bin/*)
 % print -l \${\${(UM)list:#*ssh*}:t}

SSH
SSH-ADD
SSH-AGENT
SSH-KEYGEN
SSH-KEYSCAN
 
For more on modifiers and parameter expansion flags, see the zshexpn man page.

${E_MAGENTA_FG}Conditional Expressions using [[ ]]${E_RESET}
-----------------------------------

That last example might may make you think that the zsh developers dont care about readability, but thats not 
completely true. Look at the improvements made to conditional expressions for reassurance that zsh code can in fact be readable.

zsh has an alternative method for writing conditionals thats much more expressive than using the traditional test command. 
Its greatest strength is its ability to nest conditionals using a familiar and intuitive notation. In the next example, 
notice how parentheses can be used for grouping, and && and || for logical AND and OR.

 if [[   ((\${x} -lt  8) && (\${y} -ge 32)) || ((\${z} -gt 32) && (\${w} -eq 16))  ]]
 then
     print complex combinations
     print are not a problem.

 fi
 
The [[ ]] notation is also downward compatible with the test command, being able to perform the same file and string tests. 
For example, you can use -e to see if a file exists, -d to see if a name is a directory, or perform string comparisons, in this 
case, inequality:

 [[ -e \${HOME}/.emacs ]]
 [[ -d \${HOME}/.ssh ]]
 [[ foo != bar ]]
 
${E_MAGENTA_FG}Mathematical Expressions Using (( ))${E_RESET}
------------------------------------

zsh also has a double parenthesis notation to evaluate mathematical expressions. The most interesting thing about (( )) 
is that its expression syntax is a radical departure from Bourne shell syntax. Consider the following example.

 % a=5; b=32; c=24; (( a += (++a + b * c)  2 ))
 % print \${a}

 777
 
Everything in the example above, from the mathematical operators to how dollar signs are omitted when referring to variables, 
makes zsh look and feel a lot more like a C program than a shell script. While zshs syntax is definitely an improvement over 
expr and backticks, there are times when zsh can be a bit too much like C.

For example, the shell script below (just a one-liner typed at the command prompt) demonstrates that zshs type system 
doesnt automatically promote integer types to yield the most accurate result. Instead, its necessary to explicitly specify 
one of the two numbers as a floating-point number to get the highest accuracy. Most scripting languages will perform the 
promotion for you, but whoever implemented the (( )) notation apparently liked C a lot.

% print \$(( 5 / 2 ))
 2

 % print \$(( 5.0 / 2 ))
 2.5

Besides being used for mathematical functions, (( )) is often used in statements needing conditional expressions. In these 
cases, expressions that evaluate to 0 are false and everything else is true (like C).

An idiom that youll see a lot in the completion functions is the \$+var technique, which tests to see if \${var} is defined. Here 
are a few examples:

 % (( \$+var )) && print \tvar exists
 % (( \$+var )) || print \tno, it doesnt exist
         no, it doesnt exist

 % var=5
 % (( \$+var )) && print \tnow var exists
         now var exists
 
Notice also how the logical AND and OR act as if-then statements.  This is just like Perl.

=========================
${E_MAGENTA_FG}TYPESET${E_RESET}
=========================
typeset args:

${E_WHITE_FG}-A${E_RESET}  The names refer to associative array parameters; see 'Array Parameters' in zsh- param(1).

${E_WHITE_FG}-L${E_RESET}  Left justify and remove leading blanks from value. If n is nonzero, it defines the width of the field.  If n is zero, the width is 
    determined by the width of the value of the first assignment. In the case of numeric parameters, the length of the complete value 
    assigned to the parameter is used to determine the width, not the value that would be output.

    The width is the count of characters, which may be multibyte characters if the MULTIBYTE option is in effect. Note that the screen width
    of the character is not taken into account; if this is required, use padding with parameter expansion flags \${(ml...)...} as described 
    in 'Parameter Expansion Flags' in zshexpn(1).

    When the parameter is expanded, it is filled on the right with blanks or truncated if necessary to fit the field. Note truncation can 
    lead to unexpected results with numeric parameters. Leading zeros are removed if the -Z flag is also set.

${E_WHITE_FG}-R${E_RESET}  Similar to -L, except that right justification is used; when the parameter is expanded, the field is left filled with blanks or truncated 
    from the end. May not be combined with the -Z flag.

${E_WHITE_FG}-U${E_RESET}  For arrays (but not for associative arrays), keep only the first occurrence of each duplicated value. This may also be set for 
    colon-separated special parameters like PATH or FIGNORE, etc. This flag has a different meaning when used with -f; see below.

${E_WHITE_FG}-Z${E_RESET}  Specially handled if set along with the -L flag. Otherwise, similar to -R, except that leading zeros are used for padding instead of blanks if 
    the first non-blank character is a digit. Numeric parameters are specially handled: they are always eligible for padding with zeroes, and 
    the zeroes are inserted at an appropriate place in the output.

${E_WHITE_FG}-a${E_RESET}  The names refer to array parameters. An array parameter may be created this way, but it may not be assigned to in the typeset statement. 
    When displaying, both normal and associative arrays are shown.


${E_WHITE_FG}-f${E_RESET}  The names refer to functions rather than parameters. No assignments can be made, and the only other valid flags are -t, -T, -k, -u, -U and -z. 
    The flag -t turns on execution tracing for this function; the flag -T does the same, but turns off tracing on any function called from the 
    present one, unless that function also has the -t or -T flag. The -u and -U flags cause the function to be marked for autoloading; -U 
    also causes alias expansion to be suppressed when the function is loaded. The fpath parameter will be searched to find the function definition 
    when the function is first referenced; see the section 'Functions'. The -k and -z flags make the function be loaded using ksh-style or zsh-style 
    autoloading respectively. If neither is given, the setting of the KSH_AUTOLOAD option determines how the function is loaded.

${E_WHITE_FG}-h${E_RESET}  Hide: only useful for special parameters (those marked '<S>' in the table in zsh-param(1)), and for local parameters with the same name as a
    special parameter though harmless for others. A special parameter with this attribute will not retain its special effect when made local. 
    Thus after 'typeset -h PATH', a function containing 'typeset PATH' will create an ordinary local parameter without the usual behaviour of PATH. 
    Alternatively, the local parameter may itself be given this attribute; hence inside a function 'typeset -h PATH' creates an ordinary
    local parameter and the special PATH parameter is not altered in any way. It is also possible to create a local parameter using 
    'typeset +h special', where the local copy of special will retain its special properties regardless of having the -h attribute. 
    Global special parameters loaded from shell modules (currently those in zsh/mapfile and zsh/parameter) are automatically given the -h 
    attribute to avoid name clashes.

${E_WHITE_FG}-H${E_RESET}  Hide value: specifies that typeset will not display the value of the parameter when listing parameters; the display for such parameters is 
    always as if the '+' flag had been given. Use of the parameter is in other respects normal, and the option does not apply if the parameter 
    is specified by name, or by pattern with the -m option. This is on by default for the parameters in the zsh/parameter and zsh/mapfile 
    modules. Note, however, that unlike the -h flag this is also useful for non-special parameters.

${E_WHITE_FG}-i${E_RESET}  Use an internal integer representation. If n is nonzero it defines the output arithmetic base, otherwise it is determined by the first 
    assignment. Bases from 2 to 36 inclusive are allowed.

${E_WHITE_FG}-E${E_RESET}  Use an internal double-precision floating point representation. On output the variable will be converted to scientific notation. If n is 
    nonzero it defines the number of significant figures to display; the default is ten.

${E_WHITE_FG}-F${E_RESET}  Use an internal double-precision floating point representation. On output the variable will be converted to fixed-point decimal notation. 
    If n is nonzero it defines the number of digits to display after the decimal point; the default is ten.

${E_WHITE_FG}-l${E_RESET}  Convert the result to lower case whenever the parameter is expanded. The value is not converted when assigned.

${E_WHITE_FG}-r${E_RESET}  The given names are marked readonly. Note that if name is a special parameter, the readonly attribute can be turned on, but cannot 
    then be turned off.

${E_WHITE_FG}-t${E_RESET}  Tags the named parameters. Tags have no special meaning to the shell. This flag has a different meaning when used with -f; see above.

${E_WHITE_FG}-u${E_RESET}  Convert the result to upper case whenever the parameter is expanded. The value is not converted when assigned. This flag has a different 
    meaning when used with -f; see above.

${E_WHITE_FG}-x${E_RESET}  Mark for automatic export to the environment of subsequently executed commands. If the option GLOBAL_EXPORT is set this implies the 
    option -g, unless +g is also explicitly given; in other words the parameter is not made local to the enclosing function. This is for 
    compatibility with previous versions of zsh.

===================
${E_MAGENTA_FG}REDIRECTION${E_RESET}
===================
If a command is followed by & and job control is not active, then the default standard input for the command is the 
empty file /dev/null. Otherwise, the environment for the execution of a command contains the file descriptors of the 
invoking shell as modified by input/output specifications.

The following may appear anywhere in a simple command or may precede or follow a complex command. Expansion occurs 
before word or digit is used except as noted below. If the result of substitution on word produces more than one 
filename, redirection occurs for each separate filename in turn.

< word 
Open file word for reading as standard input. It is an error to open a file in this fashion if it does not exist.

<> word
Open file word for reading and writing as standard input. If the file does not exist then it is created.

> word 
Open file word for writing as standard output. If the file does not exist then it is created. If the file 
exists, and the CLOBBER option is unset, this causes an error; otherwise, it is truncated to zero length.

>| word
>! word
Same as >, except that the file is truncated to zero length if it exists, regardless of CLOBBER.

>> word
Open file word for writing in append mode as standard output. If the file does not exist, and the CLOBBER and 
APPEND_CREATE options are both unset, this causes an error; otherwise, the file is created.

>>| word
>>! word
Same as >>, except that the file is created if it does not exist, regardless of CLOBBER and APPEND_CREATE.

<<[-] word
The shell input is read up to a line that is the same as word, or to an end-of-file. No parameter expansion, 
command substitution or filename generation is performed on word. The resulting document, called a here-document, 
becomes the standard input.

If any character of word is quoted with single or double quotes or a '\', no interpretation is placed upon the 
characters of the document. Otherwise, parameter and command substitution occurs, '\' followed by a newline is removed, 
and '\' must be used to quote the characters '\', '\$', ''' and the first character of word.

Note that word itself does not undergo shell expansion. Backquotes in word do not have their usual effect; instead they 
behave similarly to double quotes, except that the backquotes themselves are passed through unchanged. (This 
information is given for completeness and it is not recommended that backquotes be used.) Quotes in the form \$'...' 
have their standard effect of expanding backslashed references to special characters.

If <<- is used, then all leading tabs are stripped from word and from the document.

<<< word
Perform shell expansion on word and pass the result to standard input. This is known as a here-string. Compare the use 
of word in here-documents above, where word does not undergo shell expansion. The result will have a trailing newline 
after it.

<& number
>& number
The standard input/output is duplicated from file descriptor number (see dup2(2)).

<& -
>& - Close the standard input/output.

<& p
>& p The input/output from/to the coprocess is moved to the standard input/output.

>& word
&> word
(Except where '>& word' matches one of the above syntaxes; '&>' can always be used to avoid this ambiguity.) 
Redirects both standard output and standard error (file descriptor 2) in the manner of '> word'. Note that this does 
not have the same effect as '> word 2>&1' in the presence of multios (see the section below).

>&| word
>&! word
&>| word
&>! word
Redirects both standard output and standard error (file descriptor 2) in the manner of '>| word'.

>>& word
&>> word
Redirects both standard output and standard error (file descriptor 2) in the manner of '>> word'.

>>&| word
>>&! word
&>>| word
&>>! word
Redirects both standard output and standard error (file descriptor 2) in the manner of '>>| word'.

If one of the above is preceded by a digit, then the file descriptor referred to is that specified by the digit instead 
of the default 0 or 1. The order in which redirections are specified is significant. The shell evaluates each 
redirection in terms of the (file descriptor, file) association at the time of evaluation. For example:

... 1>fname 2>&1

first associates file descriptor 1 with file fname. It then associates file descriptor 2 with the file associated with 
file descriptor 1 (that is, fname). If the order of redirections were reversed, file descriptor 2 would be associated 
with the terminal (assuming file descriptor 1 had been) and then file descriptor 1 would be associated with file fname.

The '|&' command separator described in Simple Commands & Pipelines in zshmisc(1) is a shorthand for '2>&1 |'.

The various forms of process substitution, '<(list)', and '=(list)' for input and '>(list)' for output, are often used 
together with redirection. For example, if word in an output redirection is of the form '>(list)' then the output is 
piped to the command represented by list.  See Process Substitution in zshexpn(1).

OPENING FILE DESCRIPTORS USING PARAMETERS
When the shell is parsing arguments to a command, and the shell option IGNORE_BRACES is not set, a different form of 
redirection is allowed: instead of a digit before the operator there is a valid shell identifier enclosed in braces. 
The shell will open a new file descriptor that is guaranteed to be at least 10 and set the parameter named by the 
identifier to the file descriptor opened. No whitespace is allowed between the closing brace and the redirection 
character. For example:

... {myfd}>&1

This opens a new file descriptor that is a duplicate of file descriptor 1 and sets the parameter myfd to the number of 
the file descriptor, which will be at least 10. The new file descriptor can be written to using the syntax >&\$myfd. 
The file descriptor remains open in subshells and forked external executables.

The syntax {varid}>&-, for example {myfd}>&-, may be used to close a file descriptor opened in this fashion. Note that 
the parameter given by varid must previously be set to a file descriptor in this case.

It is an error to open or close a file descriptor in this fashion when the parameter is readonly. However, it is not an 
error to read or write a file descriptor using <&\$param or >&\$param if param is readonly.

If the option CLOBBER is unset, it is an error to open a file descriptor using a parameter that is already set to an 
open file descriptor previously allocated by this mechanism. Unsetting the parameter before using it for allocating 
a file descriptor avoids the error.

Note that this mechanism merely allocates or closes a file descriptor; it does not perform any redirections from or to 
it. It is usually convenient to allocate a file descriptor prior to use as an argument to exec. The syntax does not in 
any case work when used around complex commands such as parenthesised subshells or loops, where the opening brace is 
interpreted as part of a command list to be executed in the current shell.

The following shows a typical sequence of allocation, use, and closing of a file descriptor:

integer myfd
exec {myfd}>~/logs/mylogfile.txt
print This is a log message. >&\$myfd
exec {myfd}>&-

Note that the expansion of the variable in the expression >&\$myfd occurs at the point the redirection is opened. This 
is after the expansion of command arguments and after any redirections to the left on the command line have been 
processed.

MULTIOS
If the user tries to open a file descriptor for writing more than once, the shell opens the file descriptor as a pipe 
to a process that copies its input to all the specified outputs, similar to tee, provided the MULTIOS option is set, as 
it is by default. Thus:

date >foo >bar

writes the date to two files, named 'foo' and 'bar'. Note that a pipe is an implicit redirection; thus

date >foo | cat

writes the date to the file 'foo', and also pipes it to cat.

Note that the shell opens all the files to be used in the multio process immediately, not at the point they are about 
to be written.

Note also that redirections are always expanded in order. This happens regardless of the setting of the MULTIOS option, 
but with the option in effect there are additional consequences. For example, the meaning of the expression >&1 will 
change after a previous redirection:

date >&1 >output

In the case above, the >&1 refers to the standard output at the start of the line; the result is similar to the tee 
command. However, consider:

date >output >&1

As redirections are evaluated in order, when the >&1 is encountered the standard output is set to the file output and 
another copy of the output is therefore sent to that file. This is unlikely to be what is intended.

If the MULTIOS option is set, the word after a redirection operator is also subjected to filename generation 
(globbing). Thus

: > *

will truncate all files in the current directory, assuming there's at least one. (Without the MULTIOS option, it would 
create an empty file called '*'.) Similarly, you can do

echo exit 0 >> *.sh

If the user tries to open a file descriptor for reading more than once, the shell opens the file descriptor as a pipe 
to a process that copies all the specified inputs to its output in the order specified, provided the MULTIOS option is 
set. It should be noted that each file is opened immediately, not at the point where it is about to be read: this 
behaviour differs from cat, so if strictly standard behaviour is needed, cat should be used instead.

Thus

sort <foo <fubar

or even

sort <f{oo,ubar}

is equivalent to 'cat foo fubar | sort'.

Expansion of the redirection argument occurs at the point the redirection is opened, at the point described above for 
the expansion of the variable in >&\$myfd.

Note that a pipe is an implicit redirection; thus

cat bar | sort <foo

is equivalent to 'cat bar foo | sort' (note the order of the inputs).

If the MULTIOS option is unset, each redirection replaces the previous redirection for that file descriptor. However, 
all files redirected to are actually opened, so

echo Hello > bar > baz

when MULTIOS is unset will truncate 'bar', and write 'Hello' into 'baz'.

There is a problem when an output multio is attached to an external program. A simple example shows this:

cat file >file1 >file2
cat file1 file2

Here, it is possible that the second 'cat' will not display the full contents of file1 and file2 (i.e. the original 
contents of file repeated twice).

The reason for this is that the multios are spawned after the cat process is forked from the parent shell, so the 
parent shell does not wait for the multios to finish writing data. This means the command as shown can exit before 
file1 and file2 are completely written. As a workaround, it is possible to run the cat process as part of a job in 
the current shell:

{ cat file } >file >file2

Here, the {...} job will pause to wait for both files to be written.

REDIRECTIONS WITH NO COMMAND
When a simple command consists of one or more redirection operators and zero or more parameter assignments, but no 
command name, zsh can behave in several ways.

If the parameter NULLCMD is not set or the option CSH_NULLCMD is set, an error is caused. This is the csh behavior and 
CSH_NULLCMD is set by default when emulating csh.

If the option SH_NULLCMD is set, the builtin ':' is inserted as a command with the given redirections. This is the 
default when emulating sh or ksh.

Otherwise, if the parameter NULLCMD is set, its value will be used as a command with the given redirections. If both 
NULLCMD and READNULLCMD are set, then the value of the latter will be used instead of that of the former when the 
redirection is an input. The default for NULLCMD is 'cat' and for READNULLCMD is 'more'.
Thus:

< file

shows the contents of file on standard output, with paging if that is a terminal. NULLCMD and READNULLCMD may refer to 
shell functions.

===================
${E_MAGENTA_FG}READ${E_RESET}
===================
read [ -rszpqAclneE ] [ -t [ num ] ] [ -k [ num ] ] [ -d delim ] [ -u n ] [ name[?prompt] ] [ name ... ]

Read one line and break it into fields using the characters in \${IFS} as separators, except as noted below. The first field is
assigned to the first name, the second field to the second name, etc., with leftover fields assigned to the last name. If name is
omitted then REPLY is used for scalars and reply for arrays.  

${E_WHITE_FG}-r${E_RESET}     Raw mode: a '' at the end of a line does not signify line continuation and backslashes in the line don't quote the following character and are not removed.
 
${E_WHITE_FG}-s${E_RESET}     Don't echo back characters if reading from the terminal.  Currently does not work with the -q option.
 
${E_WHITE_FG}-q${E_RESET}     Read only one character from the terminal and set name to 'y' if this character was 'y' or 'Y' and to 'n' other- wise. With this flag set the return 
       status is zero only if the character was 'y' or 'Y'. This option may be used with a timeout; if the read times out, or encounters end of file, 
       status 2 is returned.  Input is read from the terminal unless one of -u or -p is present.  This option may also be used within zle widgets.
 
${E_WHITE_FG}-k[n]${E_RESET}  Read only one (or num) characters. All are assigned to the first name, without word splitting. This flag is ignored when -q is present. 
       Input is read from the terminal unless one of -u or -p is present. This option may also be used within zle widgets.
 
       Note that despite the mnemonic 'key' this option does read full characters, which may consist of multiple bytes if the option MULTIBYTE is set.
 
${E_WHITE_FG}-z${E_RESET}     Read one entry from the editor buffer stack and assign it to the first name, without word splitting. Text is pushed onto the stack with 'print -z' 
       or with push-line from the line editor (see zshzle(1)). This flag is ignored when the -k or -q flags are present.
 
${E_WHITE_FG}-e -E${E_RESET}  The input read is printed (echoed) to the standard output. If the -e flag is used, no input is assigned to the parameters.
 
${E_WHITE_FG}-A${E_RESET}     The first name is taken as the name of an array and all words are assigned to it.
 
${E_WHITE_FG}-c -l${E_RESET}  These flags are allowed only if called inside a function used for completion (specified with the -K flag to com- pctl).  If the -c flag is given, 
       the words of the current command are read. If the -l flag is given, the whole line is assigned as a scalar. If both flags are present, -l is used 
       and -c is ignored.
 
${E_WHITE_FG}-n${E_RESET}     Together with -c, the number of the word the cursor is on is read. With -l, the index of the character the cur- sor is on is read. Note that the 
       command name is word number 1, not word 0, and that when the cursor is at the end of the line, its character index is the length of the line plus one.
 
${E_WHITE_FG}-u n${E_RESET}   Input is read from file descriptor n.
 
${E_WHITE_FG}-p${E_RESET}     Input is read from the coprocess.
 
${E_WHITE_FG}-d${E_RESET}     delim Input is terminated by the first character of delim instead of by newline.
 
${E_WHITE_FG}-t[n]${E_RESET}  Test if input is available before attempting to read.  If num is present, it must begin with a digit and will be evaluated to give a number of 
       seconds, which may be a floating point number; in this case the read times out if input is not available within this time. If num is not present, 
       it is taken to be zero, so that read returns immediately if no input is available. If no input is available, return status 1 and do not set 
       any variables.

       This option is not available when reading from the editor buffer with -z, when called from within completion with -c or -l, with -q which clears 
       the input queue before reading, or within zle where other mechanisms should be used to test for input.

       Note that read does not attempt to alter the input processing mode. The default mode is canonical input, in which an entire line is read at a time,
       so usually 'read -t' will not read anything until an entire line has been typed. However, when reading from the terminal with -k input is processed 
       one key at a time; in this case, only availability of the first character is tested, so that e.g.  'read -t -k 2' can still block on the second 
       character.  Use two instances of 'read -t -k' if this is not what is wanted.
 
       If the first argument contains a '?', the remainder of this word is used as a prompt on standard error when the shell is interactive.
 
       The value (exit status) of read is 1 when an end-of-file is encountered, or when -c or -l is present and the command is not called from a compctl 
       function, or as described for -q. Otherwise the value is 0.

       The behavior of some combinations of the -k, -p, -q, -u and -z flags is undefined. Presently -q cancels all the oth- ers, -p cancels -u, 
       -k cancels -z, and otherwise -z cancels both -p and -u.

       The -c or -l flags cancel any and all of -kpquz.

===================
${E_MAGENTA_FG}BUILTINS${E_RESET}
===================
       Some  shell  builtin  commands  take options as described in individual entries; these are often referred to in the list below as 'flags'
       to avoid confusion with shell options, which may also have an effect on the behaviour of builtin commands.  In this introductory section,
       'option' always has the meaning of an option to a command that should be familiar to most command line users.

       Typically,  options are single letters preceded by a hyphen (-).  Options that take an argument accept it either immediately following
       the option letter or after white space, for example 'print -C3 *' or 'print -C 3 *' are equivalent.  Arguments to options are not the same as
       arguments to the  command;  the	documentation indicates which is which.  Options that do not take an argument may be combined in a single word,
       for example 'print -ca *' and 'print -c -a *' are equivalent.  Some shell builtin commands also take options that begin with '+'
       instead of '-'.	The list below makes clear which commands these are.  Options	(together  with  their individual arguments, if any) must
       appear in a group before any non-option arguments; once the first non-option argument has been found, option processing is terminated.

       All builtin commands other than precommand modifiers, even those that have no options, can be given the argument '--' to terminate
       option processing.  This indi‐ cates  that  the  following words are non-option arguments, but is otherwise ignored.  This is
       useful in cases where arguments to the command may begin with '-'.  For historical reasons, most builtin commands also recognize a single
       '-' in a separate word for this purpose; note that this is less standard and use of '--' is recommended.

       - simple command
	      See the section 'Precommand Modifiers' in zshmisc(1).

       . file [ arg ... ]
	      Read commands from file and execute them in the current shell environment.

	      If  file does not contain a slash, or if PATH_DIRS is set, the shell looks in the components of \${path} to find the directory
	      containing file.	Files in the current directory are not read unless '.' appears somewhere in \${path}.  If a file named
	      'file.zwc' is found, is newer than file, and is the  compiled form (created with the zcompile builtin) of file, then commands
	      are read from that file instead of file.

	      If  any  arguments arg are given, they become the positional parameters; the old positional parameters are restored when the
	      file is done executing.  How‐ ever, if no arguments are given, the positional parameters remain those of the calling context,
	      and no restoring is done.

	      If file was not found the return status is 127; if file was found but contained a syntax error the return status is 126; else the
	      return  status  is  the exit status of the last command executed.

       : [ arg ... ]
	      This command does nothing, although normal argument expansions is performed which may have effects on shell parameters.
	      A zero exit status is returned.

       alias [ {+|-}gmrsL ] [ name[=value] ... ]
	      For  each name with a corresponding value, define an alias with that value.	A trailing space in value causes the next
	      word to be checked for alias expan‐ sion.  If the -g flag is present, define a global alias; global aliases are expanded
	      even if they do not occur in command position.

	      If the -s flag is present, define a suffix alias: if the command word on a command line is in the form 'text.name', where text
	      is any non-empty string, it is  replaced	by  the  text 'value text.name'.  Note that name is treated as a literal string,
	      not a pattern.  A trailing space in value is not special in this case.  For example,

		     alias -s ps=gv

	      will cause the command '*.ps' to be expanded to 'gv *.ps'.  As alias expansion is carried out earlier than globbing, the
	      '*.ps'  will  then  be  expanded.  Suffix  aliases  constitute a different name space from other aliases (so in the above example
	      it is still possible to create an alias for the command ps) and the two sets are never listed together.

	      For each name with no value, print the value of name, if any.  With no arguments, print all currently defined aliases other than
	      suffix aliases.	If  the -m  flag  is  given  the arguments are taken as patterns (they should be quoted to preserve them from
	      being interpreted as glob patterns), and the aliases matching these patterns are printed.  When printing aliases and one of the
	      -g, -r or -s flags is present, restrict the printing to global, regular or suf‐ fix aliases, respectively; a regular alias is
	      one which is neither a global nor a suffix alias.   Using '+' instead of '-', or ending the option list with a single '+',
	      prevents the values of the aliases from being printed.

	      If the -L flag is present, then print each alias in a manner suitable for putting in a startup script.  The exit status is
	      nonzero  if  a  name  (with  no value) is given for which no alias has been defined.

	      For more on aliases, include common problems, see the section ALIASING in zshmisc(1).

       autoload [ {+|-}RTUXdkmrtWz ] [ -w ] [ name ... ]
	      See  the	section  'Autoloading  Functions' in zshmisc(1) for full details.  The fpath parameter will be searched to find
	      the function definition when the function is first referenced.

	      If name consists of an absolute path, the function is defined to load from the file given (searching as usual for dump files
	      in the given location).	The name  of  the function is the basename (non-directory part) of the file.  It is normally an
	      error if the function is not found in the given location; how‐ ever, if the option -d is given, searching for the function
	      defaults to \${fpath}.  If a function is loaded by absolute path, any functions  loaded  from  it that are marked for autoload
	      without an absolute path have the load path of the parent function temporarily prepended to \${fpath}.

	      If the option -r or -R is given, the function is searched for immediately and the location is recorded internally for use
	      when the function is executed; a relative path is expanded using the value of \${PWD}.	This protects against a change to
	      \${fpath} after the call to autoload.  With -r, if the function is not found,  it  is silently left unresolved until execution;
	      with -R, an error message is printed and command processing aborted immediately the search fails, i.e. at the autoload
	      command rather than at function execution..

	      The flag -X may be used only inside a shell function.  It causes the calling function to be marked for autoloading and then
	      immediately  loaded  and	exe‐ cuted, with the current array of positional parameters as arguments.  This replaces the previous
	      definition of the function.  If no function definition is found, an error is printed and the function remains undefined and
	      marked for autoloading.  If an argument is given, it is used as  a  directory	(i.e.  it does	not  include the name of
	      the function) in which the function is to be found; this may be combined with the -d option to allow the function search
	      to default to \${fpath} if it is not in the given location.

	      The flag +X attempts to load each name as an autoloaded function, but does not execute it.	The exit status is zero (success) if
	      the function was not pre‐ viously  defined  and a definition for it was found.  This does not replace any existing definition
	      of the function.	The exit status is nonzero (failure) if the function was already defined or when no definition was found.
	      In the latter case the function remains undefined and marked for  autoloading.   If ksh-style	autoloading is enabled,
	      the function created will contain the contents of the file plus a call to the function itself appended to it, thus giv‐
	      ing normal ksh autoloading behaviour on the first call to the function.  If the -m flag is also given each name is treated
	      as a pattern and all  functions already marked for autoload that match the pattern are loaded.

	      With the -t flag, turn on execution tracing; with -T, turn on execution tracing only for the current function, turning
	      it off on entry to any called func‐ tions that do not also have tracing enabled.

	      With the -U flag, alias expansion is suppressed when the function is loaded.

	      With the -w flag, the names are taken as names of files compiled with the zcompile builtin, and all functions defined in them
	      are marked for autoloading.

	      The flags -z and -k mark the function to be autoloaded using the zsh or ksh style, as if the option KSH_AUTOLOAD were unset
	      or  were	set,  respectively.  The flags override the setting of the option at the time the function is loaded.

	      Note  that  the  autoload  command makes no attempt to ensure the shell options set during the loading or execution of the
	      file have any particular value.  For this, the emulate command can be used:

		     emulate zsh -c 'autoload -Uz func'

	      arranges that when func is loaded the shell is in native zsh emulation, and this emulation is also applied when func is run.

	      Some of the functions of autoload are also provided by functions -u or functions -U, but autoload is a more comprehensive
	      interface.

       bg [ job ... ] job ... &
	      Put each specified job in the background, or the current job if none is specified.

       bindkey
	      See the section 'Zle Builtins' in zshzle(1).

       break [ n ]
	      Exit from an enclosing for, while, until, select or repeat loop. If an arithmetic expression n is specified, then break
	      n levels instead of just one.

       builtin name [ args ... ]
	      Executes the builtin name, with the given args.

       bye    Same as exit.

       cap    See the section 'The zsh/cap Module' in zshmodules(1).

       cd [ -qsLP ] [ arg ] cd [ -qsLP ] old new cd [ -qsLP ] {+|-}n Change the current directory.  In the first form, change the
	      current directory to arg, or to the value of \${HOME} if arg is not specified.  If arg  is  '-', change to the previous directory.

	      Otherwise, if arg begins with a slash, attempt to change to the directory given by arg.

	      If  arg  does  not begin with a slash, the behaviour depends on whether the current directory '.' occurs in the list of
	      directories contained in the shell parameter cdpath.  If it does not, first attempt to change to the directory arg under
	      the current directory, and if that fails but cdpath is set and  con‐ tains  at least one element attempt to change
	      to the directory arg under each component of cdpath in turn until successful.  If '.' occurs in cdpath, then cdpath is
	      searched strictly in order so that '.' is only tried at the appropriate point.

	      The order of testing cdpath is modified if the option POSIX_CD is set, as described in the documentation for the option.

	      If no directory is found, the option CDABLE_VARS is set, and a parameter named arg exists whose value begins with a slash,
	      treat its value as  the  direc‐ tory.  In that case, the parameter is added to the named directory hash table.

	      The second form of cd substitutes the string new for the string old in the name of the current directory, and tries to change
	      to this new directory.

	      The  third form of cd extracts an entry from the directory stack, and changes to that directory.  An argument of the form '+n'
	      identifies a stack entry by counting from the left of the list shown by the dirs command, starting with zero.  An argument of
	      the form '-n' counts from the right.  If the PUSHD_MINUS option is set, the meanings of '+' and '-' in this context are swapped.

	      If the -q (quiet) option is specified, the hook function chpwd and the functions in the array chpwd_functions are not called.
	      This is useful for calls to cd that do not change the environment seen by an interactive user.

	      If the -s option is specified, cd refuses to change the current directory if the given pathname contains symlinks.  If the  -P
	      option  is  given  or  the CHASE_LINKS  option is set, symbolic links are resolved to their true values.	If the -L option is
	      given symbolic links are retained in the directory (and not resolved) regardless of the state of the CHASE_LINKS option.

       chdir  Same as cd.

       clone  See the section 'The zsh/clone Module' in zshmodules(1).

       command [ -pvV ] simple command
	      The simple command argument is taken as an external command instead of a function or builtin and  is	executed.  If  the
	      POSIX_BUILTINS  option  is  set, builtins  will also be executed but certain special properties of them are suppressed. The
	      -p flag causes a default path to be searched instead of that in \${path}. With the -v flag, command is similar to whence and
	      with -V, it is equivalent to whence -v.

	      See also the section 'Precommand Modifiers' in zshmisc(1).

       comparguments
	      See the section 'The zsh/computil Module' in zshmodules(1).

       compcall
	      See the section 'The zsh/compctl Module' in zshmodules(1).

       compctl
	      See the section 'The zsh/compctl Module' in zshmodules(1).

       compdescribe
	      See the section 'The zsh/computil Module' in zshmodules(1).

       compfiles
	      See the section 'The zsh/computil Module' in zshmodules(1).

       compgroups
	      See the section 'The zsh/computil Module' in zshmodules(1).

       compquote
	      See the section 'The zsh/computil Module' in zshmodules(1).

       comptags
	      See the section 'The zsh/computil Module' in zshmodules(1).

       comptry
	      See the section 'The zsh/computil Module' in zshmodules(1).

       compvalues
	      See the section 'The zsh/computil Module' in zshmodules(1).

       continue [ n ]
	      Resume the next iteration of the enclosing for, while,
	      until, select or repeat loop. If an arithmetic expression n
	      is specified, break out  of  n-1	loops and resume at the nth
	      enclosing loop.

       declare
	      Same as typeset.

       dirs [ -c ] [ arg ... ] dirs [ -lpv ]
	      With no arguments, print the contents of the directory stack.  Directories are added to this stack with the pushd command,
	      and removed with the cd or popd commands.  If arguments are specified, load them onto the directory stack, replacing
	      anything that was there, and push  the  current  directory onto  the stack.

	      -c     clear the directory stack.

	      -l     print directory names in full instead of using of
	      using ~ expressions (see Dynamic and Static named directories in zshexpn(1)).

	      -p     print directory entries one per line.

	      -v     number the directories in the stack when printing.

       disable [ -afmprs ] name ...
	      Temporarily  disable  the  named hash table elements or patterns.  The default is to disable builtin commands.
	      This allows you to use an external command with the same name as a builtin command.  The -a option causes disable to act
	      on regular or global aliases.  The -s option causes disable to act on suffix aliases.  The -f option causes disable to
	      act on shell functions.  The -r options causes disable to act on reserved words.  Without arguments all disabled hash
	      table elements from the corresponding hash table are printed.  With the -m flag the arguments are taken as patterns (which
	      should be quoted	to  pre‐ vent  them  from undergoing filename expansion), and all hash table elements from the
	      corresponding hash table matching these patterns are disabled.  Dis‐ abled objects can be enabled with the enable command.

	      With the option -p, name ... refer to elements of the shell's pattern syntax as described in the section 'Filename Generation'.
	      Certain elements	can  be disabled separately, as given below.  
	      Note  that  patterns  not allowed by the current settings for the options EXTENDED_GLOB, KSH_GLOB and SH_GLOB are never enabled,
	      regardless of the setting here.  For example, if EXTENDED_GLOB is not active, the pattern ^ is ineffective even if 'disable
	      -p "^"' has not been issued.  The list  below  indicates any  option  settings  that restrict the use of the pattern.
	      It should be noted that setting SH_GLOB has a wider effect than merely disabling patterns as certain expressions, in
	      particular those involving parentheses, are parsed differently.

	      The following patterns may be disabled; all the strings need quoting on the command line to prevent them from being
	      interpreted  immediately	as  patterns and the patterns are shown below in single quotes as a reminder.

	      '?'    The pattern character ? wherever it occurs, including when preceding a parenthesis with KSH_GLOB.

	      '*'    The pattern character * wherever it occurs, including recursive globbing and when preceding a parenthesis with KSH_GLOB.

	      '['    Character classes.

	      '<' (NO_SH_GLOB)
		     Numeric ranges.

	      '|' (NO_SH_GLOB)
		     Alternation in grouped patterns, case statements, or KSH_GLOB parenthesised expressions.

	      '(' (NO_SH_GLOB)
		     Grouping  using  single  parentheses.   Disabling	this does not disable the use of parentheses for KSH_GLOB
		     where they are introduced by a special character, nor for glob qualifiers (use 'setopt NO_BARE_GLOB_QUAL'
		     to disable glob qualifiers that use parentheses only).

	      '~' (EXTENDED_GLOB)
		     Exclusion in the form A~B.

	      '^' (EXTENDED_GLOB)
		     Exclusion in the form A^B.

	      '#' (EXTENDED_GLOB)
		     The pattern character # wherever it occurs, both for repetition of a previous pattern and for indicating globbing flags.

	      '?(' (KSH_GLOB)
		     The grouping form ?(...).	Note this is also disabled if '?' is disabled.

	      '*(' (KSH_GLOB)
		     The grouping form *(...).	Note this is also disabled if '*' is disabled.

	      '+(' (KSH_GLOB)
		     The grouping form +(...).

	      '!(' (KSH_GLOB)
		     The grouping form !(...).

	      '@(' (KSH_GLOB)
		     The grouping form @(...).

       disown [ job ... ] job ... &| job ... &!
	      Remove the specified jobs from the job table; the shell will no longer report their status, and will not complain if you try
	      to exit an interactive  shell with them running or stopped.  If no job is specified, disown the current job.

	      If  the  jobs  are  currently  stopped and the AUTO_CONTINUE option is not set, a warning is printed containing information
	      about how to make them running after they have been disowned.  If one of the latter two forms is used, the jobs will
	      automatically be made running, independent of  the  setting of  the AUTO_CONTINUE option.

       echo [ -neE ] [ arg ... ]
	      Write  each arg on the standard output, with a space separating each one.  If the -n flag is not present, print a newline at
	      the end.	echo recognizes the following escape sequences:

	      \a     bell character \b	   backspace \c     suppress subsequent characters and final newline \e	  escape \f	form feed \n
	      linefeed (newline) \r	carriage return \t     horizontal tab \v	 vertical tab \\     backslash \0NNN  character code
	      in octal \xNN   character code in hexadecimal \uNNNN unicode character code in hexadecimal \UNNNNNNNN unicode character code in hexadecimal

	      The -E flag, or the BSD_ECHO option, can be used to disable these escape sequences.  In the latter case, -e flag can be
	      used to enable them.

       echotc See the section 'The zsh/termcap Module' in zshmodules(1).

       echoti See the section 'The zsh/terminfo Module' in zshmodules(1).

       emulate [ -lLR ] [ {zsh|sh|ksh|csh} [ flags ... ] ]
	      Without any argument print current emulation mode.

	      With single argument set up zsh options to emulate the specified shell as much as possible.  csh will never be fully emulated.
	      If the argument is not one of the shells listed above, zsh will be used as a default; more precisely, the tests performed
	      on the argument are the same as those used to determine the emulation at startup based on the shell name, see the section
	      COMPATIBILITY in zsh(1) .  In addition to setting shell options, the command  also  restores the pristine state of pattern
	      enables, as if all patterns had been enabled using enable -p.

	      If  the  emulate	command  occurs  inside a function that has been marked for execution tracing with functions -t then the
	      xtrace option will be turned on regardless of emulation mode or other options.  Note that code executed inside the function
	      by the ., source, or eval commands is  not  considered  to be running directly from the function, hence does not provoke
	      this behaviour.

	      If the -R switch is given, all settable options are reset to their default value corresponding to the specified emulation
	      mode, except for certain options describing the interactive environment; otherwise, only those options likely to cause
	      portability problems in scripts and functions are altered.  If  the -L  switch  is  given,  the  options LOCAL_OPTIONS,
	      LOCAL_PATTERNS and LOCAL_TRAPS will be set as well, causing the effects of the emulate command and any setopt, disable -p
	      or enable -p, and trap commands to be local to the immediately surrounding shell function, if any; normally these  options
	      are  turned off in all emulation modes except ksh. The -L switch is mutually exclusive with the use of -c in flags.

	      If  there  is a single argument and the -l switch is given, the options that would be set or unset (the latter indicated
	      with the prefix 'no') are listed.  -l can be combined with -L or -R and the list will be modified in the appropriate way.
	      Note the list does not depend on the current setting  of options, i.e. it includes all options that may in principle
	      change, not just those that would actually change.

	      The  flags  may  be  any	of  the invocation-time flags described in the section INVOCATION in zsh(1), except that '-o EMACS' and
	      '-o VI' may not be used.	Flags such as '+r'/'+o RESTRICTED' may be prohibited in some circumstances.

	      If -c arg appears in flags, arg is evaluated while the requested emulation is temporarily in effect.  In this case the emulation
	      mode and all options  are restored  to  their  previous values before emulate returns.  The -R switch may precede the name
	      of the shell to emulate; note this has a meaning distinct from including -R in flags.

	      Use of -c enables 'sticky' emulation mode for functions defined within the evaluated expression:	the emulation mode
	      is  associated  thereafter  with	the function  so  that whenever	the  function is executed the emulation (respecting
	      the -R switch, if present) and all options are set (and pattern disables cleared) before entry to the function, and the state
	      is restored after exit.  If the function is called when the sticky emulation is  already  in	effect, either	within	an
	      'emulate shell -c' expression or within another function with the same sticky emulation, entry and exit from the function
	      do not cause options to be altered (except due to standard processing such as the LOCAL_OPTIONS option).  This also applies
	      to functions marked for autoload within the sticky emulation; the appropriate set of options will be applied at the point
	      the function is loaded as well as when it is run.

	      For example:

		     emulate sh -c 'fni() { setopt cshnullglob; } fno() {
		     fni; }' fno

	      The  two	functions fni and fno are defined with sticky sh emulation.  fno is then executed, causing options associated
	      with emulations to be set to their values in sh.	fno then calls fni; because fni is also marked for sticky sh emulation,
	      no option changes take place on entry to or exit	from  it.  Hence the  option  cshnullglob,  turned off by sh emulation,
	      will be turned on within fni and remain on return to fno.  On exit from fno, the emulation mode and all options will
	      be restored to the state they were in before entry to the temporary emulation.

	      The documentation above is typically sufficient for the intended purpose of executing code designed for other shells
	      in  a  suitable  environment.   More detailed rules follow.  

		  1.     The sticky emulation environment provided by 'emulate shell -c' is identical to that provided by entry to a function marked 
		  for sticky emulation as a consequence of being defined in such an environment.  Hence, for example, the sticky emulation is inherited 
		  by subfunctions defined within  func‐ tions with sticky emulation.

	      2.     No  change of options takes place on entry to or exit from functions that are not marked for sticky emulation,
	      other than those that would normally take place, even if those functions are called within sticky emulation.

	      3.     No special handling is provided for functions marked for autoload nor for functions present in wordcode created by
	      the zcompile command.  4.     The presence or absence of the -R switch to emulate corresponds to different sticky emulation
	      modes, so for example 'emulate sh -c', 'emulate -R sh -c' and 'emulate csh -c' are treated as three distinct sticky emulations.

	      5.     Difference  in shell options supplied in addition to the basic emulation also mean the sticky emulations are different,
	      so for example 'emulate zsh -c' and 'emulate zsh -o cbases -c' are treated as distinct sticky emulations.

       enable [ -afmprs ] name ...
	      Enable the named hash table elements, presumably disabled earlier with disable.  The default is to enable builtin commands.  The -a
	      option  causes  enable to  act  on regular or global aliases.  The -s option causes enable to act on suffix aliases.  The -f
	      option causes enable to act on shell functions.  The -r option causes enable to act on reserved words.  Without arguments all
	      enabled hash table elements from the corresponding hash table are printed.   With the  -m  flag the arguments are taken as
	      patterns (should be quoted) and all hash table elements from the corresponding hash table matching these patterns are enabled.
	      Enabled objects can be disabled with the disable builtin command.

	      enable -p reenables patterns disabled with disable -p.  Note that it does not override globbing options; for example, 'enable -p
	      "~"' does not  cause  the pattern  character ~ to be active unless the EXTENDED_GLOB option is also set.  To enable all
	      possible patterns (so that they may be individually disabled with disable -p), use 'setopt EXTENDED_GLOB KSH_GLOB NO_SH_GLOB'.

       eval [ arg ... ]
	      Read the arguments as input to the shell and execute the resulting command(s) in the current shell process.  The return
	      status is the same as if the  com‐ mands had been executed directly by the shell; if there are no args or they contain no
	      commands (i.e. are an empty string or whitespace) the return status is zero.

       exec [ -cl ] [ -a argv0 ] [ command [ arg ... ] ]
	      Replace the current shell with command rather than forking.  If command is a shell builtin command or a shell function,
	      the shell executes it, then  imme‐ diately exits.

	      With  -c clear the environment; with -l prepend - to the argv[0] string of the command executed (to simulate a login shell);
	      with -a argv0 set the argv[0] string of the command executed.
	      See the section 'Precommand Modifiers' in zshmisc(1).

	      If the option POSIX_BUILTINS is set, command is never interpreted as a shell builtin command or shell function.
	      This means further  precommand  modifiers such as builtin and noglob are also not interpreted within the shell.  Hence command
	      is always found by searching the command path.

	      If command is omitted but any redirections are specified, then the redirections will take effect in the current shell.

       exit [ n ]
	      Exit the shell with the exit status specified by an arithmetic expression n; if none is specified, use the exit status from
	      the last command executed.  An EOF condition will also cause the shell to exit, unless the IGNORE_EOF option is set.

	      See notes at the end of the section JOBS in zshmisc(1) for some possibly unexpected interactions of the exit command with jobs.

       export [ name[=value] ... ]
	      The specified names are marked for automatic export to the environment of subsequently executed commands.  Equivalent to
	      typeset  -gx.   If  a  parameter specified does not already exist, it is created in the global scope.

       false [ arg ... ]
	      Do nothing and return an exit status of 1.

       fc [ -e ename ] [ -LI ] [ -m match ] [ old=new ... ] [ first [ last ] ] 
	   fc -l [ -LI ] [ -nrdfEiD ] [ -t timefmt ] [ -m match ] [ old=new ... ] [ first [ last ] ]
       fc -p [ -a ] [ filename [ histsize [ savehistsize ] ] ] fc -P fc -ARWI [ filename ]
	      The  fc  command	controls the interactive history mechanism.  Note that reading and writing of history options is only
	      performed if the shell is interac‐ tive.  Usually this is detected automatically, but it can be forced by setting the
	      interactive option when starting the shell.

	      The first two forms of this command select a range of events from first to last from the history list.  The arguments
	      first and last may be specified as a number  or  as  a string.  A negative number is used as an offset to the current history
	      event number.  A string specifies the most recent event beginning with the given string.	All substitutions old=new,
	      if any, are then performed on the text of the events.

	      In addition to the number range, -I     restricts to only internal events (not from \${HISTFILE}) -L	  restricts to
	      only local events (not from other shells, see SHARE_HISTORY in zshoptions(1) -- note that \${HISTFILE} is considered local
	      when  read  at startup) -m     takes the first argument as a pattern (should be quoted)
	      and only the history events matching this pattern are considered

	      If  first  is not specified, it will be set to -1 (the most recent event), or to -16 if the -l flag is given.  If last is
	      not specified, it will be set to first, or to -1 if the -l flag is given.  However, if the current event has added entries to the
	      history with 'print -s' or 'fc -R', then the default last for -l includes all new history entries since the current event began.

	      When  the  -l flag is given, the resulting events are listed on standard output.  Otherwise the editor program ename is
	      invoked on a file containing these history events.  If ename is not given, the value of the parameter FCEDIT is used; if
	      that is not set the value of the parameter EDITOR is used; if  that is not set a builtin default, usually 'vi' is used.
	      If ename is '-', no editor is invoked.  When editing is complete, the edited command is executed.

	      The flag -r reverses the order of the events and the flag -n suppresses event numbers when listing.

	      Also when listing, -d	prints timestamps for each event -f prints full time-date stamps in the US 'MM/DD/YY hh:mm' format
	      -E     prints full time-date stamps in the European 'dd.mm.yyyy hh:mm' format -i	   prints full time-date stamps in ISO8601
	      'yyyy-mm-dd hh:mm' format -t fmt prints  time  and date stamps in the given format; fmt is formatted with the strftime function
	      with the zsh extensions described for the %D{string} prompt format in the section EXPANSION OF PROMPT SEQUENCES
		     in zshmisc(1).  The resulting formatted string must be no more than  256	characters  or will not be printed
	      -D     prints elapsed times; may be combined with one of the options above

	      'fc  -p'	pushes	the current history list onto a stack and switches to a new history list.  If the -a option is also
	      specified, this history list will be automatically popped when the current function scope is exited, which is a much
	      better solution than creating a trap function to call  'fc  -P' manually.  If  no  arguments  are  specified,  the history list
	      is left empty, \${HISTFILE} is unset, and \${HISTSIZE} & \${SAVEHIST} are set to their default values.	If one argument is given,
	      \${HISTFILE} is set to that filename, \${HISTSIZE} & \${SAVEHIST} are left unchanged, and the history file is read in (if it exists)
	      to initial‐ ize  the  new  list.  If a second argument is specified, \${HISTSIZE} & \${SAVEHIST} are instead set to the single
	      specified numeric value.	Finally, if a third argument is specified, \${SAVEHIST} is set to a separate value from \${HISTSIZE}.
	      You are free to change these environment values for the new history list how‐ ever you desire in order to manipulate
	      the new history list.

	      'fc  -P'	pops  the history list back to an older list saved by 'fc -p'.  The current list is saved to its \${HISTFILE} before
	      it is destroyed (assuming that \${HISTFILE} and \${SAVEHIST} are set appropriately, of course).  The values of \${HISTFILE}, \${HISTSIZE},
	      and \${SAVEHIST} are restored to the values they had when 'fc -p' was  called.   Note that this restoration can conflict with
	      making these variables "local", so your best bet is to avoid local declarations for these variables in functions that use
	      'fc -p'.	The one other guaranteed-safe combination is declaring these variables to be local at the top of  your  function and
	      using the automatic option (-a) with 'fc -p'.  Finally, note that it is legal to manually pop a push marked for automatic
	      popping if you need to do so before the function exits.

	      'fc -R' reads the history from the given file, 'fc -W' writes the history out to the given file, and 'fc -A' appends the history
	      out to  the  given  file.  If  no  filename  is  specified, the  \${HISTFILE} is assumed.  If the -I option is added to -R,
	      only those events that are not already contained within the internal history list are added.	If the -I option is added to
	      -A or -W, only those events that are new since last incremental append/write to the history file are appended/written.  In any
	      case, the created file will have no more than \${SAVEHIST} entries.

       fg [ job ... ] job ...
	      Bring each specified job in turn to the foreground.  If no job is specified, resume the current job.

       float [ {+|-}Hghlprtux ] [ {+|-}EFLRZ [ n ] ] [ name[=value] ... ]
	      Equivalent to typeset -E, except that options irrelevant to floating point numbers are not permitted.

       functions [ {+|-}UkmtTuWz ] [ -x num ] [ name ... ] functions -M [-s] mathfn [ min [ max [ shellfn ] ] ] functions -M [ -m pattern ... ]
       functions +M [ -m ] mathfn ...
	      Equivalent  to  typeset  -f,  with the exception of the -x, -M and -W options.  For functions -u and functions -U, see
	      autoload, which provides additional options.

	      The -x option indicates that any functions output will have each leading tab for indentation, added by the shell to show
	      syntactic structure, expanded  to the given number num of spaces.  num can also be 0 to suppress all indentation.

	      The  -W  option  turns  on the option WARN_NESTED_VAR for the named function or functions only.  The option is turned off at
	      the start of nested functions (apart from anonoymous functions) unless the called function also has the -W attribute.

	      Use of the -M option may not be combined with any of the options handled by typeset -f.

	      functions -M mathfn defines mathfn as the name of a mathematical function recognised in all forms of arithmetical expressions;
	      see the section 'Arithmetic Evaluation'  in  zshmisc(1).  By default mathfn may take any number of comma-separated
	      arguments.  If min is given, it must have exactly min args; if min and max are both given, it must have at least min and
	      at most max args.  max may be -1 to indicate that there is no upper limit.

	      By default the function is implemented by a shell function of the same name; if shellfn is specified it gives the name of
	      the corresponding shell function while mathfn remains the name used in arithmetical expressions.  The name of the function in
	      \${0} is mathfn (not shellfn as would usually be the case), pro‐ vided the option FUNCTION_ARGZERO is in effect.  The positional
	      parameters in the shell function correspond to the arguments of the mathematical  function call.  The result of the last
	      arithmetical expression evaluated inside the shell function (even if it is a form that normally only returns a status)
	      gives the result of the mathematical function.

	      If the additional option -s is given to functions -M, the argument to the function is a single string: anything between
	      the opening and  matching  closing parenthesis  is  passed to the function as a single argument, even if it includes commas
	      or white space.  The minimum and maximum argument specifiers must therefore be 1 if given.  An empty argument list is passed
	      as a zero-length string.

	      functions -M with no arguments lists all such user-defined
	      functions in the same form as a definition.  With the additional option -m and a list of  argu‐ ments, all functions whose
	      mathfn matches one of the pattern arguments are listed.

	      function +M removes the list of mathematical functions; with the additional option -m the arguments are treated as
	      patterns and all functions whose mathfn matches the pattern are removed.  Note that the shell function implementing the
	      behaviour is not removed (regardless of whether its  name
	      coincides  with mathfn).

	      For example, the following prints the cube of 3:

		     zmath_cube() { (( \${1} * \${1} * \${1} )) } functions -M cube
		     1 1 zmath_cube print \$(( cube(3) ))

	      The following string function takes a single argument, including
	      the commas, so prints 11:

		     stringfn() { (( \${#1} )) } functions -Ms stringfn print \$(( stringfn(foo,bar,rod) ))

       getcap See the section 'The zsh/cap Module' in zshmodules(1).

       getln [ -AclneE ] name ...
	      Read the top value from the buffer stack and put it in the shell parameter name.  Equivalent to read -zr.

       getopts optstring name [ arg ... ]
	      Checks the args for legal options.  If the args are omitted, use the positional parameters.  A valid option argument begins
	      with a '+' or a '-'.  An argu‐ ment not beginning with a '+' or a '-', or the argument '--', ends the options.  Note that a
	      single '-' is not considered a valid option  argument.   opt‐ string  contains	the  letters that getopts recognizes.  If a
	      letter is followed by a ':', that option requires an argument.  The options can be separated from the argument by blanks.

	      Each time it is invoked, getopts places the option letter it finds in the shell parameter name, prepended with a '+' when
	      arg  begins  with  a  '+'.   The index of the next arg is stored in OPTIND.  The option argument, if any, is stored in OPTARG.

	      The  first  option to be examined may be changed by explicitly assigning to OPTIND.  OPTIND has an initial value of 1, and is
	      normally set to 1 upon entry to a shell function and restored upon exit (this is disabled by the POSIX_BUILTINS option).
	      OPTARG is not reset and  retains	its  value  from  the  most recent  call to getopts.	If either of OPTIND or OPTARG is
	      explicitly unset, it remains unset, and the index or option argument is not stored.  The option itself is still stored in
	      name in this case.

	      A leading ':' in optstring causes getopts to store the letter of any invalid option in OPTARG, and to set name to '?' for
	      an unknown  option  and  to  ':' when  a	required  argument is  missing.   Otherwise, getopts sets name to '?' and prints
	      an error message when an option is invalid.  The exit status is nonzero when there are no more options.

       hash [ -Ldfmrv ] [ name[=value] ] ...
	      hash can be used to directly modify the contents of the command
	      hash table, and the named directory hash table.  Normally one would modify these tables by modifying  one's  PATH  (for the
	      command hash table) or by creating appropriate shell parameters (for the named directory hash table).  The choice of hash table
	      to work on is determined by the -d option; without the option the command hash table is used, and with the option the named
	      directory hash table  is used.  Given no arguments, and neither the -r or -f options, the
	      selected hash table will be listed in full.

	      The  -r  option  causes  the selected hash table to be emptied.  It will be subsequently rebuilt in the normal fashion.
	      The -f option causes the selected hash table to be fully rebuilt immediately.  For the command hash table this hashes
	      all the absolute directories in the PATH, and for the named directory hash table this adds all users' home directories.
	      These two options cannot be used with any arguments.

	      The  -m  option  causes  the  arguments  to  be  taken as patterns (which should be quoted) and the elements of the hash
	      table matching those patterns are printed.  This is the only way to display a limited selection of hash table elements.

	      For each name with a corresponding value, put 'name' in the selected hash table, associating it with the pathname 'value'.
	      In  the  command	hash  table, this  means  that whenever 'name' is used as a command argument, the shell will try to execute
	      the file given by 'value'.  In the named directory hash ta‐ ble, this means that 'value' may be referred to as '~name'.

	      For each name with no corresponding value, attempt to add name to the hash table, checking what the appropriate value is in
	      the  normal  manner  for	that hash table.  If an appropriate value can't be found, then the hash table will be unchanged.

	      The -v option causes hash table entries to be listed as they are added by explicit specification.  If has no effect if used
	      with -f.

	      If the -L flag is present, then each hash table entry is printed in the form of a call to hash.

       history
	      Same as fc -l.

       integer [ {+|-}Hghlprtux ] [ {+|-}LRZi [ n ] ] [ name[=value] ... ]
	      Equivalent to typeset -i, except that options irrelevant to
	      integers are not permitted.

       jobs [ -dlprs ] [ job ... ] jobs -Z string
	      Lists  information  about  each given job, or all jobs if
	      job is omitted.  The -l flag lists process IDs, and the -p
	      flag lists process groups.  If the -r flag is specified only
	      running jobs will be listed and if the -s flag is given only
	      stopped jobs are shown.  If the -d flag is given, the  directory
	      from which the job was started (which may not be the current
	      directory of the job) will also be shown.

	      The  -Z option replaces the shell's argument and environment
	      space with the given string, truncated if necessary to fit.
	      This will normally be visible in ps (ps(1)) listings.  This
	      feature is typically used by daemons, to indicate their state.

       kill [ -s signal_name | -n signal_number | -sig ] job ...  kill -l [ sig ... ]
	      Sends either SIGTERM or the specified signal to the given jobs or processes.  Signals are given by number or by names,
	      with or without the  'SIG'  prefix.  If the signal being sent is not 'KILL' or 'CONT', then the job will be sent a 'CONT'
	      signal if it is stopped.	The argument job can be the process ID of a job not in the job list.	In the second form, kill -l,
	      if sig is not specified the signal names are listed.  Otherwise, for each sig that is a  name,  the corresponding signal number
	      is listed.  For each sig that is a signal number or a number representing the exit status of a process which was terminated
	      or stopped by a signal the name of the signal is printed.

	      On some systems, alternative signal names are allowed for a few signals.	Typical examples are SIGCHLD and SIGCLD or SIGPOLL and
	      SIGIO, assuming they cor‐ respond to the same signal number.  kill -l will only list the preferred form, however kill -l
	      alt will show if the alternative form corresponds to a sig‐ nal number.  For example, under Linux kill -l IO and kill -l
	      POLL both output 29, hence kill -IO and kill -POLL have the
	      same effect.

	      Many systems will allow process IDs to be negative to kill a
	      process group or zero to kill the current process group.

       let arg ...
	      Evaluate each arg as an arithmetic expression.  See the section 'Arithmetic Evaluation' in zshmisc(1) for a description of
	      arithmetic  expressions.	 The exit status is 0 if the value of the last expression is nonzero, 1 if it is zero, and 2 if
	      an error occurred.

       limit [ -hs ] [ resource [ limit ] ] ...
	      Set  or  display resource limits.  Unless the -s flag is given, the limit applies only the children of the shell.  If -s is given
	      without other arguments, the resource limits of the current shell is set to the previously set resource limits of the children.

	      If limit is not specified, print the current limit placed on resource, otherwise set the limit to the specified value.
	      If the -h flag is given, use  hard limits instead of soft limits.  If no resource is given, print all limits.

	      When  looping  over  multiple  resources, the shell will abort immediately if it detects a badly formed argument.  However,
	      if it fails to set a limit for some other reason it will continue trying to set the remaining limits.

	      resource can be one of:

	      addressspace
		     Maximum amount of address space used.
	      aiomemorylocked
		     Maximum amount of memory locked in RAM for AIO operations.
	      aiooperations
		     Maximum number of AIO operations.
	      cachedthreads
		     Maximum number of cached threads.
	      coredumpsize
		     Maximum size of a core dump.
	      cputime
		     Maximum CPU seconds per process.
	      datasize
		     Maximum data size (including stack) for each process.
	      descriptors
		     Maximum value for a file descriptor.
	      filesize
		     Largest single file allowed.
	      kqueues
		     Maximum number of kqueues allocated.
	      maxproc
		     Maximum number of processes.
	      maxpthreads
		     Maximum number of threads per process.
	      memorylocked
		     Maximum amount of memory locked in RAM.
	      memoryuse
		     Maximum resident set size.
	      msgqueue
		     Maximum number of bytes in POSIX message queues.
	      posixlocks
		     Maximum number of POSIX locks per user.
	      pseudoterminals
		     Maximum number of pseudo-terminals.
	      resident
		     Maximum resident set size.
	      sigpending
		     Maximum number of pending signals.
	      sockbufsize
		     Maximum size of all socket buffers.
	      stacksize
		     Maximum stack size for each process.
	      swapsize
		     Maximum amount of swap used.
	      vmemorysize
		     Maximum amount of virtual memory.

	      Which of these resource limits are available depends on the system.  resource can be abbreviated to any unambiguous prefix.
	      It can also  be  an  integer, which corresponds to the integer defined for the resource by the operating system.

	      If  argument  corresponds  to a number which is out of the range of the resources configured into the shell, the shell
	      will try to read or write the limit anyway, and will report an error if this fails.  As the shell does not store such
	      resources internally, an attempt to set the limit will fail unless  the -s option is present.

	      limit is a number, with an optional scaling factor, as follows:

	      nh     hours nk	  kilobytes (default) nm     megabytes or minutes ng     gigabytes [mm:]ss minutes and seconds

	      The  limit  command  is  not made available by default when the shell starts in a mode emulating another shell.  It can be made
	      available with the command 'zmodload -F zsh/rlimits b:limit'.

       local [ {+|-}AHUahlprtux ] [ {+|-}EFLRZi [ n ] ] [ name[=value] ... ]
	      Same as typeset, except that the options -g, and -f are not permitted.  In this case the -x option does not force the use
	      of -g, i.e.  exported  variables will be local to functions.

       log    List all users currently logged in who are affected by the current setting of the watch parameter.

       logout [ n ]
	      Same as exit, except that it only works in a login shell.

       noglob simple command
	      See the section 'Precommand Modifiers' in zshmisc(1).

       popd [ -q ] [ {+|-}n ]
	      Remove  an entry from the directory stack, and perform a cd to the new top directory.  With no argument, the current top
	      entry is removed.  An argument of the form '+n' identifies a stack entry by counting from the left of the list shown by the
	      dirs command, starting with zero.  An argument of  the  form -n counts from the right.  If the PUSHD_MINUS option is set,
	      the meanings of '+' and '-' in this context are swapped.

	      If the -q (quiet) option is specified, the hook function chpwd and the functions in the array \${chpwd_functions} are not called,
	      and the new directory stack is not printed.  This is useful for calls to popd that do not change the environment seen by
	      an interactive user.

       print [ -abcDilmnNoOpPrsSz ] [ -u n ] [ -f format ] [ -C cols ] [ -v name ] [ -xX tabstop ] [ -R [ -en ]] [ arg ... ]
	      With the '-f' option the arguments are printed as described by printf.  With no flags or with the flag '-', the arguments
	      are printed on the standard out‐ put  as  described  by echo, with the following differences: the escape sequence '\M-x'
	      (or '\Mx') metafies the character x (sets the highest bit), '\C-x' (or '\Cx') produces a control character ('\C-@' and
	      '\C-?' give the characters NULL and delete), a character	code in  octal  is  represented  by  '\NNN' (instead of '\0NNN'),
	      and '\E' is a synonym for '\e'.  Finally, if not in an escape sequence, '' escapes the following character and is not printed.

	      -a     Print arguments with the column incrementing first.  Only useful with the -c and -C options.

	      -b     Recognize all the escape sequences defined for the bindkey command, see the section 'Zle Builtins' in zshzle(1).

	      -c     Print the arguments in columns.  Unless -a is also given, arguments are printed with the row incrementing first.

	      -C cols
		     Print the arguments in cols columns.  Unless -a is also given, arguments are printed with the row incrementing first.

	      -D     Treat the arguments as paths, replacing directory prefixes with ~ expressions corresponding to directory names,
	      as appropriate.

	      -i     If given together with -o or -O, sorting is performed case-independently.

	      -l     Print the arguments separated by newlines instead of spaces.

	      -m     Take  the first argument as a pattern (should be quoted), and remove it from the argument list together with subsequent
	      arguments that do not match this pattern.

	      -n     Do not add a newline to the output.

	      -N     Print the arguments separated and terminated by nulls.

	      -o     Print the arguments sorted in ascending order.

	      -O     Print the arguments sorted in descending order.

	      -p     Print the arguments to the input of the coprocess.

	      -P     Perform prompt expansion (see EXPANSION OF PROMPT SEQUENCES in zshmisc(1)).  In combination with '-f', prompt
	      escape  sequences  are  parsed  only within interpolated arguments, not within the format string.

	      -r     Ignore the escape conventions of echo.

	      -R     Emulate  the  BSD	echo command, which does not process escape sequences unless the -e flag is given.  The -n flag
	      suppresses the trailing newline.  Only the -e and -n flags are recognized after -R; all other arguments and options are printed.

	      -s     Place the results in the history list instead of on the standard output.  Each argument to the print command is
	      treated as a  single  word  in  the history, regardless of its content.

	      -S     Place  the  results  in  the history list instead of on the standard output.  In this case only a single argument
	      is allowed; it will be split into words as if it were a full shell command line.  The effect
		     is similar to reading the line from  a  history  file with  the	HIST_LEX_WORDS	option active.

	      -u n   Print the arguments to file descriptor n.

	      -v name
		     Store the printed arguments as the value of the parameter name.

	      -x tab-stop
		     Expand leading tabs on each line of output in the printed string assuming a tab stop every tab-stop characters.
		     This is appropriate for formatting code that may be indented with tabs.  Note that leading tabs of any
		     argument to print, not just the first, are expanded, even  if  print  is  using spaces to separate arguments
		     (the column count is maintained across arguments but may be incorrect on output owing to previous unexpanded tabs).

		     The  start  of the output of each print command is assumed to be aligned with a tab stop.  Widths of
		     multibyte characters are handled if the option MULTIBYTE is in effect.  This option is ignored if other formatting
		     options are in effect, namely column alignment or printf style, or if output is to a special location such as
		     shell history or the command line editor.

	      -X tab-stop
		     This  is  similar	to  -x, except that all tabs in the printed string are expanded.  This is appropriate if tabs
		     in the arguments are being used to produce a table format.

	      -z     Push the arguments onto the editing buffer stack, separated by spaces.

	      If any of '-m', '-o' or '-O' are used in combination with '-f' and there are no arguments (after the removal process in the
	      case of '-m') then nothing  is printed.

       printf [ -v name ] format [ arg ... ]
	      Print  the  arguments  according to the format specification. Formatting rules are the same as used in
	      C. The same escape sequences as for echo are recog‐ nised in the format. All C conversion specifications ending in one
	      of csdiouxXeEfgGn are handled. In addition to this, '%b' can be used instead of '%s' to cause  escape  sequences
	      in  the  argument to be recognised and '%q' can be used to quote the argument in such a way that allows it to be
	      reused as shell input. With the numeric format specifiers, if the corresponding argument starts with a quote character,
	      the numeric value of the	following  character  is used  as the number to print; otherwise the argument is evaluated as an
	      arithmetic expression. See the section 'Arithmetic Evaluation' in zshmisc(1) for a description of arithmetic expressions. With
	      '%n', the corresponding argument is taken as an identifier which is created as an integer parameter.

	      Normally, conversion specifications are applied to each argument in order but they can explicitly specify the nth
	      argument is to be used by replacing  '%' by  '%n\$'  and '*' by '*n\$'.  It is recommended that you do not mix references
	      of this explicit style with the normal style and the handling of such mixed styles may be subject to future change.

	      If arguments remain unused after formatting, the format string is reused until all arguments have been consumed. With the
	      print builtin, this can be  sup‐ pressed  by using the -r option. If more arguments are required by the format than have
	      been specified, the behaviour is as if zero or an empty string had been specified as the argument.

	      The -v option causes the output to be stored as the value of the parameter name, instead of printed. If name is an array
	      and the format string  is  reused when consuming arguments then one array element will be used for each use of the format string.

       pushd [ -qsLP ] [ arg ] pushd [ -qsLP ] old new pushd [ -qsLP ] {+|-}n
	      Change  the  current  directory, and push the old current directory onto the directory stack.  In the first form, change
	      the current directory to arg.  If arg is not specified, change to the second directory on the stack (that is, exchange the top
	      two entries), or change to \${HOME} if the PUSHD_TO_HOME  option is  set or if there is only one entry on the stack.  Otherwise,
	      arg is interpreted as it would be by cd.	The meaning of old and new in the second form is also the same as for cd.

	      The third form of pushd changes directory by rotating the directory list.  An argument of the form '+n' identifies a
	      stack entry by counting from the left of	the  list  shown  by the dirs command, starting with zero.  An argument of the form
	      '-n' counts from the right.  If the PUSHD_MINUS option is set, the meanings of '+' and '-' in this context are swapped.

	      If the -q (quiet) option is specified, the hook function chpwd and the functions in the array \${chpwd_functions} are not called,
	      and the new directory stack is not printed.  This is useful for calls to pushd that do not change the environment seen by
	      an interactive user.

	      If the option -q is not specified and the shell option PUSHD_SILENT is not set, the directory stack will be printed
	      after a pushd is performed.

	      The options -s, -L and -P have the same meanings as for the cd builtin.

       pushln [ arg ... ]
	      Equivalent to print -nz.

       pwd [ -rLP ]
	      Print  the absolute pathname of the current working directory.  If the -r or the -P flag is specified, or the CHASE_LINKS
	      option is set and the -L flag is not given, the printed path will not contain symbolic links.

       r      Same as fc -e -.

       readonly
	      Same as typeset -r.  With the POSIX_BUILTINS option set,
	      same as typeset -gr.

       rehash Same as hash -r.

       return [ n ]
	      Causes a shell function or '.' script to return to the invoking script with the return status specified by an arithmetic
	      expression n. If	n  is  omitted, the return status is that of the last command executed.

	      If  return  was  executed  from  a trap in a TRAPNAL function, the effect is different for zero and non-zero return status.
	      With zero status (or after an implicit return at the end of the trap), the shell will return to whatever it was
	      previously processing; with a non-zero status, the shell will behave  as interrupted except that the return status of the
	      trap is retained.  Note that the numeric value of the signal which caused the trap is passed as the first argument, so the
	      statement 'return \$((128+\${1}))' will return the same status as if the signal had not been trapped.

       sched  See the section 'The zsh/sched Module' in zshmodules(1).

       set [ {+|-}options | {+|-}o [ option_name ] ] ... [ {+|-}A [ name ] ] [ arg ... ]
	      Set the options for the shell and/or set the positional parameters, or declare and set an array.	If the -s option is
	      given, it causes the specified argu‐ ments  to	be sorted before assigning them to the positional parameters (or to
	      the array name if -A is used).  With +s sort arguments in descending order.  For the meaning of the other flags, see
	      zshoptions(1).  Flags may be specified by name using the -o option. If no option name is  supplied  with  -o,  the current
	      option  states are printed:  see the description of setopt below for more information on the format.  With +o they are
	      printed in a form that can be used as input to the shell.

	      If the -A flag is specified, name is set to an array containing the given args; if no name is specified, all arrays are printed
	      together with  their  val‐ ues.

	      If  +A  is used and name is an array, the given arguments will replace the initial elements of that array; if no name
	      is specified, all arrays are printed without their values.

	      The behaviour of arguments after -A name or +A name depends on whether the option KSH_ARRAYS is set.	If it is not set,
	      all arguments following  name  are treated as values for the array, regardless of their form.  If the option is set,
	      normal option processing continues at that point; only regular arguments are treated as values for the array.  This means that

		     set -A array -x -- foo

	      sets array to '-x -- foo' if KSH_ARRAYS is not set, but sets the array to foo and turns on the option '-x' if it is set.

	      If the -A flag is not present, but there are arguments beyond the options, the positional parameters are set.  If the option
	      list (if any)  is  terminated by '--', and there are no further arguments, the positional parameters will be unset.

	      If  no  arguments and no '--' are given, then the names and values of all parameters are printed on the standard output.
	      If the only argument is '+', the names of all parameters are printed.

	      For historical reasons, 'set -' is treated as 'set +xv' and 'set - args' as 'set +xv -- args' when in any other emulation
	      mode than zsh's native mode.

       setcap See the section 'The zsh/cap Module' in zshmodules(1).

       setopt [ {+|-}options | {+|-}o option_name ] [ -m ] [ name ... ]
	      Set the options for the shell.  All options specified either with flags or by name are set.

	      If no arguments are supplied, the names of all options currently set are printed.	The form is chosen so as to minimize the
	      differences from	the  default options  for the current emulation (the default emulation being native zsh, shown as
	      <Z> in zshoptions(1)).  Options that are on by default for the emula‐ tion are shown with the prefix no only if they are off,
	      while other options are shown without the prefix no and only if they  are  on.   In  addition  to options  changed  from	the
	      default  state by the user, any options activated automatically by the shell (for example, SHIN_STDIN or INTERACTIVE) will be
	      shown in the list.  The format is further modified by the option KSH_OPTION_PRINT, however the rationale for choosing options
	      with or without the no  pre‐ fix remains the same in this case.

	      If  the  -m flag is given the arguments are taken as patterns (which should be quoted to protect them from filename expansion),
	      and all options with names matching these patterns are set.

	      Note that a bad option name does not cause execution of subsequent shell code to be aborted; this is behaviour is
	      different from that of 'set  -o'.   This is because set is regarded as a special builtin by the POSIX standard, but setopt
	      is not.

       shift [ -p ] [ n ] [ name ... ]
	      The  positional  parameters  \${n+1}  ...	are  renamed to \${1} ..., where n is an arithmetic expression that defaults to 1.
	      If any names are given then the arrays with these names are shifted instead of the positional parameters.

	      If the option -p is given arguments are instead removed (popped) from the end rather than the start of the array.

       source file [ arg ... ]
	      Same as '.', except that the current directory is always searched and is always searched first, before directories in \${path}.

       stat   See the section 'The zsh/stat Module' in zshmodules(1).

       suspend [ -f ]
	      Suspend the execution of the shell (send it a SIGTSTP) until it receives a SIGCONT.  Unless the -f option is given, this
	      will refuse to  suspend  a  login shell.

       test [ arg ... ] [ [ arg ... ] ]
	      Like the system version of test.	Added for compatibility; use conditional expressions instead (see the section 'Conditional
	      Expressions').  The main dif‐ ferences between the conditional expression syntax and the test and [ builtins are:  these
	      commands are not handled syntactically, so for example an empty variable	expansion  may	cause  an argument to be omitted;
	      syntax errors cause status 2 to be returned instead of a shell error; and arithmetic operators expect integer arguments rather
	      than arithmetic expressions.

	      The command attempts to implement POSIX and its extensions where these are specified.  Unfortunately there are intrinsic
	      ambiguities  in  the  syntax;  in particular  there  is no  distinction between test operators and strings that
	      resemble them.  The standard attempts to resolve these for small numbers of arguments (up to four); for five or more
	      arguments compatibility cannot be relied on.  Users are urged wherever possible to use the '[[' test syntax which does not
	      have these ambiguities.

       times  Print the accumulated user and system times for the shell and for processes run from the shell.

       trap [ arg ] [ sig ... ]
	      arg  is  a series of commands (usually quoted to protect it from immediate evaluation by the shell) to be read and executed when
	      the shell receives any of the signals specified by one or more sig args.  Each sig can be given as a number, or as the name
	      of a signal either with or without  the  string  SIG  in front (e.g. 1, HUP, and SIGHUP are all the same signal).

	      If arg is '-', then the specified signals are reset to their defaults, or, if no sig args are present, all traps are reset.

	      If arg is an empty string, then the specified signals are ignored by the shell (and by the commands it invokes).

	      If  arg is omitted but one or more sig args are provided (i.e.  the first argument is a valid signal number or name),
	      the effect is the same as if arg had been specified as '-'.

	      The trap command with no arguments prints a list of commands associated with each signal.

	      If sig is ZERR then arg will be executed after each command with a nonzero exit status.  ERR is an alias for ZERR on
	      systems that have  no  SIGERR  signal (this is the usual case).

	      If sig is DEBUG then arg will be executed before each command if the option DEBUG_BEFORE_CMD is set (as it is by default),
	      else after each command.	Here, a 'command' is what is described as a 'sublist' in the shell grammar, see the section SIMPLE
	      COMMANDS & PIPELINES in zshmisc(1).  If  DEBUG_BEFORE_CMD  is set  various additional features are available.  First, it is
	      possible to skip the next command by setting the option ERR_EXIT; see the description of the ERR_EXIT option in zshoptions(1).
	      Also, the shell parameter ZSH_DEBUG_CMD is set to the string corresponding to the command to be executed following  the trap.
	      Note that this string is reconstructed from the internal format and may not be formatted the same way as the original text.
	      The parameter is unset after the trap is executed.

	      If sig is 0 or EXIT and the trap statement is executed inside the body of a function, then the command arg is executed after
	      the function completes.	The value  of  \${?}  at  the  start of execution is the exit status of the shell or the return
	      status of the function exiting.  If sig is 0 or EXIT and the trap statement is not executed inside the body of a function,
	      then the command arg is executed when the shell terminates; the trap runs before any zshexit hook functions.

	      ZERR, DEBUG, and EXIT traps are not executed inside other traps.  ZERR and DEBUG traps are kept within subshells, while other
	      traps are reset.

	      Note  that  traps  defined  with the trap builtin are slightly different from those defined as 'TRAPNAL () { ... }', as the
	      latter have their own function environment (line numbers, local variables, etc.) while the former use the environment
	      of the command in which they were called.  For example,

		     trap 'print \${LINENO}' DEBUG

	      will print the line number of a command executed after it has
	      run, while

		     TRAPDEBUG() { print \${LINENO}; }

	      will always print the number zero.

	      Alternative signal names are allowed as described under kill above.  Defining a trap under either name causes any
	      trap under an  alternative  name	to  be removed.  However, it is recommended that for consistency users stick exclusively
	      to one name or another.

       true [ arg ... ]
	      Do nothing and return an exit status of 0.

       ttyctl [ -fu ]
	      The  -f  option freezes the tty (i.e. terminal or terminal emulator), and -u unfreezes it.  When the tty is frozen, no
	      changes made to the tty settings by external programs will be honored by the shell, except for changes in the size of
	      the screen; the shell will simply reset the settings to  their previous values  as  soon as each command exits or is suspended.
	      Thus, stty and similar programs have no effect when the tty is frozen.  Freezing the tty does not cause the current state
	      to be remembered: instead, it causes future changes to the state to be blocked.

	      Without options it reports whether the terminal is frozen or not.

	      Note that, regardless of whether the tty is frozen or not, the shell needs to change the settings when the line editor
	      starts, so unfreezing the tty  does not  guarantee settings made on the command line are preserved.  Strings of commands
	      run between editing the command line will see a consistent tty state.  See also the shell variable STTY for a means of
	      initialising the tty before running external commands.

       type [ -wfpamsS ] name ...
	      Equivalent to whence -v.

       ulimit [ -HSa ] [ { -bcdfiklmnpqrsTtvwx | -N resource } [ limit ] ... ]
	      Set or display resource limits of the shell and the processes started by the shell.  The value of limit can be a number in
	      the unit specified below or one of the values 'unlimited', which removes the limit on the resource, or 'hard', which uses
	      the current value of the hard limit on the resource.

	      By  default,  only soft limits are manipulated. If the -H flag is given use hard limits instead of soft limits.	If the -S flag
	      is given together with the -H flag set both hard and soft limits.

	      If no options are used, the file size limit (-f) is assumed.

	      If limit is omitted the current value of the specified resources are printed.  When more than one resource value is printed,
	      the limit name  and  unit  is printed before each value.

	      When  looping  over  multiple  resources, the shell will abort immediately if it detects a badly formed argument.  However,
	      if it fails to set a limit for some other reason it will continue trying to set the remaining limits.

	      Not all the following resources are supported on all systems.
	      Running ulimit -a will show which are supported.

	      -a     Lists all of the current resource limits.	
		  -b     Socket buffer size in bytes (N.B. not kilobytes) 
		  -c     512-byte blocks on the size of core dumps.  
		  -d	Kilobytes on the size of the data segment.  
		  -f	512-byte blocks on the size of files written.  
		  -i	The number of pending signals.
	      -k     The number of kqueues allocated.  
		  -l     Kilobytes on the size of locked-in memory.	
		  -m     Kilobytes on the size of physical memory.	
		  -n     open file descriptors.
	      -p     The number of pseudo-terminals.  
		  -q     Bytes in POSIX message queues.  
		  -r     Maximum real time priority.  On some systems where this is not available, such as NetBSD, this has the same effect 
		         as -T for compatibility with sh.
	      -s     Kilobytes on the size of the stack.  
		  -T	 The number of simultaneous threads available to the user.  
		  -t     CPU seconds to be used.  
		  -u	 The number of processes available to the user.  
		  -v	 Kilobytes on the size of virtual memory.  On some systems this refers to the limit called 'address space'.
	      -w     Kilobytes on the size of swapped out memory.  
		  -x	  The number of locks on files.

	      A resource may also be specified by integer in the form '-N resource', where resource corresponds to the integer defined
	      for the resource by the operating system.  This may be used to set the limits for resources known to the shell which do
	      not correspond to option letters.  Such limits will be shown by num‐ ber in the output of 'ulimit -a'.

	      The number may alternatively be out of the range of limits compiled into the shell.	The shell will try to read or write
	      the limit anyway, and will report an error if this fails.

       umask [ -S ] [ mask ]
	      The  umask  is  set  to  mask.  mask can be either an octal number or a symbolic value as described in chmod(1).  If mask
	      is omitted, the current value is printed.  The -S option causes the mask to be printed as a symbolic value.  Otherwise, the mask
	      is printed as an octal number.  Note that in the	symbolic form the permissions you specify are those which are to be allowed
	      (not denied) to the users specified.

       unalias [ -ams ] name ...
	      Removes  aliases.   This	command  works	the  same  as  unhash -a, except that the -a option removes all regular or global
	      aliases, or with -s all suffix aliases: in this case no name arguments may appear.  The options -m (remove by pattern)
	      and -s without -a (remove listed suffix  aliases)  behave as  for unhash -a.  Note that the meaning of -a is different
	      between unalias and unhash.

       unfunction
	      Same as unhash -f.

       unhash [ -adfms ] name ...
	      Remove  the  element  named name from an internal hash table.  The default is remove elements from the command hash table.
	      The -a option causes unhash to remove regular or global aliases; note when removing a global aliases that the argument must be
	      quoted to prevent it  from  being  expanded  before  being passed  to  the  command.   The  -s option causes unhash to
	      remove suffix aliases.  The -f option causes unhash to remove shell functions.	The -d options causes unhash to remove
	      named directories.  If the -m flag is given the arguments are taken as patterns (should be quoted) and all elements of the
	      corre‐ sponding hash table with matching names will be removed.

       unlimit [ -hs ] resource ...
	      The  resource limit for each resource is set to the hard limit.  If the -h flag is given and the shell has appropriate
	      privileges, the hard resource limit for each resource is removed.  The resources of the shell process are only changed if the -s
	      flag is given.

	      The unlimit command is not made available by default when the shell starts in a mode emulating another shell.  It can be made
	      available with  the  command 'zmodload -F zsh/rlimits b:unlimit'.

       unset [ -fmv ] name ...
	      Each  named  parameter  is unset.  Local parameters remain local even if unset; they appear unset within scope, but the
	      previous value will still reappear when the scope ends.

	      Individual elements of associative array parameters may be unset by using subscript syntax on name, which should be quoted
	      (or the entire command prefixed with noglob) to protect the subscript from filename generation.

	      If  the -m flag is specified the arguments are taken as patterns (should be quoted) and all parameters with matching names
	      are unset.  Note that this can‐ not be used when unsetting associative array elements, as the subscript will be treated
	      as part of the pattern.

	      The -v flag specifies that name refers to parameters. This is the default behaviour.

	      unset -f is equivalent to unfunction.

       unsetopt [ {+|-}options | {+|-}o option_name ] [ name ... ]
	      Unset the options for the shell.	All options specified either with flags or by name are unset.	If no arguments are supplied,
	      the names  of  all  options currently  unset are printed.  If the -m flag is given the arguments are taken as patterns
	      (which should be quoted to preserve them from being interpreted as glob patterns), and all options with names matching these
	      patterns are unset.

       vared  See the section 'Zle Builtins' in zshzle(1).

       wait [ job ... ]
	      Wait for the specified jobs or processes.  If job is not given then all currently active child processes are waited for.
	      Each job can  be	either	a  job specification or the process ID of a job in the job table.  The exit status from this command
	      is that of the job waited for.

	      It  is  possible	to  wait  for recent processes (specified by process ID, not by job) that were running in the background even
	      if the process has exited.  Typically the process ID will be recorded by capturing the value of the variable \$! immediately
	      after the process has been started.  There is a  limit  on the number  of  process  IDs	remembered  by	the  shell; this
	      is given by the value of the system configuration parameter CHILD_MAX.  When this limit is reached, older process IDs are
	      discarded, least recently started processes first.

	      Note there is no protection against the process ID wrapping, i.e. if the wait is not executed soon enough there is a chance
	      the process waited for is  the wrong  one.   A  conflict implies both process IDs have been generated by the shell, as other
	      processes are not recorded, and that the user is potentially interested in both, so this problem is intrinsic to process IDs.

       whence [ -vcwfpamsS ] [ -x num ] name ...
	      For each name, indicate how it would be interpreted if used as a command name.

	      whence is most useful when name is only the last path component of a command, i.e. does not include a '/'; in particular,
	      pattern matching	only  succeeds if just the non-directory component of the command is passed.

	      -v     Produce a more verbose report.

	      -c     Print the results in a csh-like format.  This takes precedence over -v.

	      -w     For  each	name, print 'name: word' where word is one of alias, builtin, command, function, hashed, reserved or none,
	             according as name corresponds to an alias, a built-in command, an external command, a shell function, a command defined 
				 with the hash builtin, a reserved word, or is not  recog‐ nised.  This takes precedence over -v and -c.

	      -f     Causes the contents of a shell function to be displayed, which would otherwise not happen unless the -c flag were used.

	      -p     Do a path search for name even if it is an alias, reserved word, shell function or builtin.

	      -a     Do a search for all occurrences of name throughout the command path.  Normally only the first occurrence is printed.

	      -m     The  arguments are taken as patterns (pattern characters should be quoted), and the information is displayed for each command 
		         matching one of these patterns.

	      -s     If a pathname contains symlinks, print the symlink-free pathname as well.

	      -S     As -s, but if the pathname had to be resolved by following multiple symlinks, the intermediate steps are printed, too.
	             The  symlink  resolved  at each step might be anywhere in the path.

	      -x num Expand tabs when outputting shell functions using the -c option.  This has the same effect as the -x option to the
	      functions builtin.

       where [ -wpmsS ] [ -x num ] name ...
	      Equivalent to whence -ca.

       which [ -wpamsS ] [ -x num ] name ...
	      Equivalent to whence -c.

       zcompile [ -U ] [ -z | -k ] [ -R | -M ] file [ name ... ] zcompile -ca [ -m ] [ -R | -M ] file [ name ... ] zcompile -t file [ name ... ]
	      This  builtin command can be used to compile functions or scripts, storing the compiled form in a file, and to examine
	      files containing the compiled form.  This allows faster autoloading of functions and sourcing of scripts by avoiding
	      parsing of the text when the files are read.

	      The first form (without the -c, -a or -t options) creates a compiled file.  If only the file argument is given, the output
	      file has	the  name  'file.zwc' and  will  be  placed  in  the same directory as the file.  The shell will load the compiled
	      file instead of the normal function file when the function is autoloaded; see the section 'Autoloading Functions' in zshmisc(1)
	      for a description of how autoloaded functions are searched.  The extension  .zwc  stands for 'zsh word code'.

	      If  there is at least one name argument, all the named files are compiled into the output file given as the first argument.
	      If file does not end in .zwc, this extension is automatically appended.  Files containing multiple compiled functions are
	      called 'digest' files, and are intended to be used as elements of the FPATH/fpath special array.

	      The  second  form,  with the -c or -a options, writes the compiled definitions for all the named functions into file.
	      For -c, the names must be functions currently defined in the shell, not those marked for autoloading.	Undefined functions
	      that are marked for autoloading may be  written  by  using the  -a option,  in  which  case the fpath is searched and
	      the contents of the definition files for those functions, if found, are compiled into file.  If both -c and -a are given,
	      names of both defined functions and functions marked for autoloading may be given.  In either case, the functions in
	      files written  with the -c or -a option will be autoloaded as if the KSH_AUTOLOAD option were unset.

	      The  reason  for	handling  loaded and not-yet-loaded functions with different options is that some definition files for
	      autoloading define multiple func‐ tions, including the function with the same name as the file, and, at the end, call
	      that function.  In such cases the output of  'zcompile  -c' does  not include  the additional functions defined in the
	      file, and any other initialization code in the file is lost.  Using 'zcompile -a' captures all this extra information.

	      If the -m option is combined with -c or -a, the names are used as patterns and all functions whose names match one of
	      these patterns will be  written.	If no name is given, the definitions of all functions currently defined or marked as
	      autoloaded will be written.

	      Note  the  second form cannot be used for compiling functions that include redirections as part of the definition rather
	      than within the body of the func‐ tion; for example

		     fn1() { { ... } >~/logfile }

	      can be compiled but

		     fn1() { ... } >~/logfile

	      cannot.  It is possible to use the first form of zcompile to compile autoloadable functions that include the full function
	      definition instead of just  the body of the function.

	      The  third  form, with the -t option, examines an existing compiled file.  Without further arguments, the names of the
	      original files compiled into it are listed.  The first line of output shows the version of the shell which compiled the file
	      and how the file will be used (i.e. by reading it directly or  by mapping  it  into memory).  With arguments, nothing is
	      output and the return status is set to zero if definitions for all names were found in the compiled file, and non-zero
	      if the definition for at least one name was not found.

	      Other options:

	      -U     Aliases are not expanded when compiling the named files.

	      -R     When the compiled file is read, its contents are copied
	      into the shell's memory, rather than memory-mapped (see -M).  This happens automatically on systems that do not support memory mapping.

		  When compiling scripts instead of autoloadable functions, it is often desirable to use this option; otherwise
		  the whole file, including the code to define functions which have already been defined, will remain mapped,
		  consequently wasting memory.

	      -M     The compiled file is mapped into the shell's memory when read. This is done in such a way that multiple instances
	             of the shell running on the  same host will share this mapped file.	If neither -R nor -M is given, the zcompile builtin 
				 decides what to do based on the size of the compiled file.

	      -k -z	These  options are used when the compiled file contains functions which are to be autoloaded. If -z is given,
	      the function will be autoloaded as if the KSH_AUTOLOAD option is not set, even if it is set at
		     the time the compiled file is read, while if the -k is given, the function will be  loaded as  if  KSH_AUTOLOAD
		     is  set.  These options also take precedence over any -k or -z options specified to the autoload builtin. If
		     neither of these options is given, the function will be loaded as determined by the setting of the KSH_AUTOLOAD
		     option at the time the compiled file is read.

		     These options may also appear as many times as necessary between the listed names to specify the loading style
		     of all following  functions,  up  to the next -k or -z.

		     The created file always contains two versions of the compiled format, one for big-endian machines and one for
		     small-endian machines.  The upshot of this is that the compiled file is machine independent and if it is read
		     or mapped, only one half of the file is actually used (and mapped).

       zformat
	      See the section 'The zsh/zutil Module' in zshmodules(1).

       zftp   See the section 'The zsh/zftp Module' in zshmodules(1).

       zle    See the section 'Zle Builtins' in zshzle(1).

       zmodload [ -dL ] [ -s ] [ ... ] zmodload -F [ -alLme -P param ] module
       [ [+-]feature ... ] zmodload -e [ -A ] [ ... ] zmodload [ -a [ -bcpf
       [ -I ] ] ] [ -iL ] ...  zmodload -u [ -abcdpf [ -I ] ] [ -iL ] ...
       zmodload -A [ -L ] [ modalias[=module] ... ] zmodload -R modalias ...
	      Performs operations relating to zsh's loadable modules.  Loading of modules while the shell is running ('dynamical
	      loading') is not available on all oper‐ ating  systems, or  on  all  installations  on a particular operating system,
	      although the zmodload command itself is always available and can be used to manipulate modules built into versions of the
	      shell executable without dynamical loading.

	      Without arguments the names of all currently loaded binary modules are printed.  The -L option causes this list to be
	      in the form of a series of  zmodload commands.  Forms with arguments are:

	      zmodload [ -is ] name ...  zmodload -u [ -i ] name ...
		     In  the  simplest	case,  zmodload  loads a binary module.  The module must be in a file with a name consisting
		     of the specified name followed by a standard suffix, usually '.so' ('.sl' on HPUX).  If the module to be
		     loaded is already loaded the duplicate module is ignored.  If zmodload detects an inconsistency, such as an invalid
		     module name or circular dependency list, the current code block is aborted.  If it is available, the module
		     is loaded if necessary, while if it is not available, non-zero status is silently returned.  The option -i
		     is accepted for compatibility  but  has  no effect.

		     The  named  module  is  searched for in the same way a command is, using \${module_path} instead of \${path}.
		     However, the path search is performed even when the module name contains a '/', which it usually does.
		     There is no way to prevent the path search.

		     If the module supports features (see below), zmodload tries to enable all features when loading a module.
		     If the module  was  successfully  loaded but not all features could be enabled, zmodload returns status 2.

		     If  the  option  -s  is  given,  no  error is printed if the module was not available (though other errors
		     indicating a problem with the module are printed).  The return status indicates if the module was loaded.
		     This is appropriate if the caller considers the module optional.

		     With -u, zmodload unloads modules.  The same name must be given that was given when the module was loaded,
		     but it is not necessary for  the  module to exist in the file system.  The -i option suppresses the error
		     if the module is already unloaded (or was never loaded).

		     Each  module has a boot and a cleanup function.  The module will not be loaded if its boot function fails.
		     Similarly a module can only be unloaded if its cleanup function runs successfully.

	      zmodload -F [ -almLe -P param ] module [ [+-]feature ... ]
		     zmodload -F allows more selective control over the features provided by modules.  With no options apart
		     from -F, the module named module is loaded, if it was not already loaded, and the list of features is set
		     to the required state.  If no features are specified, the module is loaded, if it was not already loaded,
		     but the state of features is unchanged.  Each feature may be preceded by a + to turn the feature on, or - to
		     turn it off; the + is  assumed  if  neither character is present.  Any feature not explicitly mentioned is left
		     in its current state; if the module was not previously loaded this means any such features will remain disabled.
		     The return status is zero if all features were set, 1 if the module failed to load,  and 2  if  some features
		     could not be set (for example, a parameter couldn't be added because there was a different parameter of the
		     same name) but the module was loaded.

		     The standard features are builtins, conditions, parameters and math functions; these are indicated by
		     the prefix 'b:', 'c:' ('C:' for an infix con‐ dition), 'p:' and 'f:', respectively, followed by the name that
		     the corresponding feature would have in the shell.  For example, 'b:strftime' indi‐ cates a builtin named
		     strftime and p:EPOCHSECONDS indicates a parameter named EPOCHSECONDS.  The module may provide other ('abstract')
		     features  of its own as indicated by its documentation; these have no prefix.

		     With  -l or -L, features provided by the module are listed.  With -l alone, a list of features together
		     with their states is shown, one feature per line.  With -L alone, a zmodload -F command that would cause
		     enabled features of the module to be turned on is shown.  With -lL, a zmodload -F com‐ mand  that	would cause all
		     the features to be set to their current state is shown.  If one of these combinations is given with the option
		     -P param then the parameter param is set to an array of features, either features together with their state or
		     (if -L alone is given) enabled features.

		     With the option -L the module name may be omitted; then a list of all enabled features for all modules
		     providing features is printed in the form of zmodload -F commands.  If -l is also given, the state of both
		     enabled and disabled features is output in that form.

		     A set of features may be provided together with -l or -L and a module name; in that case only the state of
		     those features is considered.  Each fea‐ ture may be preceded by + or - but the character has no effect.  If no
		     set of features is provided, all features are considered.

		     With -e, the command first tests that the module is loaded; if it is not, status 1 is returned.  If the
		     module is	loaded,  the  list  of	features given	as an  argument  is examined.  Any feature given with no
		     prefix is simply tested to see if the module provides it; any feature given with a prefix + or - is tested to see
		     if is provided and in the given state.  If the tests on all features in the list succeed, status 0 is returned,
		     else status 1.

		     With -m, each entry in the given list of features is taken as a pattern to be matched against the list of
		     features provided by the module.  An ini‐ tial + or - must be given explicitly.	This may not be combined with
		     the -a option as autoloads must be specified explicitly.

		     With -a, the given list of features is marked for autoload from the specified module, which may not yet be loaded.
		     An optional + may appear before the  feature  name.  If  the  feature  is prefixed with -, any existing
		     autoload is removed.  The options -l and -L may be used to list autoloads.  Autoloading is specific to
		     individual features; when the module is loaded only the requested feature is enabled.  Autoload requests  are
		     preserved if the module is subsequently unloaded until an explicit 'zmodload -Fa module -feature' is issued.
		     It is not an error to request an autoload for a feature of a module that is already loaded.

		     When the module is loaded each autoload is checked against the features actually provided by the  module;
		     if  the  feature  is  not	provided  the autoload request is deleted.  A warning message is output; if the
		     module is being loaded to provide a different feature, and that autoload is suc‐ cessful, there is no effect
		     on the status of the current command.  If the module is already loaded at the time when zmodload -Fa is run,
		     an  error message is printed and status 1 returned.

		     zmodload  -Fa  can  be  used with the -l, -L, -e and -P options for listing and testing the existence of
		     autoloadable features.  In this case -l is ignored if -L is specified.  zmodload -FaL with no module name
		     lists autoloads for all modules.

		     Note that only standard features as described above can be autoloaded; other features require the module
		     to be loaded before enabling.

	      zmodload -d [ -L ] [ name ] zmodload -d name dep ...
	      zmodload -ud name [ dep ... ]
		     The -d option can be used to specify module dependencies.  The modules named in the second and subsequent arguments
		     will be loaded before the	mod‐ ule named in the first argument.

		     With -d and one argument, all dependencies for that module are listed.  With -d and no arguments, all module
		     dependencies are listed.  This listing is by default in a Makefile-like format.  The -L option changes this
		     format to a list of zmodload -d commands.

		     If -d and -u are both used, dependencies are removed.  If only one argument is given, all dependencies for
		     that module are removed.

	      zmodload -ab [ -L ] zmodload -ab [ -i ] name [ builtin ... ]
	      zmodload -ub [ -i ] builtin ...
		     The -ab option defines autoloaded builtins.  It defines the specified builtins.  When any of those builtins is
		     called, the module specified in  the first argument is loaded and all its features are enabled (for
		     selective control of features use 'zmodload -F -a' as described above).  If only the name is given, one
		     builtin is defined, with the same name as the module.  -i suppresses the error if the builtin is already defined
		     or  autoloaded, but not if another builtin of the same name is already defined.

		     With  -ab	and  no  arguments, all autoloaded builtins are listed, with the module name (if different) shown
		     in parentheses after the builtin name.  The -L option changes this format to a list of zmodload -a commands.

		     If -b is used together with the -u option, it removes builtins previously defined with -ab.  This is only
		     possible  if  the	builtin  is  not  yet loaded.  -i suppresses the error if the builtin is already removed
		     (or never existed).

		     Autoload requests are retained if the module is subsequently unloaded until an explicit 'zmodload -ub
		     builtin' is issued.

	      zmodload -ac [ -IL ] zmodload -ac [ -iI ] name [ cond ... ]
	      zmodload -uc [ -iI ] cond ...
		     The  -ac option is used to define autoloaded condition codes. The cond strings give the names of the conditions
		     defined by the module. The optional -I option is used to define infix condition names. Without this option
		     prefix condition names are defined.

		     If given no condition names, all defined names are listed (as a series of zmodload commands if the -L
		     option is given).

		     The -uc option removes definitions for autoloaded conditions.

	      zmodload -ap [ -L ] zmodload -ap [ -i ] name [ parameter ... ]
	      zmodload -up [ -i ] parameter ...
		     The -p option is like the -b and -c options, but makes zmodload work on autoloaded parameters instead.

	      zmodload -af [ -L ] zmodload -af [ -i ] name [ function ... ]
	      zmodload -uf [ -i ] function ...
		     The -f option is like the -b, -p, and -c options, but makes zmodload work on autoloaded math functions instead.

	      zmodload -a [ -L ] zmodload -a [ -i ] name [ builtin ... ]
	      zmodload -ua [ -i ] builtin ...
		     Equivalent to -ab and -ub.

	      zmodload -e [ -A ] [ string ... ]
		     The -e option without arguments lists all loaded modules; if the -A option is also given, module aliases
		     corresponding to loaded modules  are  also shown.  If arguments are provided, nothing is printed; the
		     return status is set to zero if all strings given as arguments are names of loaded mod‐ ules and to one if
		     at least on string is not the name of a loaded module.  This can be used to test for the availability of things
		     implemented  by modules.  In this case, any aliases are automatically resolved and the -A flag is not used.

	      zmodload -A [ -L ] [ modalias[=module] ... ]
		     For  each	argument,  if  both modalias and module are given, define modalias to be an alias for the module
		     module.  If the module modalias is ever subsequently requested, either via a call to zmodload or implicitly,
		     the shell will attempt to load module instead.  If module is not  given,  show the  definition  of  modalias.
		     If no arguments are given, list all defined module aliases.  When listing, if the -L flag was also given,
		     list the definition as a zmodload command to recreate
		     the alias.

		     The existence of aliases for modules is completely independent of whether the name resolved is actually
		     loaded as a module: while the alias exists, loading and unloading the module under any alias has exactly
		     the same effect as using the resolved name, and does not affect the connection between the alias and the
		     resolved name which can be removed either by zmodload -R or by redefining the alias.  Chains of aliases	(i.e.
		     where  the  first resolved  name  is  itself  an  alias) are valid so long as these are not circular.  As the
		     aliases take the same format as module names, they may include path separators:  in this case, there is no
		     requirement for any part of the path named to exist as the alias will be resolved  first.   For example,
		     'any/old/alias' is always a valid alias.

		     Dependencies  added  to  aliased modules are actually added to the resolved module; these remain if the alias
		     is removed.  It is valid to create an alias whose name is one of the standard shell modules and which
		     resolves to a different module.  However, if a module has dependencies, it will not be possible to use the
		     module name as an alias as the module will already be marked as a loadable module in its own right.

		     Apart  from the above, aliases can be used in the zmodload command anywhere module names are required.
		     However, aliases will not be shown in lists of loaded modules with a bare 'zmodload'.

	      zmodload -R modalias ...
		     For each modalias argument that was previously defined as a module alias via zmodload -A, delete the alias.
		     If any was not defined,  an  error  is caused and the remainder of the line is ignored.

	      Note  that  zsh  makes  no distinction between modules that were linked into the shell and modules that are loaded dynamically. In
	      both cases this builtin command has to be used to make available the builtins and other things defined by modules (unless the
	      module is autoloaded on these definitions). This	is true even for systems that don't support dynamic loading of modules.

       zparseopts
	      See the section 'The zsh/zutil Module' in zshmodules(1).

       zprof  See the section 'The zsh/zprof Module' in zshmodules(1).

       zpty   See the section 'The zsh/zpty Module' in zshmodules(1).

       zregexparse
	      See the section 'The zsh/zutil Module' in zshmodules(1).

       zsocket
	      See the section 'The zsh/net/socket Module' in zshmodules(1).

       zstyle See the section 'The zsh/zutil Module' in zshmodules(1).

       ztcp   See the section 'The zsh/net/tcp Module' in zshmodules(1).

${E_MAGENTA_FG}VI Keys${E_RESET}
===================
Key Action                                                  Followed by
-----------------------------------------------------------------------
a enter insertion mode after current character              text, ESC
b back word
c change command                                            cursor motion command
d delete command                                            cursor motion command
e end of word
f find character after cursor in current line               character to find
h move left one character
i enter insertion mode before current character             text, ESC
j move down one line
k move up one line
l move right one character
o open line below and enter insertion mode                  text, ESC
p put buffer after cursor
r replace single character at cursor                        replacement character expected
s substitute single character with new text                 text, ESC
u undo
w move foreward one word
x delete single character
y yank command                                              cursor motion command
z position current line                                     CR = top; "." = center; "-"=bottom
A enter insertion mode after end of line                    text, ESC
B move back one Word
C change to end of line                                     text, ESC
D delete to end of line
E move to end of Word
F backwards version of "f"                                  character to find
G goto line number prefixed, or goto end if none
H home cursor - goto first line on screen
I insertion before first non-whitespace character           text, ESC
J join current line with next line
L goto last line on screen
M goto middle line on screen
O open line above and enter insertion mode                  text, ESC
P put buffer before cursor
Q leave visual mode (go into "ex" mode)
R replace through end of current line,then insert           text, ESC
S substitute line - delete line, insert                     text, ESC
W forward Word
X delete backwards single character
0 move to column zero
1-9 any numeric precursor to other command                  command
  (SPACE) move right one character
\$ move to end of line
% match nearest [],(),{} 
^ move to first non-whitespace character of line
( move to previous sentence
) move to next sentence
| move to column zero
- move to first non-whitespace of previous line
_ similar to "^" but uses numeric prefix oddly
+ move to first non-whitespace of next line
[ move to previous "{...}" section                         "["
] move to next "{...}" section                             "]"
{ move to previous blank-line separated section            "{"
} move to next blank-line separated section                "}"
' move to marked line, memorized column                    character tag (a-z)
: ex-submode                                               ex command
" access numbered buffer; load or access lettered buffer   1-9,a-z
~ reverse case of current character and cursor forward
. repeat last text-changing command
< unindent command                                         cursor motion command
> indent command                                           cursor motion command

${E_MAGENTA_FG}SNAP Commands${E_RESET}
sudo snap find    : To list the available packages
sudo snap install <package name>   : To install a package
sudo snap list   : To view all the installed snap packages
sudo snap changes   : To view a list of logged actions
sudo snap refresh <package name>   : To upgrade a package to its latest available version
sudo snap remove   : To uninstall a package

${E_MAGENTA_FG}SET Commands${E_RESET}
'set' single char options
-0 CORRECT
-1 PRINT_EXIT_VALUE
-2 NO_BAD_PATTERN
-3 NO_NOMATCH
-4 GLOB_DOTS
-5 NOTIFY
-6 BG_NICE
-7 IGNORE_EOF
-8 MARK_DIRS
-9 AUTO_LIST
-B NO_BEEP
-C NO_CLOBBER
-D PUSHD_TO_HOME
-E PUSHD_SILENT
-F NO_GLOB
-G NULL_GLOB
-H RM_STAR_SILENT
-I IGNORE_BRACES
-J AUTO_CD
-K NO_BANG_HIST
-L SUN_KEYBOARD_HACK
-M SINGLE_LINE_ZLE
-N AUTO_PUSHD
-O CORRECT_ALL
-P RC_EXPAND_PARAM
-Q PATH_DIRS
-R LONG_LIST_JOBS
-S REC_EXACT
-T CDABLE_VARS
-U MAIL_WARNING
-V NO_PROMPT_CR
-W AUTO_RESUME
-X LIST_TYPES
-Y MENU_COMPLETE
-Z ZLE
-a ALL_EXPORT
-e ERR_EXIT
-f NO_RCS
-g HIST_IGNORE_SPACE
-h HIST_IGNORE_DUPS
-i INTERACTIVE
-k INTERACTIVE_COMMENTS
-l LOGIN
-m MONITOR
-n NO_EXEC
-p PRIVILEGED
-r RESTRICTED
-s SHIN_STDIN
-t SINGLE_COMMAND
-u NO_UNSET
-v VERBOSE
-w CHASE_LINKS
-x XTRACE
-y SH_WORD_SPLIT

#sh/ksh emulation set
-C NO_CLOBBER
-T TRAPS_ASYNC
-X MARK_DIRS
-a ALL_EXPORT
-b NOTIFY
-e ERR_EXIT
-f NO_GLOB
-i INTERACTIVE
-l LOGIN
-m MONITOR
-n NO_EXEC
-p PRIVILEGED
-r RESTRICTED
-s SHIN_STDIN
-t SINGLE_COMMAND
-u NO_UNSET
-v VERBOSE
-x XTRACE

#16.4.3 Also note
-A Used by set for setting arrays
-b Used on the command line to specify end of option processing
-c Used on the command line to specify a single command
-m Used by setopt for pattern-matching option setting
-o Used in all places to allow use of long option names
-s Used by set to sort positional parameters
tip_zsh_EOF_2
}

tip_zsh_comp_official () {
	(
	okular --page 1 "/usr/local/etc/zsh-completions-howto.pdf"
	win_max okular
	) 2>/dev/null &
}

tip_zsh_comp_guide () {
	(
	okular --page 1 "/usr/local/etc/ZshUserGuideCompletion.pdf"
	win_max okular
	) 2>/dev/null &
}

tip_zshdb () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}
cat << 'tip_zshdb_EOF'

ZSH Debugger Help
-----------------
Aliases for action: a
Aliases for break: b
Aliases for continue: c, cont
Aliases for edit: ed
Aliases for examine: x
Aliases for kill: kill!
Aliases for next: n+, n-, n
Aliases for print: pr
Aliases for shell: zsh, sh
Aliases for help: h, ?
Aliases for list: l>, list>, l
Aliases for run: R, restart
Aliases for step: s+, s-, s
Aliases for backtrace: T, bt, where
Aliases for delete: d, unset
Aliases for eval: eval?, ev?, ev
Aliases for quit: q!, exit, q

---------------------
[action]
---------------------
	**action** *linespec* *command*
	
	Run *command* when *linespec* is hit
	
	Use "A" to remove all actions and "L" to get a list of the actions in
	effect.
	
	Aliases for action: a

---------------------
[break]
---------------------

	**break** [*loc-spec*]
	
	Set a breakpoint at *loc-spec*.
	
	If no location specification is given, use the current line.
	
	Multiple breakpoints at one place are permitted, and useful if conditional.
	
	See also:
	---------
	
	"tbreak" and "continue"
	
	Aliases for break: b

---------------------
[continue]
---------------------

	**continue** [*loc* | **-** ]
	
	Continue script execution.
	
	If *loc* or *-* is not given, continue until the next breakpoint or
	the end of program is reached.  If **-** is given, then debugging will
	be turned off after continuing causing your program to run at full
	speed.
	
	If **loc* is given, a temporary breakpoint is set at the location.
	
	Examples:
	---------
	
	    continue          # Continue execution
	    continue 5        # Continue with a one-time breakpoint at line 5
	
	See Also:
	---------
	
	**next**, **skip**, and **step** provide other ways to progress execution.
	
	Aliases for continue: c, cont

---------------------
[disable]
---------------------

	**disable** *bpnum1* [*bpnum2* ...]
	
	Disables breakopints *bpnum1*, *bpnum2*. Breakpoints numbers are given
	as a space-separated list of breakpoint numbers.
	
	To disable all breakpoints, give no argument.
	A disabled breakpoint is not forgotten, but has no effect until re-enabled.
	
	See also:
	---------
	
	**enable** and **info break**.

---------------------
[edit]
---------------------

	**edit** [*line-number*]
	
	Edit specified file at *line-number*.
	
	If *line-number* is not given, use the current line number.
	Uses "EDITOR" environment variable contents as editor (or ex as default).
	Assumes the editor positions at a file using options "+linenumber filename".
	
	Aliases for edit: ed

---------------------
[examine]
---------------------

	**examine** *expr*
	
	Print value of an expression via 'typeset', 'let', and failing these, 'eval'.
	
	Single variables and arithmetic expressions do not need leading $ for
	their value is to be substituted. However if neither these, variables
	need $ to have their value substituted.
	
	In contrast to normal zsh expressions, expressions should not have
	blanks which would cause zsh to see them as different tokens.
	
	Examples:
	---------
	
	    examine x+1   # ok
	    examine x + 1 # not ok
	
	See also:
	---------
	
	**eval**.
	
	Aliases for examine: x

---------------------
[handle]
---------------------

	**handle** *signal* *action*
	
	Specify how to handle *signal*.
	
	*signal* is a signal name like SIGSEGV, but numeric signals like 11
	(which is usually equivalent on *nix systems) is okay too.
	
	*action* is one of "stop", "nostop", "print", and
	"noprint". "Stop" indicates entering debugger if this signal
	happens. "Print" indicates printing a message if this signal is
	encountered. "Stack" is like "print" but except the entire call
	stack is printed. Prefacing these actions with "no" indicates not to
	do the indicated action.

---------------------
[kill]
---------------------

	**kill** [*signal-number*]
	
	**kill!** [*signal-number*]
	
	Send this process a POSIX signal ("9" for "SIGKILL" or "kill -SIGKILL")
	
	9 is a non-maskable interrupt that terminates the program. If program
	is threaded it may be expedient to use this command to terminate the
	program.
	
	However other signals, such 15 or '-INT' which allow for the debugged program to
	run an interrupt handler can be sent too.
	
	Giving a negative number is the same as using its positive value.
	
	When the ! suffix appears, no confirmation is neeeded.
	
	Examples:
	---------
	
	    kill                # non-interuptable, nonmaskable kill
	    kill 9              # same as above
	    kill -9             # same as above
	    kill 15             # nicer, maskable TERM signal
	    kill! 15            # same as above, but no confirmation
	    kill -INT           # same as above
	    kill -SIGINT        # same as above
	    kill -WINCH         # send "window change" signal
	    kill -USR1          # send "user 1" signal
	
	See also:
	---------
	
	**quit** for less a forceful termination command.
	**run** is a way to restart the debugged program.
	
	Aliases for kill: kill!

---------------------
[next]
---------------------

	**next** [*count*]
	
	Step over a statement *count* times ignoring functions.
	
	If *count* is given, stepping occurs that many times before
	stopping. Otherwise *count* is one. *count* can be an arithmetic
	expression.
	
	In contrast to **step**, functions and source'd files are not stepped
	into.
	
	See also:
	---------
	
	**step**, **skip**, **next-** **next+**, and **set different**.
	
	Aliases for next: n+, n-, n

---------------------
[print]
---------------------

	print EXPRESSION -- Print EXPRESSION.
	
	EXPRESSION is a string like you would put in a print statement.
	See also eval.
	
	The difference between eval and print. Suppose cmd has the value "ls".
	
	print ${cmd} # prints "ls"
	eval ${cmd}  # runs an ls command
	
	
	Aliases for print: pr

---------------------
[return]
---------------------

	**return** [*return-value*]
	
	Force an immediate return from a function.
	
	The remainder of function will not be executed. If *return-value* is given,
	it should be an integer and will be the return value passed back as
	${?}.
	
	See also:
	---------
	
	**finish**, **quit**, and **run**.

---------------------
[shell]
---------------------

	**shell** [*options*]
	
	Options:
	--------
	
	   --no-fns  | -F  : don't copy in function definitions from parent shell
	   --no-vars | -V  : don't copy in variable definitions
	   --shell SHELL_NAME
	   --posix         : corresponding shell option
	   --login | l     : corresponding shell option
	   --noprofile     : corresponding shell option
	   --norc          : corresponding shell option
	
	Enter a nested shell, not a subshell. Before entering the shell
	current variable definitions and function definitions are stored in
	profile /tmp/.zshenv. which is is read in via the
	**--init-file** option.
	
	If you don't want variable definitions to be set, use option **-V** or
	**--no-vars**. If you don't want function definitions to be set, use
	option **-F** or **--no-fns**. There are several corresponding shell
	options. Many of these by nature defeate reading on saved functions
	and variables.
	
	The shell that used is taken from the shell used to build the debugger
	which is: zsh. Use **--shell** to use a different
	compatible shell.
	
	By default, variables set or changed in the shell do not persist after
	the shell is left to to back to the debugger or debugged program.
	
	However you can tag variables to persist by running the function
	'save_vars' which takes a list of variable names. You can run this
	as many times as you want with as many variable names as you want.
	
	For example:
	  save_vars PROFILE PARSER
	marks variable PROFILE and PARSER to be examined and their values used
	in the trap EXIT of the shell.
	
	
	Aliases for shell: zsh, sh

---------------------
[source]
---------------------

	**source** *file*
	
	Run debugger commands in *file*.

---------------------
[step-]
---------------------

	**step-**
	
	Single step a statement without the 'step force' setting.
	
	Set step force may have been set on. step- ensures we turn that off for
	this command.
	
	See also:
	---------
	
	**step** and **set different**.

---------------------
[unalias]
---------------------

	**unalias** *name*
	
	Remove debugger command alias *name*.
	
	Use **show aliases** to get a list the aliases in effect.

---------------------
[up]
---------------------

	**up** [*count*]
	
	Move the current frame up in the stack trace (to an older frame). 0 is
	the most recent frame.
	
	If **count** is omitted, use 1.
	
	See also:
	---------
	
	**down** and **frame**.

---------------------
[alias]
---------------------

	**alias** *alias-name* *debugger-command*
	
	Make *alias-name* be an alias for *debugger-command*.
	
	Examples:
	---------
	
	    alias cat list   # "cat prog.py" is the same as "list prog.py"
	    alias s   step   # "s" is now an alias for "step".
	                     # The above example is done by default.
	
	See also:
	---------
	
	**unalias** and **show alias**.

---------------------
[complete]
---------------------

	**complete** *prefix-str*...
	
	Show command completion strings for *prefix-str*
	
	debug
	debug [*zsh-script* [*args*...]]
	
	Recursively debug into *zsh-script*.
	
	If *script* is not given, take the script name from the command that
	is about to be executed. Note that when the nested debug finished, you
	are still where you were prior to entering the debugger.
	
	See Also:
	---------
	
	**skip** and **run**

---------------------
[display]
---------------------

	**display** [*stmt*]
	
	Evalute *stmt* each time the debugger is stopped. If *stmt* is omitted, evaluate
	all of the display statements that are active. In contrast, **info display**
	shows the display statements without evaluating them.
	
	Examples:
	---------
	
	  display echo ${x}  # show the current value of x each time debugger stops
	  display          # evaluate all display statements
	
	See also:
	---------
	
	**undisplay** and **info display**.

---------------------
[enable]
---------------------

	**enable** *bpnum1* [*bpnum2* ...]
	
	Enables breakpoints *bpnum1*, *bpnum2*... Breakpoints numbers are
	given as a space-separated list of numbers.
	
	With no subcommand, breakpoints are enabled until you command otherwise.
	This is used to cancel the effect of the "disable" command.
	
	See also:
	---------
	
	**disable** and **info break**.

---------------------
[export]
---------------------

	**export** *var1* [**var2** ...]
	
	Marks **var1**, **var2***, to get reassigned with their current values after on
	subshell exit. The values are set by the debugger only after it
	notices that the current shell is left.
	
	Nothing is done if you are not in a subshell.

---------------------
[help]
---------------------

	**help** [*command* [*subcommand* ..]]
	
	If no arguments are given, print a list of command names.
	With a command name give help for that command. For many commands
	you can get further detailed help by listing the subcommand name.
	
	Examples:
	---------
	
	  help
	  help up
	  help set
	  help set args
	
	
	Aliases for help: h, ?

---------------------
[list]
---------------------

	**list**[**>**] [*location*|**.**|**-**] [*num*]
	
	List source code.
	
	Without arguments, print lines centered around the current line. If
	*location* is given, that number of lines is shown.
	
	If this is the first list command issued since the debugger command
	loop was entered, then the current line is the current frame. If a
	subsequent list command was issued with no intervening frame changing,
	then that is start the line after we last one previously shown.
	
	A *location* is either:
	
	* a number, e.g. 5,
	* a filename, colon, and a number, e.g. '/etc/profile:5',
	* a "." for the current line number
	* a "-" for the lines before the current linenumber
	
	By default aliases **l>** and **list>** are set to list. In this case and
	more generally when the alias ends in ">", rather than center lines
	around *location* that will be used as the starting point.
	
	Examples:
	---------
	
	    list 5                  # List starting from line 5
	    list 4+1                # Same as above.
	    list /etc/profile:5     # List starting from line 5 of /etc/profile
	    list /etc/profile 5     # Same as above.
	    list /etc/profile 5 6   # list lines 5 and 6 of /etc/profile
	    list /etc/profile 5 2   # Same as above, since 2 < 5.
	    list profile:5 2        # List two lines starting from line 5 of profile
	    list .                  # List lines centered from where we currently are stopped
	    list -                  # List lines previous to those just shown
	
	See also:
	---------
	
	**set listsize** or **show listsize** to see or set the value.
	
	
	Aliases for list: l>, list>, l

---------------------
[next+]
---------------------

	**next+**
	
	Step over stepping ensuring a different line after the step.
	
	In contrast to **next**, we ensure that the file and line position is
	different from the last one just stopped at.
	
	See also:
	---------
	
	**next-**, **next** and **set different**.

---------------------
[pwd]
---------------------

	**pwd**
	
	Show working directory.

---------------------
[run]
---------------------

	**run** [*args*]
	
	Attempt to restart the program.
	
	See also:
	---------
	
	**kill** and **quit** for termintation commands, or
	**set args** for another way to set run arguments.
	
	Aliases for run: R, restart

---------------------
[show]
---------------------

	show alias       -- Show list of aliases currently in effect.
	show annotate    -- Show annotation_level
	show autoeval    -- Evaluate unrecognized commands is off.
	show autolist    -- Auto run a 'list' command is off.
	show basename    -- Show if we are are to show short or long filenames.
	show commands    -- Show the history of commands you typed.
	show confirm     -- confirm dangerous operations on.
	show copying     -- Conditions for redistributing copies of debugger.
	show debug       -- Show if we are set to debug the debugger.
	show different   -- Show stepping forces a new line is off.
	show editing     -- Show editing of command lines and edit style.
	show highlight   -- Show if we syntax highlight source listings.
	show history     -- Show if we are recording command history.
	show linetrace   -- Show whether to trace lines before execution.
	show listsize    -- Number of source lines zshdb will list by default is 10.
	show prompt      -- Show zshdb's command prompt.
	show style       -- Set pygments highlighting style is off.
	show warranty    -- Various kinds of warranty you do not have.
	show width       -- Line width is 173.

---------------------
[step]
---------------------

	**step** [*count*]
	
	Single step a statement *count* times.
	
	If *count* is given, stepping occurs that many times before
	stopping. Otherwise *count* is one. *count* an be an arithmetic
	expression.
	
	In contrast to "next", functions and source'd files are stepped
	into.
	
	See also:
	---------
	
	**next**, **skip**, **step-** **step+**, and **set different**.
	
	Aliases for step: s+, s-, s

---------------------
[tbreak]
---------------------

	**tbreak* [*loc-spec*]
	
	Set a one-time breakpoint at *loc-spec*.
	
	Like "break" except the breakpoint is only temporary,
	so it will be deleted when hit.  Equivalent to "break" followed
	by using "delete" on the breakpoint number.
	
	If no location specification is given, use the current line.

---------------------
[undisplay]
---------------------

	**undisplay** *display-number*...
	
	Cancel some expressions to be displayed when program stops. Arguments are the code numbers
	of the expressions to stop displaying.
	
	Examples:
	---------
	
	    undisplay 0     # Removes display statement 0
	    undisplay 0 3 4 # Removes display statements 0, 3, and 4
	
	See also:
	---------
	
	*display* and *info display*.

---------------------
[backtrace]
---------------------

	**backtrace** [*opts*] [*count*]
	
	Print backtrace of all stack frames, or inner-most *count* frames.
	
	With a negative argument, print outer-most -*count* frames.
	
	An arrow indicates the "current frame". The current frame determines
	the context used for many debugger commands such as expression
	evaluation or source-line listing.
	
	*opts* are:
	
	   -s | --source  - show source code line
	   -h | --help    - give this help
	
	Examples:
	---------
	
	   backtrace      # Print a full stack trace
	   backtrace 2    # Print only the top two entries
	   backtrace -1   # Print a stack trace except the initial (least recent) call.
	   backtrace -s   # show source lines in listing
	   backtrace --source   # same as above
	
	See also:
	---------
	
	**frame** and  **list**
	
	
	Aliases for backtrace: T, bt, where

---------------------
[condition]
---------------------

	**condition** *bp_number* *condition*
	
	Break only if *condition* is true in breakpoint number *bp_number*.
	
	*bp_number* is a breakpoint number. *condition* is a zsh expression
	which must evaluate to *True* before the breakpoint is honored.  If
	*condition* is absent, any existing condition is removed; i.e., the
	breakpoint is made unconditional.
	
	Examples:
	---------
	
	   condition 5 x > 10  # Breakpoint 5 now has condition x > 10
	   condition 5         # Remove above condition
	
	See also:
	---------
	
	*break*, *tbreak*.

---------------------
[delete]
---------------------

	**delete** {*brkpt-num*}...
	
	Delete some breakpoints.
	
	Arguments are breakpoint numbers with spaces in between. Without
	arguments, clear all breaks (but first ask for confirmation).
	
	Aliases for delete: d, unset

---------------------
[down]
---------------------

	**down** [*count*]
	
	Move the current frame down in the stack trace (to an newer frame). 0 is
	the most recent frame.
	
	If *count* is omitted, use 1.
	
	See also:
	---------
	
	**down** and **frame**.

---------------------
[eval]
---------------------

	**eval** *cmd*
	
	**eval**
	
	**eval?**
	
	In the first form *cmd* is a string; *cmd* is a string sent to special
	shell builtin eval.
	
	In the second form, use evaluate the current source line text.
	
	Often when one is stopped at the line of the first part of an "if",
	"elif", "case", "return", "while" compound statement or an assignment
	statement, one wants to eval is just the expression portion.  For
	this, use eval?. Actually, any alias that ends in ? which is aliased
	to eval will do thie same thing.
	
	If no string is given, we run the string from the current source code
	about to be run. If the command ends '?' (via an alias) and no string is
	given, the following translations occur:
	
	    {if|elif} <expr> [; then] => <expr>
	    while <expr> [; do]?      => <expr>
	    return <expr>             => <expr>
	    <var>=<expr>              => <expr>
	
	See also:
	---------
	
	**set autoeval** and **examine**.
	
	Aliases for eval: eval?, ev?, ev

---------------------
[frame]
---------------------

	**frame** [*frame-number*].
	
	Change the current frame to frame *frame-number* if specified, or the
	most-recent frame, 0, if no frame number specified.
	
	A negative number indicates the position from the other or
	least-recently-entered end.  So **frame -1** moves to the oldest frame.
	
	See also:
	---------
	
	**up**, **down**

---------------------
[info]
---------------------

	List of info subcommands:
	info breakpoints -- Status of user-settable breakpoints
	info display -- Show all display expressions
	info files -- Source files in the program
	info line -- list current line number and and file name
	info program -- Execution status of the program.
	info source -- Information about the current source file
	info stack -- Backtrace of the stack
	info variables -- All global and static variable names
	info warranty -- Various kinds of warranty you do not have
	
	
	**load** *zsh-script*
	
	Read in lines of a *zsh-script*.
	
	See also:
	---------
	**info files**

---------------------
[next-]
---------------------

	**next-**
	
	Step over stepping a statement without the **set different** setting.
	
	Set step force may have been set on. step- ensures we turn that off for
	this command.
	
	See also:
	---------
	
	**next+**, **next**, and **set different**.

---------------------
[quit]
---------------------

	**quit** [*exit-code* [*shell-levels*]]
	
	Gently quit the debugger.
	
	The program being debugged is aborted.  If *exit-code* is given, then
	that will be the exit return code. If *shell-levels* is given, then up
	to that many nested shells are quit. However to be effective, the last
	of those shells should have been run under the debugger.
	
	See also:
	---------
	
	**kill**, **run** and **restart**.
	
	Aliases for quit: q!, exit, q
	set
	set annotate    -- Set annotation level.
	set args        -- Set argument list to give program when it is restarted.
	set autoeval    -- auto evaluation of unrecognized commands is off.
	set autolist    -- auto listing on debugger stop is off.
	set basename    -- short filenames (the basename) is off.
	set confirm     -- confirm dangerous operations on.
	set debug       -- debug the debugger is off.
	set different   -- stop on different lines is off.
	set editing     -- Set editing of command lines as they are typed is on.
	set highlight   -- Set syntax highlighting of source listings is light
	set history     -- Set record command history is off.
	set linetrace   -- Set tracing execution of lines before executed is off.
	set listsize    -- Set number of lines in listings is 10
	set prompt      -- prompt string
	set showcommand -- Set showing the command to execute is .
	set style       -- Set pygments highlighting style is off.
	set width       -- Set maximum width of lines is 173.

---------------------
[skip]
---------------------

	**skip** [*count*]
	
	Skip over (don't run) the next *count* command(s).
	
	If *count* is given, stepping occurs that many times before
	stopping. Otherwise *count* is one. *count* can be an arithmetic
	expression.
	
	Note that skipping doesn't change the value of ${?}. This has
	consequences in some compound statements that test on ${?}. For example
	in:
	
	   if grep foo bar.txt ; then
	      echo not skipped
	   fi
	
	Skipping the *if* statement will, in effect, skip running the *grep*
	command. Since the return code is 0 when skipped, the *if* body is
	entered. Similarly the same thing can  happen in a *while* statement
	test.
	
	See also:
	---------
	
	**continue**, **next**, and **step**.

---------------------
[step+]
---------------------

	**step+**
	
	Single step a statement ensuring a different line after the step.
	
	In contrast to **step**, we ensure that the file and line position is
	different from the last one just stopped at.
	
	See also:
	---------
	
	**step-** and **set different**.

---------------------
[trace]
---------------------

	**trace** *function*
	
	trace alias *alias*
	
	Set "xtrace" (set -x) tracing when *function* is called.

---------------------
[untrace]
---------------------

	**untrace** *function*
	
	Untrace previuosly traced *function*.

tip_zshdb_EOF
}

tip_zsh_params () {
echo ${E_BOLD}${E_WHITE_FG}${(C)${0/tip_/}} Tips${E_RESET}

local PARAM_1=ABC

cat << EP1
\${name}

The value, if any, of the parameter name is substituted. The braces are required if the expansion is
to be followed by a  letter,  digit,  or underscore that  is not to be interpreted as part of name.
In addition, more complicated forms of substitution usually require the braces to be present;
exceptions, which only apply if the option KSH_ARRAYS is not set, are a single subscript or any
colon modifiers appearing after the name, or  any  of  the  characters '^', '=', '~', '#' or '+'
appearing before the name, all of which work with or without braces.

If  name is an array parameter, and the KSH_ARRAYS option is not set, then the value of each element
of name is substituted, one element per word.  Otherwise, the expansion results in one word only;
with KSH_ARRAYS, this is the first element of an array.  No field splitting is done on the result
unless the SH_WORD_SPLIT option is set.  See also the flags = and s:string:.
EP1
echo "\nWith: PARAM_1=ABC"

echo ${WHITE_FG}
echo "\n\${PARAM_1} == ${PARAM_1}"
echo "\${PARAM_2} == ${PARAM_2}\n"
echo ${RESET}

cat << EP1
\${+name}

If name is the name of a set parameter '1' is substituted, otherwise '0' is substituted.
EP1

echo ${WHITE_FG}
echo "\n\${+PARAM_1} == ${+PARAM_1}"
echo "\${+PARAM_2} == ${+PARAM_2}\n"
echo ${RESET}
 
cat << EP1
\${name-word} \${name:-word}

If name is set, or in the second form is non-null, then substitute its value; otherwise substitute word.
In the second form name may be omitted, in which case word is always substituted.
EP1

echo ${WHITE_FG}
echo "\n\${PARAM_1-word} == ${PARAM_1-word}"
echo "\${PARAM_1:-word} == ${PARAM_1:-word}\n"
echo ${RESET}

cat << EP1
\${name+word} \${name:+word}

If name is set, or in the second form is non-null, then substitute word; otherwise substitute nothing.
EP1

echo ${WHITE_FG}
echo "\n\${PARAM_1+word} == ${PARAM_1+word}"
echo "\${PARAM_1:+word} == ${PARAM_1:+word}\n"
echo ${RESET}

cat << EP1
\${name=word} \${name:=word} \${name::=word}

In the first form, if name is unset then set it to word
In the second form, if name is unset or null then set it to word
In the third form, unconditionally set name to word.
In all forms, the value of the parameter is then substituted.
EP1

echo ${WHITE_FG}
echo "\n\${PARAM_1=word} == ${PARAM_1=word}"
echo "\${PARAM_1:=word} == ${PARAM_1:=word}"
echo "\${PARAM_1::=word} == ${PARAM_1::=word}\n"
echo ${RESET}

cat << EP1
\${name?word} \${name:?word}

In the first form, if name is set, or in the second form if name is both set and non-null, then
substitute its value; otherwise, print word and exit from the shell.  Interactive shells instead
return to the prompt.  If word is omitted, then a standard message is printed.
EP1

echo ${WHITE_FG}
echo "\n\${PARAM_1?word} == ${PARAM_1?word}"
echo "\${PARAM_1:?word} == ${PARAM_1:?word}"
echo ${RESET}

echo ${CYAN_FG}
cat << EP1
In any of the above expressions that test a variable and substitute an alternate word, note that you
can use standard shell quoting in the word value  to  selectively override the splitting done by the
SH_WORD_SPLIT option and the = flag, but not splitting by the s:string: flag.
EP1
echo ${RESET}


echo ${GREEN_FG}
cat << EP1
In the following expressions, when name is an array and the substitution is not quoted, or if the '(@)'
flag or the name[@] syntax is used, matching and replacement is performed on each array element separately.

If the pattern matches the beginning of the value of name, then substitute the value of name with
the matched portion deleted; otherwise, just  substitute the value of name.  In the first form, the
smallest matching pattern is preferred; in the second form, the largest matching pattern is preferred.
EP1
echo ${RESET}


cat << EP1
\${name%pattern} \${name%%pattern}

If the pattern matches the end of the value of name, then substitute the value of name with
the matched portion deleted; otherwise, just substitute the value of name.  In the first form, the
smallest matching pattern is preferred; in the second form, the largest matching pattern is preferred.
EP1

local NAME=ABC
local PATTERN=ABF

echo ${WHITE_FG}
echo "NAME=${NAME}"
echo "PATTERN=${PATTERN}"
echo "\n\${name%pattern} == ${${NAME}%${PATTERN}}"
echo "\${name%%pattern} == ${${NAME}%%${PATTERN}}"
echo ${RESET}

cat << EP1
\${name:#pattern}

If the pattern matches the value of name, then substitute the empty string; otherwise, just substitute
the value of name.  If name is an array the  matching array elements are removed (use the '(M)'
flag to remove the non-matched elements).
EP1

echo ${WHITE_FG}
echo "NAME=${NAME}"
echo "PATTERN=${PATTERN}"
echo "\n\${name#pattern} == ${${NAME}#${PATTERN}}\n"
echo ${RESET}

cat << EP1
\${name:|arrayname}

If  arrayname  is  the name (N.B., not contents) of an array variable, then any elements contained in
arrayname are removed from the substitution of name.  If the substitution is scalar, either because
name is a scalar variable or the expression is quoted, the elements of arrayname are instead tested
against the entire expression.
EP1

local A1=(one two three four five)
local A2=(one)

echo ${WHITE_FG}
echo "A1:${A1}"
echo "A2:${A2}"

echo -n "\n\${A1:|A2} == "
echo ${A1:|A2} # can't be quoted
echo ${RESET}

cat << EP1
\${name:*arrayname}

Similar  to  the preceding substitution, but in the opposite sense, so that entries present in both
the original substitution and as elements of arrayname are retained and others removed.
EP1

echo ${WHITE_FG}
echo "A1:${A1}"
echo "A2:${A2}"

echo -n "\n\${A1*|A2} == "
echo ${A1:*A2} # can't be quoted
echo ${RESET}
 
cat << EP1
\${name:^arrayname} \${name:^^arrayname}

Zips two arrays, such that the output array is twice as long as the shortest (longest for ':^^')
of name and arrayname, with  the elements  alternatingly being picked from them. For ':^', if one
of the input arrays is longer, the output will stop when the end of the shorter array is reached.  Thus,

a=(1 2 3 4); b=(a b); print \${a:^b}

will output '1 a 2 b'.  For ':^^', then the input is repeated until all of the longer array has been
used up and the above will output '1 a 2 b 3 a 4 b'.

Either  or  both inputs may be a scalar, they will be treated as an array of length 1 with the scalar
as the only element. If either array is empty, the other array is output with no extra elements inserted.

Currently the following code will output 'a b' and '1' as two separate elements, which can be
unexpected. The second print  provides  a  workaround  which should continue to work if this is changed.

a=(a b); b=(1 2); print -l "\${a:^b}"; print -l "\${\${a:^b}}"
EP1

echo ${WHITE_FG}
echo "A1:${A1}"
echo "A2:${A2}"

echo -n "\n\${A1:^A2} == "
echo ${A1:^A2} # can't be quoted
echo -n "\${A1:^^|A2} == "
echo ${A1:^^A2} # can't be quoted
echo ${RESET}

cat << EP1
\${name:offset} \${name:offset:length}

This  syntax  gives effects similar to parameter subscripting in the form \$name[start,end], but is
compatible with other shells; note that both offset and length are interpreted differently from the
components of a subscript.

If offset is non-negative, then if the variable name is a scalar substitute the contents starting
offset  characters  from the  first  character  of  the string, and if name is an array substitute
elements starting offset elements from the first element.  If length is given, substitute that many
characters or elements, otherwise the entire rest of the scalar or array.

A positive offset is always treated as the offset of a character or element in name from the first
character or element of the array  (this is  different from native zsh subscript notation).  Hence 0
refers to the first character or element regardless of the setting of the option KSH_ARRAYS.

A negative offset counts backwards from the end of the scalar or array, so that -1 corresponds to
the last character or element, and so on.

When  positive,  length  counts  from the offset position toward the end of the scalar or array.
When negative, length counts back from the end.  If this results in a position smaller than offset,
a diagnostic is printed and nothing is substituted.

The option MULTIBYTE is obeyed, i.e. the offset and length count multibyte characters where appropriate.

offset and length undergo the same set of shell substitutions as for scalar assignment; in addition,
they  are  then  subject to  arithmetic evaluation.  Hence, for example

print \${foo:3} print \${foo: 1 + 2} print \${foo:\$(( 1 + 2))} print \${foo:\$(echo 1 + 2)}

all have the same effect, extracting the string starting at the fourth character of \$foo if the
substitution would otherwise return a scalar, or the array starting at the fourth element if \$foo
would return an array.  Note that with the option KSH_ARRAYS \$foo always returns a scalar (regardless
of the use of the offset syntax) and a form such as \${foo[*]:3} is required to extract elements of
an array named foo.

If  offset  is  negative,  the - may not appear immediately after the : as this indicates the
\${name:-word} form of substitution.  Instead, a space may be inserted before the -.  Furthermore,
neither offset nor length may begin with an alphabetic character or & as these are  used to
indicate history-style modifiers.  To substitute a value from a variable, the recommended approach
is to precede it with a \$ as this signifies the intention (parameter substitu‐ tion can easily be
rendered unreadable); however, as arithmetic substitution is performed, the expression \${var: offs}
does work,  retrieving  the  offset from \$offs.

For  further  compatibility with other shells there is a special case for array offset 0.  This usually
accesses the first element of the array. However, if the substitution refers to the positional
parameter array, e.g. \$@ or \$*, then offset 0 instead refers to \$0, offset 1 refers to \$1,  and
so  on. In other words, the positional parameter array is effectively extended by prepending \$0.
Hence \${*:0:1} substitutes \$0 and \${*:1:1} substitutes \$1.
EP1

local VAR="abcdefghijklmnopqrstuvwxyz"

echo ${WHITE_FG}
echo "VAR:${VAR}"
echo "\n\${VAR:5} == ${VAR:5}"
echo "\${VAR:5:2} == ${VAR:5:2}"
echo "\${VAR: -3:3} == ${VAR: -3:3}"
echo ${RESET}

cat << EP1
\${name/pattern/repl} \${name//pattern/repl} \${name:/pattern/repl}

Replace  the  longest possible match of pattern in the expansion of parameter name by string repl.
The first form replaces just the first occurrence, the second form all occurrences, and the third
form replaces only if pattern matches the entire string. Both pattern and repl are  subject  to
double-quoted substitution,  so  that expressions like \${name/\$opat/\$npat} will work, but obey
the usual rule that pattern characters in \$opat are not treated specially unless either the option
GLOB_SUBST is set, or \$opat is instead substituted as \${~opat}.

The pattern may begin with a '#', in which case the pattern must match at the start of the string,
or '%', in which case it must match at the end  of  the string, or '#%' in which case the pattern
must match the entire string.  The repl may be an empty string, in which case the final '/' may also
be omitted.  To quote the final '/' in other cases it should be preceded by a single backslash;
this is not necessary if the '/' occurs inside a substituted parameter.  Note also that the '#',
'%' and '#%' are not active if they occur inside a substituted parameter, even at the start.

If, after quoting rules apply, \${name} expands to an array, the replacements act on each element
individually.  Note also the effect of the I and S parameter expansion flags below; however,
the flags M, R, B, E and N are not useful.

For example,

foo="twinkle twinkle little star" sub="t*e" rep="spy" print \${foo//\${~sub}/\$rep} print
\${(S)foo//\${~sub}/\$rep}

Here, the '~' ensures that the text of \$sub is treated as a pattern rather than a plain string.
In the first case, the longest match for t*e  is substituted and the result is 'spy star',
while in the second case, the shortest matches are taken and the result is 'spy spy lispy star'.
EP1

local VAR1="the quick brown fox chases the lazy dog"
local local VAR2="twinkle twinkle little star"
local VAR3="one two three"
local SUB="t*e"
local REP="spy"

echo ${WHITE_FG}

#\${name/pattern/repl} \${name//pattern/repl} \${name:/pattern/repl}
echo "VAR1:${VAR1}"
echo "\nVAR2:${VAR2}"
echo "SUB:${SUB}"
echo "REP:${REP}"
echo "\nVAR3:${VAR3}"
echo "\n\${VAR1${BOLD}/${RESET}${WHITE_FG}quick brown/slow black} == ${VAR1/quick brown/slow black}"
echo "\${(S)VAR2//\${~SUB}/\$REP} == ${(S)VAR2//${~SUB}/$REP}"
echo "\${VAR3${BOLD}:/${RESET}${WHITE_FG}one two three/four five six} == ${VAR3:/one two three/four five six}"

echo ${RESET}
cat << EP1
\${#spec}

If  spec is  one of the above substitutions, substitute the length in characters of the result
instead of the result itself.  If spec is an array expres‐ sion, substitute the number of elements
of the result.  This has the side-effect that joining is skipped even in quoted  forms,  which  may
affect  other sub-expressions in spec.  Note that '^', '=', and '~', below, must appear to the left of
'#' when these forms are combined.

If  the option POSIX_IDENTIFIERS is not set, and spec is a simple name, then the braces are optional;
this is true even for special parameters so e.g. \$#- and \$#* take the length of the string \$- and
the array \$* respectively.  If POSIX_IDENTIFIERS is set, then braces are required for the # to be
treated  in this fashion.
EP1

echo ${WHITE_FG}

VAR="abcdefghijklmnopqrstuvwxyz"
echo "VAR:${VAR}"
echo "\n\${#VAR} == ${#VAR}"

echo ${RESET}
cat << EP1
\${^spec}

Turn  on the RC_EXPAND_PARAM option for the evaluation of spec; if the '^' is doubled, turn it off.
When this option is set, array expansions of the form foo\${xx}bar, where the parameter xx is set
to (a b c), are substituted with 'fooabar foobbar foocbar' instead of the default 'fooa b cbar'.
Note that  an empty array will therefore cause all arguments to be removed.

Internally,  each such expansion is converted into the equivalent list for brace expansion.  E.g.,
\${^var} becomes {\$var[1],\$var[2],...}, and is processed as described in the section 'Brace Expansion'
below: note, however, the expansion happens immediately, with any explicit brace expansion happening
later.  If word splitting is also in effect the \$var[N] may themselves be split into different
list elements.
EP1

echo ${WHITE_FG}

local AR=(a b c)

echo "AR:${AR}"
echo "\nfoo\${^AR}bar == " foo${^AR}bar
echo "foo\${^^AR}bar == " foo${^^AR}bar

echo ${RESET}

cat << EP1
\${=spec}

Perform  word splitting using the rules for SH_WORD_SPLIT during the evaluation of spec, but regardless
of whether the parameter appears in double quotes; if the '=' is doubled, turn it off.  This forces
parameter expansions to be split into separate words before substitution, using IFS as a delimiter.
This is done by default in most other shells.

Note  that  splitting  is  applied  to  word in the assignment forms of spec before the assignment
to name is performed.  This affects the result of array assignments with the A flag.
EP1

echo
echo

cat << EP1
\${~spec}

Turn on the GLOB_SUBST option for the evaluation of spec; if the '~' is doubled, turn it off.  When this
option is set,  the  string  resulting  from  the expansion  will be interpreted as a pattern anywhere
that is possible, such as in filename expansion and filename generation and pattern-matching contexts
like the right hand side of the '=' and '!=' operators in conditions.

In nested substitutions, note that the effect of the ~ applies to the result of the current level of
substitution.  A surrounding pattern operation on the result  may  cancel it.  Hence, for example,
if the parameter foo is set to *, \${~foo//\*/*.c} is substituted by the pattern *.c, which may be
expanded by filename generation, but \${\${~foo}//\*/*.c} substitutes to the string *.c, which will
not be further expanded.

If a \${...} type parameter expression or a \$(...) type command substitution is used in place of name
above, it is expanded first and the result is used as if  it were  the  value  of  name.   Thus it  is
possible to perform nested operations:  \${\${foo#head}%tail} substitutes the value of \$foo with both 'head'
and 'tail' deleted.  The form with \$(...) is often useful in combination with the flags described next;
see the examples below. Each name or nested \${...} in  a  parameter expansion may also be followed by a
subscript expression as described in Array Parameters in zshparam(1).

Note  that  double  quotes  may appear around nested expressions, in which case only the part inside is
treated as quoted; for example, \${(f)"\$(foo)"} quotes the result of \$(foo), but the flag '(f)' (see below)
is applied using the rules for unquoted expansions.  Note further that quotes are themselves nested in
this con‐ text;  for  example,  in  "\${(@f)"\$(foo)"}",  there are two sets of quotes, one surrounding
the whole expression, the other (redundant) surrounding the \$(foo) as before.
EP1

touch /tmp/file_1.c 
touch /tmp/file_2.c 
touch /tmp/file_3.c

local FOO='*'

echo ${WHITE_FG}
echo "touch /tmp/file_1.c"
echo "touch /tmp/file_2.c"
echo "touch /tmp/file_3.c"

echo "\nFOO:${FOO}"
echo "\n\${~FOO//\*//\/tmp/*.c}" ${~FOO//\*/\/tmp/*.c}
echo "\${~~FOO//\*//\/tmp/*.c}" ${~~FOO//\*/\/tmp/*.c}

rm /tmp/file_1.c 
rm /tmp/file_2.c 
rm /tmp/file_3.c

echo "\n${WHITE_FG}Parameter Expansion Flags${RESET}\n"
cat << EP1
 If  the  opening  brace  is  directly followed by an opening parenthesis, the string up to the matching closing parenthesis will be taken as a list of flags.  In
 cases where repeating a flag is meaningful, the repetitions need not be consecutive; for example, '(q%q%q)' means the same thing as the more readable  '(%%qqq)'.
 The following flags are supported:

 #      Evaluate  the resulting words as numeric expressions and interpret these as character codes.  Output the corresponding characters.  Note that this form is
    entirely distinct from use of the # without parentheses.

    If the MULTIBYTE option is set and the number is greater than 127 (i.e. not an ASCII character) it is treated as a Unicode character.

 %      Expand all % escapes in the resulting words in the same way as in prompts (see EXPANSION OF PROMPT SEQUENCES in zshmisc(1)). If this flag is given  twice,
    full prompt expansion is done on the resulting words, depending on the setting of the PROMPT_PERCENT, PROMPT_SUBST and PROMPT_BANG options.

 @      In  double  quotes,  array elements are put into separate words.  E.g., '"\${(@)foo}"' is equivalent to '"\${foo[@]}"' and '"\${(@)foo[1,2]}"' is the same as
    '"\$foo[1]" "\$foo[2]"'.  This is distinct from field splitting by the f, s or z flags, which still applies within each array element.

 A      Convert the substitution into an array expression, even if it otherwise would be scalar.  This has lower precedence than subscripting,  so  one  level  of
    nested expansion is required in order that subscripts apply to array elements.  Thus \${\${(A)name}[1]} yields the full value of name when name is scalar.

    This  assigns  an array parameter with '\${...=...}', '\${...:=...}' or '\${...::=...}'.  If this flag is repeated (as in 'AA'), assigns an associative array
    parameter.  Assignment is made before sorting or padding; if field splitting is active, the word part is split before assignment.  The name part may be  a
    subscripted  range  for  ordinary  arrays;  when  assigning  an  associative  array,  the  word  part  must be converted to an array, for example by using
    '\${(AA)=name=...}' to activate field splitting.

    Surrounding context such as additional nesting or use of the value in a scalar assignment may cause the array to be  joined  back  into  a  single  string
    again.

 a      Sort  in  array  index  order; when combined with 'O' sort in reverse array index order.  Note that 'a' is therefore equivalent to the default but 'Oa' is
    useful for obtaining an array's elements in reverse order.

 b      Quote with backslashes only characters that are special to pattern matching. This is useful when the contents of the  variable  are  to  be  tested  using
    GLOB_SUBST, including the \${~...} switch.

    Quoting  using  one  of  the q family of flags does not work for this purpose since quotes are not stripped from non-pattern characters by GLOB_SUBST.  In
    other words,

     pattern=\${(q)str}
     [[ \$str = \${~pattern} ]]

    works if \$str is 'a*b' but not if it is 'a b', whereas

     pattern=\${(b)str}
     [[ \$str = \${~pattern} ]]

    is always true for any possible value of \$str.

 c      With \${#name}, count the total number of characters in an array, as if the elements were concatenated with spaces between them.  This is not a  true  join
    of the array, so other expressions used with this flag may have an effect on the elements of the array before it is counted.

 C      Capitalize the resulting words.  'Words' in this case refers to sequences of alphanumeric characters separated by non-alphanumerics, not to words that re‐
    sult from field splitting.

 D      Assume the string or array elements contain directories and attempt to substitute the leading part of these by names.  The  remainder  of  the  path  (the
    whole  of it if the leading part was not substituted) is then quoted so that the whole string can be used as a shell argument.  This is the reverse of '~'
    substitution:  see the section FILENAME EXPANSION below.

 e      Perform single word shell expansions, namely parameter expansion, command substitution and arithmetic expansion, on the result.  Such  expansions  can  be
    nested but too deep recursion may have unpredictable effects.

 f      Split the result of the expansion at newlines. This is a shorthand for 'ps:\n:'.

 F      Join the words of arrays together using newline as a separator.  This is a shorthand for 'pj:\n:'.

 g:opts:
    Process  escape  sequences like the echo builtin when no options are given (g::).  With the o option, octal escapes don't take a leading zero.  With the c
    option, sequences like '^X' are also processed.  With the e option, processes '\M-t' and similar sequences like the print builtin.  With both of the o and
    e options, behaves like the print builtin except that in none of these modes is '\c' interpreted.

 i      Sort case-insensitively.  May be combined with 'n' or 'O'.

 k      If name refers to an associative array, substitute the keys (element names) rather than the values of the elements.  Used with subscripts (including ordi‐
    nary arrays), force indices or keys to be substituted even if the subscript form refers to values.  However, this flag may not be combined with  subscript
    ranges.  With the KSH_ARRAYS option a subscript '[*]' or '[@]' is needed to operate on the whole array, as usual.

 L      Convert all letters in the result to lower case.

 n      Sort  decimal integers numerically; if the first differing characters of two test strings are not digits, sorting is lexical.  '+' and '-' are not treated
    specially; they are treated as any other non-digit.  Integers with more initial zeroes are sorted before those  with  fewer  or  none.   Hence  the  array
    'foo+24 foo1 foo02 foo2 foo3 foo20 foo23' is sorted into the order shown.  May be combined with 'i' or 'O'.

 -      As  n,  but  a leading minus sign indicates a negative decimal integer.  A leading minus sign not followed by an integer does not trigger numeric sorting.
    Note that '+' signs are not handled specially (this may change in the future).

 o      Sort the resulting words in ascending order; if this appears on its own the sorting is lexical and case-sensitive (unless the locale renders  it  case-in‐
    sensitive).  Sorting in ascending order is the default for other forms of sorting, so this is ignored if combined with 'a', 'i', 'n' or '-'.

 O      Sort  the resulting words in descending order; 'O' without 'a', 'i', 'n' or '-' sorts in reverse lexical order.  May be combined with 'a', 'i', 'n' or '-'
    to reverse the order of sorting.

 P      This forces the value of the parameter name to be interpreted as a further parameter name, whose value will be used where appropriate.   Note  that  flags
    set with one of the typeset family of commands (in particular case transformations) are not applied to the value of name used in this fashion.

    If  used  with a nested parameter or command substitution, the result of that will be taken as a parameter name in the same way.  For example, if you have
    'foo=bar' and 'bar=baz', the strings \${(P)foo}, \${(P)\${foo}}, and \${(P)\$(echo bar)} will be expanded to 'baz'.

    Likewise, if the reference is itself nested, the expression with the flag is treated as if it were directly replaced by the parameter name.  It is an  er‐
    ror  if  this nested substitution produces an array with more than one word.  For example, if 'name=assoc' where the parameter assoc is an associative ar‐
    ray, then '\${\${(P)name}[elt]}' refers to the element of the associative subscripted 'elt'.

 q      Quote characters that are special to the shell in the resulting words with backslashes; unprintable or invalid characters are  quoted  using  the  \$'\NNN'
    form, with separate quotes for each octet.

    If  this  flag  is  given twice, the resulting words are quoted in single quotes and if it is given three times, the words are quoted in double quotes; in
    these forms no special handling of unprintable or invalid characters is attempted.  If the flag is given four times, the words are quoted in single quotes
    preceded  by  a \$.  Note that in all three of these forms quoting is done unconditionally, even if this does not change the way the resulting string would
    be interpreted by the shell.

    If a q- is given (only a single q may appear), a minimal form of single quoting is used that only quotes the string if needed to protect  special  charac‐
    ters.  Typically this form gives the most readable output.

    If  a q+ is given, an extended form of minimal quoting is used that causes unprintable characters to be rendered using \$'...'.  This quoting is similar to
    that used by the output of values by the typeset family of commands.

 Q      Remove one level of quotes from the resulting words.

 t      Use a string describing the type of the parameter where the value of the parameter would usually appear. This string consists of keywords separated by hy‐
    phens  ('-').  The first keyword in the string describes the main type, it can be one of 'scalar', 'array', 'integer', 'float' or 'association'. The other
    keywords describe the type in more detail:

    local  for local parameters

    left   for left justified parameters

    right_blanks
     for right justified parameters with leading blanks

    right_zeros
     for right justified parameters with leading zeros

    lower  for parameters whose value is converted to all lower case when it is expanded

    upper  for parameters whose value is converted to all upper case when it is expanded

    readonly
     for readonly parameters

    tag    for tagged parameters

    tied   for parameters tied to another parameter in the manner of PATH (colon-separated list) and path (array), whether these  are  special  parameters  or
     user-defined with 'typeset -T'

    export for exported parameters

    unique for arrays which keep only the first occurrence of duplicated values

    hide   for parameters with the 'hide' flag

    hideval
     for parameters with the 'hideval' flag

    special
     for special parameters defined by the shell

 u      Expand only the first occurrence of each unique word.

 U      Convert all letters in the result to upper case.

 v      Used with k, substitute (as two consecutive words) both the key and the value of each associative array element.  Used with subscripts, force values to be
    substituted even if the subscript form refers to indices or keys.

 V      Make any special characters in the resulting words visible.

 w      With \${#name}, count words in arrays or strings; the s flag may be used to set a word delimiter.

 W      Similar to w with the difference that empty words between repeated delimiters are also counted.

 X      With this flag, parsing errors occurring with the Q, e and # flags or the pattern matching forms such as  '\${name#pattern}'  are  reported.   Without  the
    flag, errors are silently ignored.

 z      Split  the  result of the expansion into words using shell parsing to find the words, i.e. taking into account any quoting in the value.  Comments are not
    treated specially but as ordinary strings, similar to interactive shells with the INTERACTIVE_COMMENTS option unset (however, see the Z flag below for re‐
    lated options)

    Note  that  this is done very late, even later than the '(s)' flag. So to access single words in the result use nested expansions as in '\${\${(z)foo}[2]}'.
    Likewise, to remove the quotes in the resulting words use '\${(Q)\${(z)foo}}'.

 0      Split the result of the expansion on null bytes.  This is a shorthand for 'ps:\0:'.

 The following flags (except p) are followed by one or more arguments as shown.  Any character, or the matching pairs '(...)', '{...}', '[...]', or  '<...>',  may
 be used in place of a colon as delimiters, but note that when a flag takes more than one argument, a matched pair of delimiters must surround each argument.

 p      Recognize the same escape sequences as the print builtin in string arguments to any of the flags described below that follow this argument.

    Alternatively,  with  this  option  string  arguments  may  be in the form \$var in which case the value of the variable is substituted.  Note this form is
    strict; the string argument does not undergo general parameter expansion.

    For example,

     sep=:
     val=a:b:c
     print \${(ps.\$sep.)val}

    splits the variable on a :.

 ~      Strings inserted into the expansion by any of the flags below are to be treated as patterns.  This applies to the string arguments of flags that follow  ~
    within  the  same  set of parentheses.  Compare with ~ outside parentheses, which forces the entire substituted string to be treated as a pattern.  Hence,
    for example,

     [[ "?" = \${(~j.|.)array} ]]

    treats '|' as a pattern and succeeds if and only if \$array contains the string '?' as an element.  The ~ may be repeated to toggle the behaviour; its  ef‐
    fect only lasts to the end of the parenthesised group.

 j:string:
    Join  the  words  of arrays together using string as a separator.  Note that this occurs before field splitting by the s:string: flag or the SH_WORD_SPLIT
    option.

 l:expr::string1::string2:
    Pad the resulting words on the left.  Each word will be truncated if required and placed in a field expr characters wide.

    The arguments :string1: and :string2: are optional; neither, the first, or both may be given.  Note that the same pairs of delimiters  must  be  used  for
    each  of  the three arguments.  The space to the left will be filled with string1 (concatenated as often as needed) or spaces if string1 is not given.  If
    both string1 and string2 are given, string2 is inserted once directly to the left of each word, truncated if necessary, before string1 is used to  produce
    any remaining padding.

    If either of string1 or string2 is present but empty, i.e. there are two delimiters together at that point, the first character of \$IFS is used instead.

    If the MULTIBYTE option is in effect, the flag m may also be given, in which case widths will be used for the calculation of padding; otherwise individual
    multibyte characters are treated as occupying one unit of width.

    If the MULTIBYTE option is not in effect, each byte in the string is treated as occupying one unit of width.

    Control characters are always assumed to be one unit wide; this allows the mechanism to be used for generating repetitions of control characters.

 m      Only useful together with one of the flags l or r or with the # length operator when the MULTIBYTE option is in effect.  Use the character width  reported
    by  the system in calculating how much of the string it occupies or the overall length of the string.  Most printable characters have a width of one unit,
    however certain Asian character sets and certain special effects use wider characters; combining characters have zero width.  Non-printable characters are
    arbitrarily counted as zero width; how they would actually be displayed will vary.

    If  the m is repeated, the character either counts zero (if it has zero width), else one.  For printable character strings this has the effect of counting
    the number of glyphs (visibly separate characters), except for the case where combining characters themselves have non-zero width (true in certain  alpha‐
    bets).

 r:expr::string1::string2:
    As l, but pad the words on the right and insert string2 immediately to the right of the string to be padded.

    Left  and  right padding may be used together.  In this case the strategy is to apply left padding to the first half width of each of the resulting words,
    and right padding to the second half.  If the string to be padded has odd width the extra padding is applied on the left.

 s:string:
    Force field splitting at the separator string.  Note that a string of two or more characters means that all of them must match in sequence;  this  differs
    from  the  treatment of two or more characters in the IFS parameter.  See also the = flag and the SH_WORD_SPLIT option.  An empty string may also be given
    in which case every character will be a separate element.

    For historical reasons, the usual behaviour that empty array elements are retained inside double quotes is disabled for  arrays  generated  by  splitting;
    hence the following:

     line="one::three"
     print -l "\${(s.:.)line}"

    produces  two  lines  of  output  for  one  and  three  and  elides  the  empty  field.   To  override this behaviour, supply the '(@)' flag as well, i.e.
    "\${(@s.:.)line}".

 Z:opts:
    As z but takes a combination of option letters between a following pair of delimiter characters.  With no options the effect is identical to z.  The  fol‐
    lowing options are available:

    (Z+c+) causes comments to be parsed as a string and retained; any field in the resulting array beginning with an unquoted comment character is a comment.

    (Z+C+) causes  comments  to  be  parsed  and  removed.   The  rule  for comments is standard: anything between a word starting with the third character of
     \$HISTCHARS, default #, up to the next newline is a comment.

    (Z+n+) causes unquoted newlines to be treated as ordinary whitespace, else they are treated as if they are shell code delimiters and  converted  to  semi‐
     colons.

    Options are combined within the same set of delimiters, e.g. (Z+Cn+).

 _:flags:
    The underscore (_) flag is reserved for future use.  As of this revision of zsh, there are no valid flags; anything following an underscore, other than an
    empty pair of delimiters, is treated as an error, and the flag itself has no effect.

 The following flags are meaningful with the \${...#...} or \${...%...} forms.  The S, I, and * flags may also be used with the \${.../...} forms.

 S      With # or ##, search for the match that starts closest to the start of the string (a 'substring match'). Of all matches at a particular  position,  #  se‐
    lects the shortest and ## the longest:

     % str="aXbXc"
     % echo \${(S)str#X*}
     abXc
     % echo \${(S)str##X*}
     a
     %

    With % or %%, search for the match that starts closest to the end of the string:

     % str="aXbXc"
     % echo \${(S)str%X*}
     aXbc
     % echo \${(S)str%%X*}
     aXb
     %

    (Note that % and %% don\'t search for the match that ends closest to the end of the string, as one might expect.)

    With substitution via \${.../...} or \${...//...}, specifies non-greedy matching, i.e. that the shortest instead of the longest match should be replaced:

     % str="abab"
     % echo \${str/*b/_}
     _
     % echo \${(S)str/*b/_}
     _ab
     %

 I:expr:
    Search  the  exprth match (where expr evaluates to a number).  This only applies when searching for substrings, either with the S flag, or with \${.../...}
    (only the exprth match is substituted) or \${...//...} (all matches from the exprth on are substituted).  The default is to take the first match.

    The exprth match is counted such that there is either one or zero matches from each starting position in the  string,  although  for  global  substitution
    matches  overlapping  previous  replacements  are ignored.  With the \${...%...} and \${...%%...} forms, the starting position for the match moves backwards
    from the end as the index increases, while with the other forms it moves forward from the start.

    Hence with the string
     which switch is the right switch for Ipswich?
    substitutions of the form \${(SI:N:)string#w*ch} as N increases from 1 will match and remove 'which', 'witch', 'witch' and 'wich'; the form using '##' will
    match  and  remove 'which switch is the right switch for Ipswich', 'witch is the right switch for Ipswich', 'witch for Ipswich' and 'wich'. The form using
    '%' will remove the same matches as for '#', but in reverse order, and the form using '%%' will remove the same matches as for '##' in reverse order.

 *      Enable EXTENDED_GLOB for substitution via \${.../...} or \${...//...}.  Note that '**' does not disable extendedglob.

 B      Include the index of the beginning of the match in the result.

 E      Include the index one character past the end of the match in the result (note this is inconsistent with other uses of parameter index).

 M      Include the matched portion in the result.

 N      Include the length of the match in the result.

 R      Include the unmatched portion in the result (the Rest).
EP1
}
tip_zsh_primitives () {
(
cat<<DOC
CONDITIONAL EXPRESSIONS
       A conditional expression is used with the [[ compound command to test attributes of  files  and
       to compare strings.  Each expression can be constructed from one or more of the following unary
       or binary expressions:

       -a file
	      true if file exists.

       -b file
	      true if file exists and is a block special file.

       -c file
	      true if file exists and is a character special file.

       -d file
	      true if file exists and is a directory.

       -e file
	      true if file exists.

       -f file
	      true if file exists and is a regular file.

       -g file
	      true if file exists and has its setgid bit set.

       -h file
	      true if file exists and is a symbolic link.

       -k file
	      true if file exists and has its sticky bit set.

       -n string
	      true if length of string is non-zero.

       -o option
	      true if option named option is on.  option may be a single character, in which  case  it
	      is a single letter option name.  (See the section 'Specifying Options'.)

       -p file
	      true if file exists and is a FIFO special file (named pipe).

       -r file
	      true if file exists and is readable by current process.

       -s file
	      true if file exists and has size greater than zero.

       -t fd  true if file descriptor number fd is open and associated with a terminal device.	(note:
	      fd is not optional)

       -u file
	      true if file exists and has its setuid bit set.

       -w file
	      true if file exists and is writable by current process.

       -x file
	      true if file exists and is executable by current process.   If  file  exists  and  is  a
	      directory, then the current process has permission to search in the directory.

       -z string
	      true if length of string is zero.

       -L file
	      true if file exists and is a symbolic link.

       -O file
	      true if file exists and is owned by the effective user ID of this process.

       -G file
	      true if file exists and its group matches the effective group ID of this process.

       -S file
	      true if file exists and is a socket.

       -N file
	      true if file exists and its access time is not newer than its modification time.

       file1 -nt file2
	      true if file1 exists and is newer than file2.

       file1 -ot file2
	      true if file1 exists and is older than file2.

       file1 -ef file2
	      true if file1 and file2 exist and refer to the same file.

       string = pattern
       string == pattern
	      true  if	string	matches pattern.  The '==' form is the preferred one.  The '=' form is
	      for backward compatibility and should be considered obsolete.

       string != pattern
	      true if string does not match pattern.

       string =~ regexp
	      true if string matches the regular expression regexp.  If the  option  RE_MATCH_PCRE  is
	      set  regexp is tested as a PCRE regular expression using the zsh/pcre module, else it is
	      tested as a POSIX extended regular expression using the zsh/regex module.  Upon success-
	      ful  match,  some  variables  will  be updated; no variables are changed if the matching
	      fails.  If the option BASH_REMATCH is set the array BASH_REMATCH is set to the substring
	      that  matched  the  pattern followed by the substrings that matched parenthesised subex-
	      pressions within the pattern; otherwise, the scalar parameter MATCH is set to  the  sub
	      string  that  matched the pattern and and the array match to the substrings that matched
	      parenthesised subexpressions.

       string1 < string2
	      true if string1 comes before string2 based on ASCII value of their characters.

       string1 > string2
	      true if string1 comes after string2 based on ASCII value of their characters.

       exp1 -eq exp2
	      true if exp1 is numerically equal to exp2.

       exp1 -ne exp2
	      true if exp1 is numerically not equal to exp2.

       exp1 -lt exp2
	      true if exp1 is numerically less than exp2.

       exp1 -gt exp2
	      true if exp1 is numerically greater than exp2.

       exp1 -le exp2
	      true if exp1 is numerically less than or equal to exp2.

       exp1 -ge exp2
	      true if exp1 is numerically greater than or equal to exp2.

       ( exp )
	      true if exp is true.

       ! exp  true if exp is false.

       exp1 && exp2
	      true if exp1 and exp2 are both true.

       exp1 || exp2
	      true if either exp1 or exp2 is true.

CHMOD notes
-----------
chmod sUid 4775
           ^
chmod sGid 2755
           ^
DOC
) | less
}
tip_zsh_cheatsheet () {
	mdless ${_EXTERNAL_FILES[zsh_cheatsheet]}
}
#--MAX_RANGE_MARKER--

#--Begin GetOpts--
read -r -d '' DESC<<EOF
Display collected tips on various topics
\tFor <KEYWORD> searches, additional options
\tmay be included to enhance search:
\t-d line detail -w word boundary, -I case sensitive
\nTIPS:\n
$(for T in ${_TIPS};do echo "\t${T}";done)
EOF

parse_opts () {
	local OPTS=${@}
	local -a OPTSTR
	local LETTER_OPT
	local O

	for O in {1..${#OPTS}};do
		[[ ${OPTS[${O}]} =~ '[a-z]' ]] && LETTER_OPT=${OPTS[${O}]}
		[[ ${O} -eq 1 && ${OPTS[${O}]} == ":" ]] && continue
		[[ ${O} -gt 1 && ${OPTS[${O}]} == ":" ]] && OPTSTR+=$(opt_type ${LETTER_OPT}) && continue
		OPTSTR+="-${OPTS[${O}]}"
	done
	echo ${OPTSTR}
}

opt_exists () {
	local OPT=${1}
	[[ $(( ${OPTIONS}[(Ie)${OPT}] )) -ne 0 ]] && return 0 || return 1
}

opt_type () {
	local OPT=${1}
	case ${OPT} in
		d) echo "<DIR>";;
		f) echo "<FILE>";;
		k) echo "<KEYWORD>";;
		t) echo "<TIP_NAME>";;
	esac
}

usage () {

	tabs 5
	[[ ${_SMCUP} == 'true' ]] && do_rmcup

	local OPTS=$(parse_opts ${OPTSTR})
	local -a PENDING_MSGS=(${@})
	(
	echo -e "\n${WHITE_FG}Usage${RESET}: ${_SCRIPT} ${WHITE_FG}[${RESET}${OPTS}${WHITE_FG}]${RESET} [$(opt_type t)]\n"
	echo -e "${WHITE_FG}-H${RESET} help"
	echo -e "${WHITE_FG}-D${RESET} debug (repeats increase level)"
	echo -e "${WHITE_FG}-k $(opt_type k)${RESET} search within tips for keyword"
	echo -e "\n${WHITE_FG}Desc${RESET}:${DESC}\n"
	) >&2

	exit_leave $(msg_err "${PENDING_MSGS}")
}

typeset -a OPTIONS
OPTSTR=":HDdk:Iw"
OPTIND=0

KEYWORD=''
KEYWORD_DETAIL=false
WORD=false
CASE=false

while getopts ${OPTSTR} OPTION;do
	case ${OPTION} in
     H) usage;;
     D) dbg_set_level;;
     I) CASE=true;;
     d) KEYWORD_DETAIL=true;;
     k) KEYWORD=${OPTARG};;
     w) WORD=true;;
     :) print -u2 "${RED_FG}${_SCRIPT}${RESET}: option: -${OPTARG} requires an argument"; usage;;
    \?) print -u2 "${RED_FG}${_SCRIPT}${RESET}: ${BOLD}${RED_FG}Unknown option${RESET} -${OPTARG}"; usage;;
	esac
	[[ ${OPTION} != 'D' ]] && OPTIONS+=${OPTION}
done
shift $((OPTIND -1))
#--End GetOpts--

#Execution
[[ ${#} -ne 0 ]] && ARG=${1} || ARG=''

typeset -A KEY_RANGE
typeset -a PDF_LIST
typeset -aU HITS

MR=$(grep -n -m1 "MAX_RANGE_MARKER" ${_SCRIPT_FQFN})
LINE=$(cut -d':' -f1 <<<${MR})
MAX_RANGE=${LINE}

MIN_RANGE=0
if [[ -n ${KEYWORD} ]];then
	for T in ${_TIPS};do
		F=$(grep -n "^tip_${T} \(\)" ${_SCRIPT_FQFN})
		LINE=$(cut -d':' -f1 <<<${F})
		[[ ${MIN_RANGE} -eq 0 ]] && MIN_RANGE=${LINE}
		KEY_RANGE[${LINE}]=${T} # Build a range table
		[[ ${_DEBUG} -gt 1 ]] && dbg "${0}:${LINENO} KEY_RANGE[${LINE}]=${T}"
	done

	[[ ${CASE} == 'true' ]] && CASE_OPT='' || CASE_OPT='-i'
	[[ ${WORD} == 'true' ]] && WORD_OPT='-w' || WORD_OPT=''

	[[ ${_DEBUG} -gt 0 ]] && dbg "${0}:${LINENO} grep --color=never -n ${CASE_OPT} ${WORD_OPT} ${KEYWORD} ${_SCRIPT_FQFN}"
	LIST=("${(f)$(grep --color=never -n ${CASE_OPT} ${WORD_OPT} ${KEYWORD} ${_SCRIPT_FQFN})}")
	[[ ${_DEBUG} -gt 0 ]] && dbg "${0}:${LINENO} KEYWORD:\"${KEYWORD}\" LIST count:${#LIST}"

	EXTERNAL_FILE_ROWS=0
	for E in ${(k)_EXTERNAL};do
		ELIST=("${(f)$(pdfgrep --color=never ${CASE_OPT} ${KEYWORD} ${_EXTERNAL_FILES[${E}]})}")
		[[ ${_DEBUG} -gt 1 ]] && dbg "${0}:${LINENO} EXTERNAL FILE:${_EXTERNAL_FILES[${E}]} - KEYWORD:\"${KEYWORD}\" ELIST count:${#ELIST}"
		if [[ ${_DEBUG} -gt 2 ]];then
			dbg "$(for D in ${ELIST};do echo ${D};done)"
		fi
		EHIT=false
		for X in ${ELIST};do
			echo ${X} | grep -q ${WORD_OPT} ${KEYWORD} # enforce WORD_OPT - pdfgrep (-w not supported)
			RC=${?}
			if [[ ${RC} -eq 0 ]];then
				EHIT=true
				((EXTERNAL_FILE_ROWS++))
				PDF_LIST+=${(k)KEY_RANGE[(r)${E}]}:${X}
			fi
		done
		[[ ${_DEBUG} -gt 0 && ${EHIT} == 'true' ]] && dbg "${0}:${LINENO} EXTERNAL FILE:${_EXTERNAL_FILES[${E}]} ELIST count:${#ELIST}"
	done
	[[ ${_DEBUG} -gt 0 ]] && dbg "${0}:${LINENO} EXTERNAL_FILE_ROWS added:${EXTERNAL_FILE_ROWS}"

	LIST+=(${PDF_LIST})
	if arr_is_populated "${LIST}";then
		[[ ${_DEBUG} -gt 0 ]] && dbg "${0}:${LINENO} Aggregate LIST count:${#LIST}"
	else
		[[ ${_DEBUG} -gt 0 ]] && dbg "${0}:${LINENO} Aggregate LIST is empty"
	fi

	for L in ${(on)LIST};do
		LINE_NUM=$(cut -d':' -f1 <<<${L})
		TEXT=$(cut -d':' -f2- <<<${L})

		if [[ ${_DEBUG} -gt 0 ]];then
			[[ ${TEXT} =~ "tip_${KEYWORD}" ]] && dbg "TIP_MATCH:${TEXT} - ejected ${TEXT}"
			[[ ${LINE_NUM} -lt ${MIN_RANGE} ]] && dbg "MIN_RANGE:${MIN_RANGE} - ejected ${LINE_NUM}"
			[[ ${LINE_NUM} -gt ${MAX_RANGE} ]] && dbg "MAX_RANGE:${MAX_RANGE} - ejected ${LINE_NUM}"
		fi

		[[ ${TEXT} =~ "tip_${KEYWORD}" ]] && continue
		[[ ${LINE_NUM} -lt ${MIN_RANGE} ]] && continue
		[[ ${LINE_NUM} -gt ${MAX_RANGE} ]] && continue

		TEXT=$(str_trim ${TEXT})
		TEXT=$(sed 's/\t/ /' <<<${TEXT})
		TEXT=$(tr -s '[:space:]' <<<${TEXT})

		LAST_K=0
		for K in ${(onk)KEY_RANGE};do
			[[ ${LAST_K} -eq 0 ]] && LAST_K=${K} && continue

			if [[ ${LINE_NUM} -ge ${LAST_K} && ${LINE_NUM} -lt ${K} ]];then
				[[ ${_DEBUG} -gt 1 ]] && dbg "${0}:${LINENO} SLOTTED LINE_NUM:${LINE_NUM} into tip_${KEY_RANGE[${LAST_K}]} -> ${LINE_NUM} -ge ${LAST_K} && ${LINE_NUM} -le ${K}"
				SNIP=$(grep --color=always ${CASE_OPT} ${WORD_OPT} ${KEYWORD} <<<${TEXT})
				if [[ -n ${SNIP} ]];then
					if [[ ${KEYWORD_DETAIL} == 'true' ]];then
						HIT="KEYWORD:${CYAN_FG}${KEYWORD}${RESET} in:[${WHITE_FG}tip_${KEY_RANGE[${LAST_K}]}${RESET}] ${SNIP[1,120]}${RESET}"
					else
						HIT="KEYWORD:${CYAN_FG}${KEYWORD}${RESET} in:[${WHITE_FG}tip_${KEY_RANGE[${LAST_K}]}${RESET}]"
					fi
					HITS+=${HIT}
					break
				fi
			fi

			LAST_K=${K}
		done
	done

	if arr_is_populated "${HITS}";then
		{
		for H in ${HITS};do
			TIP_LBL=$(cut -d':' -f3 <<<{$H} | cut -d' ' -f1)
			[[ ${KEYWORD_DETAIL} == 'true' && ${TIP_LBL} != ${LAST_TIP_LBL} ]] && echo ${MAGENTA_FG}$(str_unicode_line 7)${RESET}
			eval echo \"${H}\" 2>/dev/null
			LAST_TIP_LBL=${TIP_LBL}
		done
		[[ ${KEYWORD_DETAIL} == 'true' ]] && echo ${MAGENTA_FG}$(str_unicode_line 7)${RESET}
		} | mypager wait
	else
		echo "KEYWORD:\"${WHITE_FG}${KEYWORD}\" ${RED_FG}not found${RESET}" | mypager wait
	fi

	exit_leave
fi


if [[ -n ${ARG} ]];then
	if [[ ${${_TIPS[(i)${ARG}]}} -le ${#_TIPS} ]];then
		do_smcup
		if [[ ${_EXTERNAL[${TIP}]} -eq 1 ]];then
			tip_${ARG}
		else
			tip_${ARG} | mypager
		fi
		do_rmcup
	else
		exit_leave $(msg_err "Tip not found:${ARG}")
	fi
else
	while true;do
		do_smcup
		selection_list_set ${_TIPS}
		selection_list -O ${CYAN_FG} "<w>Select Tip or <h>(q)uit<N>"
		TIP=${_SELECTION_VALUE}
		if [[ ${_EXTERNAL[${TIP}]} -eq 1 ]];then
			tip_${TIP}
		else
			tip_${TIP} | mypager
		fi
		do_rmcup
	done
fi

exit_leave
